{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyXtmJUuu5zP",
        "outputId": "caaf8827-d72a-4bb8-c1ac-c3e31e386d85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m97.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h‚úÖ All packages installed successfully!\n",
            "\n",
            "Installed packages:\n",
            "- streamlit: For beautiful web interface\n",
            "- groq: For fast AI inference\n",
            "- google-generativeai: For Gemini API\n",
            "- PyPDF2 & pdfplumber: For PDF processing\n",
            "- python-docx: For DOCX handling\n",
            "- plotly: For interactive charts\n",
            "- pandas: For data management\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Install all required packages\n",
        "!pip install streamlit groq google-generativeai PyPDF2 pdfplumber python-docx plotly pandas pillow -q\n",
        "\n",
        "print(\"‚úÖ All packages installed successfully!\")\n",
        "print(\"\\nInstalled packages:\")\n",
        "print(\"- streamlit: For beautiful web interface\")\n",
        "print(\"- groq: For fast AI inference\")\n",
        "print(\"- google-generativeai: For Gemini API\")\n",
        "print(\"- PyPDF2 & pdfplumber: For PDF processing\")\n",
        "print(\"- python-docx: For DOCX handling\")\n",
        "print(\"- plotly: For interactive charts\")\n",
        "print(\"- pandas: For data management\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYbvGlkLu83I",
        "outputId": "96a2dd54-b239-40b0-9d4a-cc19bc426bd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ All libraries imported successfully!\n",
            "\n",
            "üìã Library purposes:\n",
            "- PyPDF2 & pdfplumber: Extract text from PDF resumes\n",
            "- Groq: Fast interview question generation\n",
            "- Google GenAI: Resume analysis with vision capabilities\n",
            "- Plotly: Beautiful interactive dashboards\n",
            "- Pandas: Data management for interview history\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Import all required libraries\n",
        "import os\n",
        "import io\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime\n",
        "from typing import List, Dict, Tuple\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# PDF Processing\n",
        "import PyPDF2\n",
        "import pdfplumber\n",
        "\n",
        "# AI APIs\n",
        "from groq import Groq\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Data handling\n",
        "import pandas as pd\n",
        "\n",
        "# Visualization\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "# For file handling\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"‚úÖ All libraries imported successfully!\")\n",
        "print(\"\\nüìã Library purposes:\")\n",
        "print(\"- PyPDF2 & pdfplumber: Extract text from PDF resumes\")\n",
        "print(\"- Groq: Fast interview question generation\")\n",
        "print(\"- Google GenAI: Resume analysis with vision capabilities\")\n",
        "print(\"- Plotly: Beautiful interactive dashboards\")\n",
        "print(\"- Pandas: Data management for interview history\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 803
        },
        "id": "-Q9i5PGDvFEr",
        "outputId": "59c3e7b5-4896-43ba-fd1f-b1aeb4d7589d"
      },
      "outputs": [],
      "source": [
        "# Cell 3: Setup and Test API Keys (FINAL VERSION)\n",
        "\n",
        "print(\"üîë API Keys Configuration\\n\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Get API keys from user\n",
        "print(\"\\nüìå You need TWO free API keys:\\n\")\n",
        "print(\"1. GROQ API Key:\")\n",
        "print(\"   - Visit: https://console.groq.com/keys\")\n",
        "print(\"   - Sign up/Login with Google\")\n",
        "print(\"   - Click 'Create API Key'\")\n",
        "print(\"   - Copy the key\\n\")\n",
        "\n",
        "print(\"2. GEMINI API Key:\")\n",
        "print(\"   - Visit: https://aistudio.google.com/app/apikey\")\n",
        "print(\"   - Sign in with Google\")\n",
        "print(\"   - Click 'Create API Key'\")\n",
        "print(\"   - Copy the key\\n\")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Input API keys\n",
        "GROQ_API_KEY = input(\"\\nüîπ Enter your GROQ API Key: \").strip()\n",
        "GEMINI_API_KEY = input(\"üîπ Enter your GEMINI API Key: \").strip()\n",
        "\n",
        "# Validate inputs\n",
        "if not GROQ_API_KEY or not GEMINI_API_KEY:\n",
        "    print(\"\\n‚ùå Error: Both API keys are required!\")\n",
        "else:\n",
        "    print(\"\\n‚úÖ API keys received!\")\n",
        "\n",
        "    # Test Groq Connection\n",
        "    print(\"\\nüß™ Testing Groq API...\")\n",
        "    try:\n",
        "        groq_client = Groq(api_key=GROQ_API_KEY)\n",
        "        test_response = groq_client.chat.completions.create(\n",
        "            messages=[{\"role\": \"user\", \"content\": \"Say 'Hello'\"}],\n",
        "            model=\"llama-3.3-70b-versatile\",\n",
        "            max_tokens=10\n",
        "        )\n",
        "        print(\"‚úÖ Groq API: Connected successfully!\")\n",
        "        print(f\"   Model: llama-3.3-70b-versatile\")\n",
        "        print(f\"   Response: {test_response.choices[0].message.content}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Groq API Error: {str(e)}\")\n",
        "\n",
        "    # Test Gemini Connection with correct model\n",
        "    print(\"\\nüß™ Testing Gemini API...\")\n",
        "    try:\n",
        "        genai.configure(api_key=GEMINI_API_KEY)\n",
        "        # Using the latest stable model from your available list\n",
        "        gemini_model = genai.GenerativeModel('gemini-2.5-flash')\n",
        "        test_response = gemini_model.generate_content(\"Say 'Hello'\")\n",
        "        print(\"‚úÖ Gemini API: Connected successfully!\")\n",
        "        print(f\"   Model: gemini-2.5-flash\")\n",
        "        print(f\"   Response: {test_response.text}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Gemini API Error: {str(e)}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"üéâ Both APIs connected successfully!\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"\\nüìù Models we'll use in this project:\")\n",
        "    print(\"   ‚Ä¢ Groq: llama-3.3-70b-versatile (Fast inference)\")\n",
        "    print(\"   ‚Ä¢ Gemini: gemini-2.5-flash (Multimodal + Vision)\")\n",
        "    print(\"\\n‚ú® Ready to build the Interview Prep system!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XdsJks3vhi-",
        "outputId": "b130c211-8eb8-4379-efdd-bf9b2d0cd0ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "üìÑ PDF Resume Parser Ready!\n",
            "============================================================\n",
            "\n",
            "‚ú® Functions created:\n",
            "   ‚Ä¢ extract_text_from_pdf() - Extracts text from PDF\n",
            "   ‚Ä¢ extract_email() - Finds email addresses\n",
            "   ‚Ä¢ extract_phone() - Finds phone numbers\n",
            "   ‚Ä¢ extract_skills() - Identifies technical skills\n",
            "   ‚Ä¢ extract_education() - Extracts education details\n",
            "   ‚Ä¢ extract_experience() - Extracts work experience\n",
            "   ‚Ä¢ structure_resume_data() - Main parsing function\n",
            "\n",
            "üí° Ready to parse resumes!\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: PDF Resume Parser\n",
        "\n",
        "import re\n",
        "from typing import Dict, List\n",
        "\n",
        "def extract_text_from_pdf(pdf_file) -> str:\n",
        "    \"\"\"\n",
        "    Extract text from uploaded PDF file using multiple methods for reliability.\n",
        "    \"\"\"\n",
        "    text = \"\"\n",
        "\n",
        "    try:\n",
        "        # Method 1: Try pdfplumber first (better for complex layouts)\n",
        "        with pdfplumber.open(pdf_file) as pdf:\n",
        "            for page in pdf.pages:\n",
        "                page_text = page.extract_text()\n",
        "                if page_text:\n",
        "                    text += page_text + \"\\n\"\n",
        "\n",
        "        if text.strip():\n",
        "            print(\"‚úÖ Successfully extracted text using pdfplumber\")\n",
        "            return text\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è pdfplumber failed: {str(e)[:50]}... Trying PyPDF2\")\n",
        "\n",
        "    try:\n",
        "        # Method 2: Fallback to PyPDF2\n",
        "        pdf_file.seek(0)  # Reset file pointer\n",
        "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "        for page_num in range(len(pdf_reader.pages)):\n",
        "            page = pdf_reader.pages[page_num]\n",
        "            text += page.extract_text() + \"\\n\"\n",
        "\n",
        "        if text.strip():\n",
        "            print(\"‚úÖ Successfully extracted text using PyPDF2\")\n",
        "            return text\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå PyPDF2 also failed: {str(e)}\")\n",
        "        return \"\"\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "def extract_email(text: str) -> str:\n",
        "    \"\"\"Extract email address from text.\"\"\"\n",
        "    email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
        "    emails = re.findall(email_pattern, text)\n",
        "    return emails[0] if emails else \"Not found\"\n",
        "\n",
        "\n",
        "def extract_phone(text: str) -> str:\n",
        "    \"\"\"Extract phone number from text.\"\"\"\n",
        "    phone_patterns = [\n",
        "        r'\\+?\\d{1,3}[-.\\s]?\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}',  # US format\n",
        "        r'\\+?\\d{10,}',  # International\n",
        "        r'\\d{3}-\\d{3}-\\d{4}',  # XXX-XXX-XXXX\n",
        "    ]\n",
        "\n",
        "    for pattern in phone_patterns:\n",
        "        phones = re.findall(pattern, text)\n",
        "        if phones:\n",
        "            return phones[0]\n",
        "    return \"Not found\"\n",
        "\n",
        "\n",
        "def extract_skills(text: str) -> List[str]:\n",
        "    \"\"\"\n",
        "    Extract technical skills from resume text.\n",
        "    \"\"\"\n",
        "    # Common technical skills database\n",
        "    skills_database = [\n",
        "        # Programming Languages\n",
        "        'python', 'java', 'javascript', 'c++', 'c#', 'ruby', 'php', 'swift',\n",
        "        'kotlin', 'go', 'rust', 'typescript', 'scala', 'r', 'matlab',\n",
        "\n",
        "        # Web Technologies\n",
        "        'html', 'css', 'react', 'angular', 'vue', 'node.js', 'express',\n",
        "        'django', 'flask', 'spring boot', 'asp.net', 'jquery',\n",
        "\n",
        "        # Databases\n",
        "        'sql', 'mysql', 'postgresql', 'mongodb', 'redis', 'oracle',\n",
        "        'sqlite', 'cassandra', 'dynamodb', 'firebase',\n",
        "\n",
        "        # Cloud & DevOps\n",
        "        'aws', 'azure', 'gcp', 'docker', 'kubernetes', 'jenkins', 'git',\n",
        "        'ci/cd', 'terraform', 'ansible', 'linux', 'shell scripting',\n",
        "\n",
        "        # Data Science & ML\n",
        "        'machine learning', 'deep learning', 'tensorflow', 'pytorch',\n",
        "        'scikit-learn', 'pandas', 'numpy', 'data analysis', 'statistics',\n",
        "        'nlp', 'computer vision', 'opencv',\n",
        "\n",
        "        # Other\n",
        "        'agile', 'scrum', 'jira', 'rest api', 'graphql', 'microservices',\n",
        "        'testing', 'debugging', 'problem solving', 'communication'\n",
        "    ]\n",
        "\n",
        "    text_lower = text.lower()\n",
        "    found_skills = []\n",
        "\n",
        "    for skill in skills_database:\n",
        "        if skill in text_lower:\n",
        "            # Capitalize properly\n",
        "            found_skills.append(skill.title())\n",
        "\n",
        "    # Remove duplicates and sort\n",
        "    found_skills = sorted(list(set(found_skills)))\n",
        "\n",
        "    return found_skills\n",
        "\n",
        "\n",
        "def extract_education(text: str) -> List[str]:\n",
        "    \"\"\"Extract education information.\"\"\"\n",
        "    education_keywords = ['bachelor', 'master', 'phd', 'b.tech', 'm.tech',\n",
        "                         'b.e', 'm.e', 'bca', 'mca', 'degree', 'university',\n",
        "                         'college', 'institute', 'b.sc', 'm.sc']\n",
        "\n",
        "    lines = text.split('\\n')\n",
        "    education = []\n",
        "\n",
        "    for i, line in enumerate(lines):\n",
        "        line_lower = line.lower()\n",
        "        if any(keyword in line_lower for keyword in education_keywords):\n",
        "            # Get current line and next 2 lines for context\n",
        "            edu_text = ' '.join(lines[i:i+3]).strip()\n",
        "            if edu_text and len(edu_text) > 10:\n",
        "                education.append(edu_text[:200])  # Limit length\n",
        "\n",
        "    return education[:3]  # Return top 3\n",
        "\n",
        "\n",
        "def extract_experience(text: str) -> List[Dict[str, str]]:\n",
        "    \"\"\"Extract work experience details.\"\"\"\n",
        "    experience = []\n",
        "\n",
        "    # Common job title keywords\n",
        "    job_keywords = ['engineer', 'developer', 'analyst', 'manager', 'designer',\n",
        "                   'consultant', 'intern', 'associate', 'specialist', 'lead']\n",
        "\n",
        "    lines = text.split('\\n')\n",
        "\n",
        "    for i, line in enumerate(lines):\n",
        "        line_lower = line.lower()\n",
        "        # Check if line contains job keywords\n",
        "        if any(keyword in line_lower for keyword in job_keywords):\n",
        "            exp_entry = {\n",
        "                'title': line.strip()[:100],\n",
        "                'description': ' '.join(lines[i+1:i+4]).strip()[:300]\n",
        "            }\n",
        "            experience.append(exp_entry)\n",
        "\n",
        "    return experience[:5]  # Return top 5 experiences\n",
        "\n",
        "\n",
        "def structure_resume_data(text: str) -> Dict:\n",
        "    \"\"\"\n",
        "    Main function to structure all extracted resume data.\n",
        "    \"\"\"\n",
        "    print(\"\\nüîç Analyzing resume structure...\")\n",
        "\n",
        "    structured_data = {\n",
        "        'raw_text': text,\n",
        "        'email': extract_email(text),\n",
        "        'phone': extract_phone(text),\n",
        "        'skills': extract_skills(text),\n",
        "        'education': extract_education(text),\n",
        "        'experience': extract_experience(text),\n",
        "        'total_words': len(text.split()),\n",
        "        'total_characters': len(text)\n",
        "    }\n",
        "\n",
        "    print(f\"‚úÖ Extracted {len(structured_data['skills'])} skills\")\n",
        "    print(f\"‚úÖ Found {len(structured_data['education'])} education entries\")\n",
        "    print(f\"‚úÖ Found {len(structured_data['experience'])} experience entries\")\n",
        "\n",
        "    return structured_data\n",
        "\n",
        "\n",
        "# Test the PDF parser with a sample\n",
        "print(\"=\" * 60)\n",
        "print(\"üìÑ PDF Resume Parser Ready!\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\n‚ú® Functions created:\")\n",
        "print(\"   ‚Ä¢ extract_text_from_pdf() - Extracts text from PDF\")\n",
        "print(\"   ‚Ä¢ extract_email() - Finds email addresses\")\n",
        "print(\"   ‚Ä¢ extract_phone() - Finds phone numbers\")\n",
        "print(\"   ‚Ä¢ extract_skills() - Identifies technical skills\")\n",
        "print(\"   ‚Ä¢ extract_education() - Extracts education details\")\n",
        "print(\"   ‚Ä¢ extract_experience() - Extracts work experience\")\n",
        "print(\"   ‚Ä¢ structure_resume_data() - Main parsing function\")\n",
        "print(\"\\nüí° Ready to parse resumes!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3t7baS5lwt3l",
        "outputId": "6fb066a7-0909-41d0-a749-08409c8fcae0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "üéØ Resume Analyzer Ready!\n",
            "============================================================\n",
            "\n",
            "‚ú® Functions created:\n",
            "   ‚Ä¢ calculate_ats_score() - Calculates ATS compatibility (0-100)\n",
            "   ‚Ä¢ analyze_resume_with_gemini() - Deep AI analysis\n",
            "   ‚Ä¢ generate_improvement_suggestions() - Actionable tips\n",
            "   ‚Ä¢ complete_resume_analysis() - Main analysis function\n",
            "\n",
            "üí° Ready to analyze resumes and provide feedback!\n"
          ]
        }
      ],
      "source": [
        "# Cell 5: Resume Analyzer with Gemini AI\n",
        "\n",
        "def calculate_ats_score(resume_data: Dict) -> Dict:\n",
        "    \"\"\"\n",
        "    Calculate ATS (Applicant Tracking System) compatibility score.\n",
        "    Based on multiple factors that ATS systems check.\n",
        "    \"\"\"\n",
        "    score = 0\n",
        "    max_score = 100\n",
        "    feedback = []\n",
        "\n",
        "    # Factor 1: Contact Information (15 points)\n",
        "    if resume_data['email'] != \"Not found\":\n",
        "        score += 8\n",
        "        feedback.append(\"‚úÖ Email found\")\n",
        "    else:\n",
        "        feedback.append(\"‚ùå Missing email address\")\n",
        "\n",
        "    if resume_data['phone'] != \"Not found\":\n",
        "        score += 7\n",
        "        feedback.append(\"‚úÖ Phone number found\")\n",
        "    else:\n",
        "        feedback.append(\"‚ùå Missing phone number\")\n",
        "\n",
        "    # Factor 2: Skills Section (30 points)\n",
        "    num_skills = len(resume_data['skills'])\n",
        "    if num_skills >= 10:\n",
        "        score += 30\n",
        "        feedback.append(f\"‚úÖ Strong skills section ({num_skills} skills)\")\n",
        "    elif num_skills >= 5:\n",
        "        score += 20\n",
        "        feedback.append(f\"‚ö†Ô∏è Moderate skills section ({num_skills} skills)\")\n",
        "    else:\n",
        "        score += 10\n",
        "        feedback.append(f\"‚ùå Weak skills section ({num_skills} skills)\")\n",
        "\n",
        "    # Factor 3: Education (15 points)\n",
        "    if len(resume_data['education']) >= 1:\n",
        "        score += 15\n",
        "        feedback.append(\"‚úÖ Education section present\")\n",
        "    else:\n",
        "        feedback.append(\"‚ùå Missing education section\")\n",
        "\n",
        "    # Factor 4: Experience (25 points)\n",
        "    num_exp = len(resume_data['experience'])\n",
        "    if num_exp >= 3:\n",
        "        score += 25\n",
        "        feedback.append(f\"‚úÖ Strong experience section ({num_exp} entries)\")\n",
        "    elif num_exp >= 1:\n",
        "        score += 15\n",
        "        feedback.append(f\"‚ö†Ô∏è Limited experience ({num_exp} entries)\")\n",
        "    else:\n",
        "        feedback.append(\"‚ùå No experience section found\")\n",
        "\n",
        "    # Factor 5: Resume Length (15 points)\n",
        "    word_count = resume_data['total_words']\n",
        "    if 300 <= word_count <= 800:\n",
        "        score += 15\n",
        "        feedback.append(f\"‚úÖ Optimal length ({word_count} words)\")\n",
        "    elif word_count < 300:\n",
        "        score += 5\n",
        "        feedback.append(f\"‚ö†Ô∏è Too short ({word_count} words)\")\n",
        "    else:\n",
        "        score += 10\n",
        "        feedback.append(f\"‚ö†Ô∏è Too long ({word_count} words)\")\n",
        "\n",
        "    return {\n",
        "        'score': score,\n",
        "        'grade': 'A+' if score >= 90 else 'A' if score >= 80 else 'B' if score >= 70 else 'C' if score >= 60 else 'D',\n",
        "        'feedback': feedback\n",
        "    }\n",
        "\n",
        "\n",
        "def analyze_resume_with_gemini(resume_data: Dict) -> Dict:\n",
        "    \"\"\"\n",
        "    Use Gemini AI to provide deep analysis and improvement suggestions.\n",
        "    \"\"\"\n",
        "    print(\"\\nü§ñ Analyzing resume with Gemini AI...\")\n",
        "\n",
        "    # Prepare prompt for Gemini\n",
        "    prompt = f\"\"\"You are an expert resume reviewer and career coach. Analyze this resume and provide detailed feedback.\n",
        "\n",
        "RESUME DATA:\n",
        "- Total Words: {resume_data['total_words']}\n",
        "- Email: {resume_data['email']}\n",
        "- Phone: {resume_data['phone']}\n",
        "- Skills ({len(resume_data['skills'])}): {', '.join(resume_data['skills'][:15])}\n",
        "- Education Entries: {len(resume_data['education'])}\n",
        "- Experience Entries: {len(resume_data['experience'])}\n",
        "\n",
        "RESUME TEXT:\n",
        "{resume_data['raw_text'][:3000]}\n",
        "\n",
        "Please provide:\n",
        "1. STRENGTHS (3-4 bullet points): What makes this resume stand out?\n",
        "2. WEAKNESSES (3-4 bullet points): What needs improvement?\n",
        "3. MISSING KEYWORDS: What important technical/professional keywords are missing?\n",
        "4. ACTIONABLE IMPROVEMENTS (5 specific suggestions): Concrete steps to improve this resume.\n",
        "5. OVERALL IMPRESSION (2-3 sentences): Professional summary of this candidate.\n",
        "\n",
        "Format your response clearly with headers for each section.\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = gemini_model.generate_content(prompt)\n",
        "        analysis = response.text\n",
        "        print(\"‚úÖ Gemini analysis complete!\")\n",
        "        return {\n",
        "            'success': True,\n",
        "            'analysis': analysis\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Gemini analysis failed: {str(e)}\")\n",
        "        return {\n",
        "            'success': False,\n",
        "            'analysis': \"Analysis unavailable. Please check API connection.\"\n",
        "        }\n",
        "\n",
        "\n",
        "def generate_improvement_suggestions(resume_data: Dict, ats_score: Dict) -> List[str]:\n",
        "    \"\"\"\n",
        "    Generate specific, actionable improvement suggestions.\n",
        "    \"\"\"\n",
        "    suggestions = []\n",
        "\n",
        "    # Contact info suggestions\n",
        "    if resume_data['email'] == \"Not found\":\n",
        "        suggestions.append(\"üî∏ Add a professional email address at the top of your resume\")\n",
        "\n",
        "    if resume_data['phone'] == \"Not found\":\n",
        "        suggestions.append(\"üî∏ Include a contact phone number\")\n",
        "\n",
        "    # Skills suggestions\n",
        "    if len(resume_data['skills']) < 8:\n",
        "        suggestions.append(\"üî∏ Add more technical skills (aim for 10-15 relevant skills)\")\n",
        "        suggestions.append(\"üî∏ Include both hard skills (technical) and soft skills (communication, leadership)\")\n",
        "\n",
        "    # Education suggestions\n",
        "    if len(resume_data['education']) == 0:\n",
        "        suggestions.append(\"üî∏ Add an Education section with degree, institution, and graduation year\")\n",
        "\n",
        "    # Experience suggestions\n",
        "    if len(resume_data['experience']) < 2:\n",
        "        suggestions.append(\"üî∏ Add more work experience or project details\")\n",
        "        suggestions.append(\"üî∏ Use action verbs (Led, Developed, Implemented, Achieved)\")\n",
        "\n",
        "    # Length suggestions\n",
        "    if resume_data['total_words'] < 300:\n",
        "        suggestions.append(\"üî∏ Expand your resume with more details about achievements and responsibilities\")\n",
        "    elif resume_data['total_words'] > 800:\n",
        "        suggestions.append(\"üî∏ Condense your resume - remove less relevant information\")\n",
        "\n",
        "    # General suggestions\n",
        "    suggestions.append(\"üî∏ Quantify achievements with numbers (e.g., 'Increased efficiency by 30%')\")\n",
        "    suggestions.append(\"üî∏ Tailor your resume for each job application\")\n",
        "    suggestions.append(\"üî∏ Use industry-specific keywords from job descriptions\")\n",
        "\n",
        "    return suggestions[:8]  # Return top 8 suggestions\n",
        "\n",
        "\n",
        "def complete_resume_analysis(resume_data: Dict) -> Dict:\n",
        "    \"\"\"\n",
        "    Main function that performs complete resume analysis.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"üìä COMPLETE RESUME ANALYSIS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Step 1: Calculate ATS Score\n",
        "    print(\"\\n1Ô∏è‚É£ Calculating ATS Score...\")\n",
        "    ats_result = calculate_ats_score(resume_data)\n",
        "    print(f\"   Score: {ats_result['score']}/100 (Grade: {ats_result['grade']})\")\n",
        "\n",
        "    # Step 2: Gemini AI Analysis\n",
        "    print(\"\\n2Ô∏è‚É£ Running Gemini AI Analysis...\")\n",
        "    gemini_analysis = analyze_resume_with_gemini(resume_data)\n",
        "\n",
        "    # Step 3: Generate Suggestions\n",
        "    print(\"\\n3Ô∏è‚É£ Generating Improvement Suggestions...\")\n",
        "    suggestions = generate_improvement_suggestions(resume_data, ats_result)\n",
        "    print(f\"   Generated {len(suggestions)} suggestions\")\n",
        "\n",
        "    # Compile complete analysis\n",
        "    complete_analysis = {\n",
        "        'ats_score': ats_result['score'],\n",
        "        'ats_grade': ats_result['grade'],\n",
        "        'ats_feedback': ats_result['feedback'],\n",
        "        'gemini_analysis': gemini_analysis['analysis'],\n",
        "        'improvement_suggestions': suggestions,\n",
        "        'contact_info': {\n",
        "            'email': resume_data['email'],\n",
        "            'phone': resume_data['phone']\n",
        "        },\n",
        "        'stats': {\n",
        "            'total_skills': len(resume_data['skills']),\n",
        "            'total_experience': len(resume_data['experience']),\n",
        "            'total_education': len(resume_data['education']),\n",
        "            'word_count': resume_data['total_words']\n",
        "        }\n",
        "    }\n",
        "\n",
        "    print(\"\\n‚úÖ Complete analysis ready!\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    return complete_analysis\n",
        "\n",
        "\n",
        "# Test message\n",
        "print(\"=\" * 60)\n",
        "print(\"üéØ Resume Analyzer Ready!\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\n‚ú® Functions created:\")\n",
        "print(\"   ‚Ä¢ calculate_ats_score() - Calculates ATS compatibility (0-100)\")\n",
        "print(\"   ‚Ä¢ analyze_resume_with_gemini() - Deep AI analysis\")\n",
        "print(\"   ‚Ä¢ generate_improvement_suggestions() - Actionable tips\")\n",
        "print(\"   ‚Ä¢ complete_resume_analysis() - Main analysis function\")\n",
        "print(\"\\nüí° Ready to analyze resumes and provide feedback!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjpiYKuDw8to",
        "outputId": "06abd702-e9e6-45a9-a9cf-558ae329d003"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "üéØ Job Description Matcher Ready!\n",
            "============================================================\n",
            "\n",
            "‚ú® Functions created:\n",
            "   ‚Ä¢ extract_job_requirements() - Extracts key job requirements\n",
            "   ‚Ä¢ calculate_match_score() - Scores resume vs JD (0-100)\n",
            "   ‚Ä¢ generate_job_match_report_with_gemini() - Detailed AI analysis\n",
            "   ‚Ä¢ generate_tailored_cover_letter() - Auto cover letter with Groq\n",
            "   ‚Ä¢ complete_job_match_analysis() - Main matching function\n",
            "\n",
            "üí° Ready to match resumes with job descriptions!\n"
          ]
        }
      ],
      "source": [
        "# Cell 6: Job Description Matcher\n",
        "\n",
        "def extract_job_requirements(job_description: str) -> Dict:\n",
        "    \"\"\"\n",
        "    Extract key requirements from job description.\n",
        "    \"\"\"\n",
        "    print(\"\\nüîç Analyzing job description...\")\n",
        "\n",
        "    jd_lower = job_description.lower()\n",
        "\n",
        "    # Extract required skills from JD\n",
        "    skills_database = [\n",
        "        'python', 'java', 'javascript', 'c++', 'c#', 'ruby', 'php', 'swift',\n",
        "        'kotlin', 'go', 'rust', 'typescript', 'scala', 'r', 'matlab',\n",
        "        'html', 'css', 'react', 'angular', 'vue', 'node.js', 'express',\n",
        "        'django', 'flask', 'spring boot', 'asp.net', 'jquery',\n",
        "        'sql', 'mysql', 'postgresql', 'mongodb', 'redis', 'oracle',\n",
        "        'aws', 'azure', 'gcp', 'docker', 'kubernetes', 'jenkins', 'git',\n",
        "        'machine learning', 'deep learning', 'tensorflow', 'pytorch',\n",
        "        'data analysis', 'statistics', 'nlp', 'computer vision',\n",
        "        'agile', 'scrum', 'rest api', 'microservices', 'testing'\n",
        "    ]\n",
        "\n",
        "    required_skills = []\n",
        "    for skill in skills_database:\n",
        "        if skill in jd_lower:\n",
        "            required_skills.append(skill.title())\n",
        "\n",
        "    # Extract experience requirements\n",
        "    exp_pattern = r'(\\d+)\\+?\\s*(?:year|yr)s?\\s*(?:of\\s*)?(?:experience|exp)'\n",
        "    exp_matches = re.findall(exp_pattern, jd_lower)\n",
        "    required_experience = int(exp_matches[0]) if exp_matches else 0\n",
        "\n",
        "    # Extract education requirements\n",
        "    education_keywords = ['bachelor', 'master', 'phd', 'b.tech', 'm.tech', 'degree']\n",
        "    required_education = any(keyword in jd_lower for keyword in education_keywords)\n",
        "\n",
        "    print(f\"‚úÖ Found {len(required_skills)} required skills\")\n",
        "    print(f\"‚úÖ Experience requirement: {required_experience} years\")\n",
        "\n",
        "    return {\n",
        "        'required_skills': required_skills,\n",
        "        'required_experience': required_experience,\n",
        "        'required_education': required_education,\n",
        "        'total_words': len(job_description.split())\n",
        "    }\n",
        "\n",
        "\n",
        "def calculate_match_score(resume_data: Dict, job_requirements: Dict) -> Dict:\n",
        "    \"\"\"\n",
        "    Calculate how well the resume matches the job description.\n",
        "    \"\"\"\n",
        "    print(\"\\nüìä Calculating match score...\")\n",
        "\n",
        "    score = 0\n",
        "    max_score = 100\n",
        "    breakdown = {}\n",
        "\n",
        "    # Factor 1: Skills Match (60 points)\n",
        "    resume_skills = set([s.lower() for s in resume_data['skills']])\n",
        "    required_skills = set([s.lower() for s in job_requirements['required_skills']])\n",
        "\n",
        "    if required_skills:\n",
        "        matching_skills = resume_skills.intersection(required_skills)\n",
        "        missing_skills = required_skills - resume_skills\n",
        "\n",
        "        skill_match_percentage = len(matching_skills) / len(required_skills)\n",
        "        skill_points = int(skill_match_percentage * 60)\n",
        "        score += skill_points\n",
        "\n",
        "        breakdown['skills'] = {\n",
        "            'score': skill_points,\n",
        "            'max': 60,\n",
        "            'matching': list(matching_skills),\n",
        "            'missing': list(missing_skills),\n",
        "            'match_percentage': round(skill_match_percentage * 100, 1)\n",
        "        }\n",
        "    else:\n",
        "        breakdown['skills'] = {\n",
        "            'score': 30,\n",
        "            'max': 60,\n",
        "            'matching': [],\n",
        "            'missing': [],\n",
        "            'match_percentage': 50.0\n",
        "        }\n",
        "        score += 30\n",
        "\n",
        "    # Factor 2: Experience Match (20 points)\n",
        "    num_experiences = len(resume_data['experience'])\n",
        "    if num_experiences >= job_requirements['required_experience']:\n",
        "        experience_points = 20\n",
        "    elif num_experiences >= job_requirements['required_experience'] - 1:\n",
        "        experience_points = 15\n",
        "    else:\n",
        "        experience_points = 10\n",
        "\n",
        "    score += experience_points\n",
        "    breakdown['experience'] = {\n",
        "        'score': experience_points,\n",
        "        'max': 20,\n",
        "        'required': job_requirements['required_experience'],\n",
        "        'found': num_experiences\n",
        "    }\n",
        "\n",
        "    # Factor 3: Education Match (10 points)\n",
        "    has_education = len(resume_data['education']) > 0\n",
        "    if has_education:\n",
        "        education_points = 10\n",
        "    else:\n",
        "        education_points = 5\n",
        "\n",
        "    score += education_points\n",
        "    breakdown['education'] = {\n",
        "        'score': education_points,\n",
        "        'max': 10,\n",
        "        'required': job_requirements['required_education'],\n",
        "        'found': has_education\n",
        "    }\n",
        "\n",
        "    # Factor 4: Overall Profile Quality (10 points)\n",
        "    quality_score = 0\n",
        "    if resume_data['email'] != \"Not found\":\n",
        "        quality_score += 3\n",
        "    if resume_data['phone'] != \"Not found\":\n",
        "        quality_score += 3\n",
        "    if resume_data['total_words'] >= 300:\n",
        "        quality_score += 4\n",
        "\n",
        "    score += quality_score\n",
        "    breakdown['quality'] = {\n",
        "        'score': quality_score,\n",
        "        'max': 10\n",
        "    }\n",
        "\n",
        "    print(f\"‚úÖ Match Score: {score}/100\")\n",
        "\n",
        "    return {\n",
        "        'total_score': score,\n",
        "        'percentage': round(score, 1),\n",
        "        'grade': 'Excellent Match' if score >= 80 else 'Good Match' if score >= 65 else 'Fair Match' if score >= 50 else 'Poor Match',\n",
        "        'breakdown': breakdown\n",
        "    }\n",
        "\n",
        "\n",
        "def generate_job_match_report_with_gemini(resume_data: Dict, job_description: str, match_score: Dict) -> str:\n",
        "    \"\"\"\n",
        "    Use Gemini to generate a detailed job match analysis.\n",
        "    \"\"\"\n",
        "    print(\"\\nü§ñ Generating match report with Gemini...\")\n",
        "\n",
        "    prompt = f\"\"\"You are a career counselor analyzing how well a candidate matches a job posting.\n",
        "\n",
        "JOB DESCRIPTION:\n",
        "{job_description[:1500]}\n",
        "\n",
        "CANDIDATE RESUME HIGHLIGHTS:\n",
        "- Skills: {', '.join(resume_data['skills'][:20])}\n",
        "- Experience Entries: {len(resume_data['experience'])}\n",
        "- Education: {len(resume_data['education'])} entries\n",
        "- Match Score: {match_score['total_score']}/100\n",
        "\n",
        "SKILLS ANALYSIS:\n",
        "- Matching Skills: {', '.join(match_score['breakdown']['skills']['matching'][:10])}\n",
        "- Missing Skills: {', '.join(match_score['breakdown']['skills']['missing'][:10])}\n",
        "\n",
        "Please provide:\n",
        "1. OVERALL FIT (2-3 sentences): How well does this candidate match the role?\n",
        "2. KEY STRENGTHS (3-4 points): What makes this candidate suitable?\n",
        "3. GAPS TO ADDRESS (3-4 points): What skills/experience are missing?\n",
        "4. INTERVIEW TALKING POINTS (4-5 points): What should the candidate emphasize in the interview?\n",
        "5. PREPARATION RECOMMENDATIONS (3-4 points): How should the candidate prepare?\n",
        "\n",
        "Be specific and actionable.\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = gemini_model.generate_content(prompt)\n",
        "        print(\"‚úÖ Gemini match report generated!\")\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Gemini report failed: {str(e)}\")\n",
        "        return \"Match report unavailable. Please check API connection.\"\n",
        "\n",
        "\n",
        "def generate_tailored_cover_letter(resume_data: Dict, job_description: str) -> str:\n",
        "    \"\"\"\n",
        "    Generate a tailored cover letter using Groq (fast generation).\n",
        "    \"\"\"\n",
        "    print(\"\\n‚úçÔ∏è Generating cover letter with Groq...\")\n",
        "\n",
        "    # Extract company name from JD if possible\n",
        "    jd_lines = job_description.split('\\n')\n",
        "    company_name = \"the hiring team\"\n",
        "\n",
        "    prompt = f\"\"\"Write a professional cover letter for this job application.\n",
        "\n",
        "CANDIDATE SKILLS: {', '.join(resume_data['skills'][:15])}\n",
        "CANDIDATE EXPERIENCE: {len(resume_data['experience'])} roles\n",
        "\n",
        "JOB DESCRIPTION:\n",
        "{job_description[:1000]}\n",
        "\n",
        "Write a concise, professional cover letter (250-300 words) that:\n",
        "1. Opens with enthusiasm for the role\n",
        "2. Highlights 2-3 most relevant skills/experiences\n",
        "3. Shows understanding of the company's needs\n",
        "4. Closes with a call to action\n",
        "\n",
        "Use a professional but warm tone. Do not include placeholder fields like [Your Name].\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = groq_client.chat.completions.create(\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            model=\"llama-3.3-70b-versatile\",\n",
        "            max_tokens=500,\n",
        "            temperature=0.7\n",
        "        )\n",
        "        cover_letter = response.choices[0].message.content\n",
        "        print(\"‚úÖ Cover letter generated!\")\n",
        "        return cover_letter\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Cover letter generation failed: {str(e)}\")\n",
        "        return \"Cover letter generation unavailable.\"\n",
        "\n",
        "\n",
        "def complete_job_match_analysis(resume_data: Dict, job_description: str) -> Dict:\n",
        "    \"\"\"\n",
        "    Main function for complete job matching analysis.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"üéØ JOB MATCH ANALYSIS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Step 1: Extract job requirements\n",
        "    job_requirements = extract_job_requirements(job_description)\n",
        "\n",
        "    # Step 2: Calculate match score\n",
        "    match_score = calculate_match_score(resume_data, job_requirements)\n",
        "\n",
        "    # Step 3: Generate detailed report with Gemini\n",
        "    gemini_report = generate_job_match_report_with_gemini(resume_data, job_description, match_score)\n",
        "\n",
        "    # Step 4: Generate cover letter with Groq\n",
        "    cover_letter = generate_tailored_cover_letter(resume_data, job_description)\n",
        "\n",
        "    print(\"\\n‚úÖ Complete job match analysis ready!\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    return {\n",
        "        'match_score': match_score['total_score'],\n",
        "        'match_percentage': match_score['percentage'],\n",
        "        'match_grade': match_score['grade'],\n",
        "        'breakdown': match_score['breakdown'],\n",
        "        'gemini_report': gemini_report,\n",
        "        'cover_letter': cover_letter,\n",
        "        'missing_skills': match_score['breakdown']['skills']['missing'],\n",
        "        'matching_skills': match_score['breakdown']['skills']['matching']\n",
        "    }\n",
        "\n",
        "\n",
        "# Test message\n",
        "print(\"=\" * 60)\n",
        "print(\"üéØ Job Description Matcher Ready!\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\n‚ú® Functions created:\")\n",
        "print(\"   ‚Ä¢ extract_job_requirements() - Extracts key job requirements\")\n",
        "print(\"   ‚Ä¢ calculate_match_score() - Scores resume vs JD (0-100)\")\n",
        "print(\"   ‚Ä¢ generate_job_match_report_with_gemini() - Detailed AI analysis\")\n",
        "print(\"   ‚Ä¢ generate_tailored_cover_letter() - Auto cover letter with Groq\")\n",
        "print(\"   ‚Ä¢ complete_job_match_analysis() - Main matching function\")\n",
        "print(\"\\nüí° Ready to match resumes with job descriptions!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swho0USddyMK",
        "outputId": "8975c49e-2e6e-40e9-f959-7d6b419fac08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "üé§ Interview Question Generator Ready!\n",
            "============================================================\n",
            "\n",
            "‚ú® Functions created:\n",
            "   ‚Ä¢ generate_technical_questions() - Technical/coding questions\n",
            "   ‚Ä¢ generate_behavioral_questions() - STAR method questions\n",
            "   ‚Ä¢ generate_situational_questions() - Scenario-based questions\n",
            "   ‚Ä¢ generate_resume_based_questions() - Personalized questions\n",
            "   ‚Ä¢ generate_complete_interview_set() - Full interview generation\n",
            "\n",
            "üí° Supports 4 interview types: Technical, Behavioral, Mixed, Full\n",
            "üí° 3 difficulty levels: Easy, Medium, Hard\n",
            "\n",
            "üöÄ Ready to generate interview questions!\n"
          ]
        }
      ],
      "source": [
        "# Cell 7: Interview Question Generator with Groq\n",
        "\n",
        "def generate_technical_questions(resume_data: Dict, difficulty: str = \"Medium\", num_questions: int = 5) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Generate technical interview questions based on candidate's skills.\n",
        "    Uses Groq for fast generation.\n",
        "    \"\"\"\n",
        "    print(f\"\\nüíª Generating {num_questions} {difficulty} technical questions...\")\n",
        "\n",
        "    skills_list = ', '.join(resume_data['skills'][:10])\n",
        "\n",
        "    prompt = f\"\"\"You are an expert technical interviewer. Generate {num_questions} {difficulty} difficulty technical interview questions.\n",
        "\n",
        "CANDIDATE'S SKILLS: {skills_list}\n",
        "\n",
        "REQUIREMENTS:\n",
        "- Questions should test the candidate's knowledge of their listed skills\n",
        "- {difficulty} difficulty level\n",
        "- Include a mix of conceptual and practical questions\n",
        "- Each question should be clear and specific\n",
        "\n",
        "FORMAT (return exactly {num_questions} questions):\n",
        "Q1: [Question text]\n",
        "Expected Answer: [Brief expected answer]\n",
        "Follow-up: [One follow-up question]\n",
        "\n",
        "Q2: [Question text]\n",
        "Expected Answer: [Brief expected answer]\n",
        "Follow-up: [One follow-up question]\n",
        "\n",
        "Continue for all {num_questions} questions.\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = groq_client.chat.completions.create(\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            model=\"llama-3.3-70b-versatile\",\n",
        "            max_tokens=1500,\n",
        "            temperature=0.8\n",
        "        )\n",
        "\n",
        "        questions_text = response.choices[0].message.content\n",
        "\n",
        "        # Parse the response into structured format\n",
        "        questions = []\n",
        "        question_blocks = questions_text.split('\\n\\n')\n",
        "\n",
        "        for i, block in enumerate(question_blocks[:num_questions], 1):\n",
        "            if block.strip():\n",
        "                questions.append({\n",
        "                    'id': i,\n",
        "                    'type': 'Technical',\n",
        "                    'difficulty': difficulty,\n",
        "                    'question': block.strip(),\n",
        "                    'category': 'Programming' if any(s in skills_list.lower() for s in ['python', 'java', 'javascript']) else 'Technical'\n",
        "                })\n",
        "\n",
        "        print(f\"‚úÖ Generated {len(questions)} technical questions\")\n",
        "        return questions\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Question generation failed: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "\n",
        "def generate_behavioral_questions(num_questions: int = 5) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Generate behavioral/HR interview questions.\n",
        "    \"\"\"\n",
        "    print(f\"\\nü§ù Generating {num_questions} behavioral questions...\")\n",
        "\n",
        "    prompt = f\"\"\"You are an HR interviewer. Generate {num_questions} behavioral interview questions using the STAR method (Situation, Task, Action, Result).\n",
        "\n",
        "REQUIREMENTS:\n",
        "- Questions should assess soft skills, teamwork, problem-solving, and leadership\n",
        "- Use behavioral interview format\n",
        "- Each question should elicit specific examples from past experiences\n",
        "\n",
        "FORMAT (return exactly {num_questions} questions):\n",
        "Q1: [Question text]\n",
        "What to listen for: [Key points in the answer]\n",
        "\n",
        "Q2: [Question text]\n",
        "What to listen for: [Key points in the answer]\n",
        "\n",
        "Continue for all {num_questions} questions.\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = groq_client.chat.completions.create(\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            model=\"llama-3.3-70b-versatile\",\n",
        "            max_tokens=1000,\n",
        "            temperature=0.7\n",
        "        )\n",
        "\n",
        "        questions_text = response.choices[0].message.content\n",
        "\n",
        "        # Parse into structured format\n",
        "        questions = []\n",
        "        question_blocks = questions_text.split('\\n\\n')\n",
        "\n",
        "        for i, block in enumerate(question_blocks[:num_questions], 1):\n",
        "            if block.strip():\n",
        "                questions.append({\n",
        "                    'id': i,\n",
        "                    'type': 'Behavioral',\n",
        "                    'difficulty': 'Medium',\n",
        "                    'question': block.strip(),\n",
        "                    'category': 'Soft Skills'\n",
        "                })\n",
        "\n",
        "        print(f\"‚úÖ Generated {len(questions)} behavioral questions\")\n",
        "        return questions\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Question generation failed: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "\n",
        "def generate_situational_questions(resume_data: Dict, num_questions: int = 3) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Generate situational/scenario-based questions.\n",
        "    \"\"\"\n",
        "    print(f\"\\nüéØ Generating {num_questions} situational questions...\")\n",
        "\n",
        "    experience_count = len(resume_data['experience'])\n",
        "\n",
        "    prompt = f\"\"\"You are an interviewer creating scenario-based questions. Generate {num_questions} situational interview questions.\n",
        "\n",
        "CANDIDATE BACKGROUND:\n",
        "- Experience level: {experience_count} roles\n",
        "- Skills: {', '.join(resume_data['skills'][:8])}\n",
        "\n",
        "REQUIREMENTS:\n",
        "- Present hypothetical workplace scenarios\n",
        "- Test decision-making and problem-solving\n",
        "- Relevant to the candidate's experience level\n",
        "- Should have multiple valid approaches\n",
        "\n",
        "FORMAT (return exactly {num_questions} questions):\n",
        "Q1: [Scenario and question]\n",
        "Evaluation criteria: [What makes a good answer]\n",
        "\n",
        "Q2: [Scenario and question]\n",
        "Evaluation criteria: [What makes a good answer]\n",
        "\n",
        "Continue for all {num_questions} questions.\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = groq_client.chat.completions.create(\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            model=\"llama-3.3-70b-versatile\",\n",
        "            max_tokens=1000,\n",
        "            temperature=0.8\n",
        "        )\n",
        "\n",
        "        questions_text = response.choices[0].message.content\n",
        "\n",
        "        # Parse into structured format\n",
        "        questions = []\n",
        "        question_blocks = questions_text.split('\\n\\n')\n",
        "\n",
        "        for i, block in enumerate(question_blocks[:num_questions], 1):\n",
        "            if block.strip():\n",
        "                questions.append({\n",
        "                    'id': i,\n",
        "                    'type': 'Situational',\n",
        "                    'difficulty': 'Medium',\n",
        "                    'question': block.strip(),\n",
        "                    'category': 'Problem Solving'\n",
        "                })\n",
        "\n",
        "        print(f\"‚úÖ Generated {len(questions)} situational questions\")\n",
        "        return questions\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Question generation failed: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "\n",
        "def generate_resume_based_questions(resume_data: Dict, num_questions: int = 4) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Generate questions specifically based on resume content.\n",
        "    This makes the interview more personalized!\n",
        "    \"\"\"\n",
        "    print(f\"\\nüìÑ Generating {num_questions} resume-based questions...\")\n",
        "\n",
        "    # Get key info from resume\n",
        "    skills = ', '.join(resume_data['skills'][:10])\n",
        "    experience_summary = \"\"\n",
        "    if resume_data['experience']:\n",
        "        for exp in resume_data['experience'][:3]:\n",
        "            experience_summary += f\"- {exp['title']}\\n\"\n",
        "\n",
        "    prompt = f\"\"\"You are an interviewer reviewing this candidate's resume. Generate {num_questions} specific questions based on their resume.\n",
        "\n",
        "RESUME HIGHLIGHTS:\n",
        "Skills: {skills}\n",
        "Experience:\n",
        "{experience_summary}\n",
        "\n",
        "REQUIREMENTS:\n",
        "- Ask about specific skills they mentioned\n",
        "- Probe into their experience claims\n",
        "- Ask them to explain or demonstrate their expertise\n",
        "- Questions should be personalized to THIS resume\n",
        "\n",
        "FORMAT (return exactly {num_questions} questions):\n",
        "Q1: [Specific question about their resume]\n",
        "Why this question: [Brief reasoning]\n",
        "\n",
        "Q2: [Specific question about their resume]\n",
        "Why this question: [Brief reasoning]\n",
        "\n",
        "Continue for all {num_questions} questions.\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = groq_client.chat.completions.create(\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            model=\"llama-3.3-70b-versatile\",\n",
        "            max_tokens=1000,\n",
        "            temperature=0.7\n",
        "        )\n",
        "\n",
        "        questions_text = response.choices[0].message.content\n",
        "\n",
        "        # Parse into structured format\n",
        "        questions = []\n",
        "        question_blocks = questions_text.split('\\n\\n')\n",
        "\n",
        "        for i, block in enumerate(question_blocks[:num_questions], 1):\n",
        "            if block.strip():\n",
        "                questions.append({\n",
        "                    'id': i,\n",
        "                    'type': 'Resume-Based',\n",
        "                    'difficulty': 'Medium',\n",
        "                    'question': block.strip(),\n",
        "                    'category': 'Experience'\n",
        "                })\n",
        "\n",
        "        print(f\"‚úÖ Generated {len(questions)} resume-based questions\")\n",
        "        return questions\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Question generation failed: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "\n",
        "def generate_complete_interview_set(resume_data: Dict, interview_type: str = \"Full\", difficulty: str = \"Medium\") -> Dict:\n",
        "    \"\"\"\n",
        "    Main function to generate a complete set of interview questions.\n",
        "\n",
        "    interview_type options: \"Technical\", \"Behavioral\", \"Mixed\", \"Full\"\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(f\"üé§ GENERATING {interview_type.upper()} INTERVIEW QUESTIONS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    all_questions = []\n",
        "\n",
        "    if interview_type == \"Technical\":\n",
        "        all_questions.extend(generate_technical_questions(resume_data, difficulty, 8))\n",
        "        all_questions.extend(generate_resume_based_questions(resume_data, 3))\n",
        "\n",
        "    elif interview_type == \"Behavioral\":\n",
        "        all_questions.extend(generate_behavioral_questions(7))\n",
        "        all_questions.extend(generate_situational_questions(resume_data, 4))\n",
        "\n",
        "    elif interview_type == \"Mixed\":\n",
        "        all_questions.extend(generate_technical_questions(resume_data, difficulty, 4))\n",
        "        all_questions.extend(generate_behavioral_questions(3))\n",
        "        all_questions.extend(generate_resume_based_questions(resume_data, 2))\n",
        "\n",
        "    else:  # Full interview\n",
        "        all_questions.extend(generate_technical_questions(resume_data, difficulty, 5))\n",
        "        all_questions.extend(generate_behavioral_questions(4))\n",
        "        all_questions.extend(generate_situational_questions(resume_data, 3))\n",
        "        all_questions.extend(generate_resume_based_questions(resume_data, 3))\n",
        "\n",
        "    print(f\"\\n‚úÖ Total questions generated: {len(all_questions)}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    return {\n",
        "        'interview_type': interview_type,\n",
        "        'difficulty': difficulty,\n",
        "        'total_questions': len(all_questions),\n",
        "        'questions': all_questions,\n",
        "        'question_types': {\n",
        "            'Technical': len([q for q in all_questions if q['type'] == 'Technical']),\n",
        "            'Behavioral': len([q for q in all_questions if q['type'] == 'Behavioral']),\n",
        "            'Situational': len([q for q in all_questions if q['type'] == 'Situational']),\n",
        "            'Resume-Based': len([q for q in all_questions if q['type'] == 'Resume-Based'])\n",
        "        }\n",
        "    }\n",
        "\n",
        "\n",
        "# Test message\n",
        "print(\"=\" * 60)\n",
        "print(\"üé§ Interview Question Generator Ready!\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\n‚ú® Functions created:\")\n",
        "print(\"   ‚Ä¢ generate_technical_questions() - Technical/coding questions\")\n",
        "print(\"   ‚Ä¢ generate_behavioral_questions() - STAR method questions\")\n",
        "print(\"   ‚Ä¢ generate_situational_questions() - Scenario-based questions\")\n",
        "print(\"   ‚Ä¢ generate_resume_based_questions() - Personalized questions\")\n",
        "print(\"   ‚Ä¢ generate_complete_interview_set() - Full interview generation\")\n",
        "print(\"\\nüí° Supports 4 interview types: Technical, Behavioral, Mixed, Full\")\n",
        "print(\"üí° 3 difficulty levels: Easy, Medium, Hard\")\n",
        "print(\"\\nüöÄ Ready to generate interview questions!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RO8vr0aeUdz",
        "outputId": "da2dd4a7-9b71-44c2-82cd-0afc3c1e2989"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "‚öñÔ∏è Answer Evaluator & Feedback System Ready!\n",
            "============================================================\n",
            "\n",
            "‚ú® Functions created:\n",
            "   ‚Ä¢ evaluate_answer_with_groq() - Scores answers on 5 criteria\n",
            "   ‚Ä¢ generate_follow_up_question() - Dynamic follow-ups\n",
            "   ‚Ä¢ analyze_answer_sentiment() - Confidence level analysis\n",
            "   ‚Ä¢ conduct_mock_interview() - Complete interview evaluation\n",
            "   ‚Ä¢ generate_improvement_plan() - Personalized coaching\n",
            "\n",
            "üìä Scoring Criteria:\n",
            "   1. Relevance (0-10)\n",
            "   2. Technical Accuracy (0-10)\n",
            "   3. Communication (0-10)\n",
            "   4. Depth (0-10)\n",
            "   5. Completeness (0-10)\n",
            "   Total: 0-50 points ‚Üí Converted to percentage & grade\n",
            "\n",
            "üöÄ Ready to evaluate interview answers!\n"
          ]
        }
      ],
      "source": [
        "# Cell 8: Answer Evaluator & Feedback System\n",
        "\n",
        "def evaluate_answer_with_groq(question: str, answer: str, question_type: str) -> Dict:\n",
        "    \"\"\"\n",
        "    Evaluate an interview answer using Groq's fast inference.\n",
        "    Provides scoring on multiple criteria.\n",
        "    \"\"\"\n",
        "    print(f\"\\n‚öñÔ∏è Evaluating {question_type} answer...\")\n",
        "\n",
        "    prompt = f\"\"\"You are an expert interview evaluator. Evaluate this candidate's answer.\n",
        "\n",
        "QUESTION TYPE: {question_type}\n",
        "QUESTION: {question}\n",
        "\n",
        "CANDIDATE'S ANSWER:\n",
        "{answer}\n",
        "\n",
        "Evaluate the answer on these 5 criteria (score each 0-10):\n",
        "\n",
        "1. RELEVANCE (0-10): How well does the answer address the question?\n",
        "2. TECHNICAL ACCURACY (0-10): Is the information correct and accurate?\n",
        "3. COMMUNICATION (0-10): Is the answer clear, well-structured, and articulate?\n",
        "4. DEPTH (0-10): Does the answer show deep understanding or just surface knowledge?\n",
        "5. COMPLETENESS (0-10): Does the answer cover all aspects of the question?\n",
        "\n",
        "Provide your evaluation in this EXACT format:\n",
        "RELEVANCE: [score]/10\n",
        "TECHNICAL_ACCURACY: [score]/10\n",
        "COMMUNICATION: [score]/10\n",
        "DEPTH: [score]/10\n",
        "COMPLETENESS: [score]/10\n",
        "\n",
        "TOTAL_SCORE: [sum]/50\n",
        "\n",
        "STRENGTHS:\n",
        "- [strength 1]\n",
        "- [strength 2]\n",
        "\n",
        "WEAKNESSES:\n",
        "- [weakness 1]\n",
        "- [weakness 2]\n",
        "\n",
        "IMPROVED_ANSWER:\n",
        "[Provide a better version of the answer in 2-3 sentences]\n",
        "\n",
        "FEEDBACK:\n",
        "[2-3 sentences of constructive feedback]\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = groq_client.chat.completions.create(\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            model=\"llama-3.3-70b-versatile\",\n",
        "            max_tokens=800,\n",
        "            temperature=0.3  # Lower temperature for consistent scoring\n",
        "        )\n",
        "\n",
        "        evaluation_text = response.choices[0].message.content\n",
        "\n",
        "        # Parse scores from response\n",
        "        scores = {}\n",
        "        try:\n",
        "            relevance = re.search(r'RELEVANCE:\\s*(\\d+)', evaluation_text)\n",
        "            technical = re.search(r'TECHNICAL_ACCURACY:\\s*(\\d+)', evaluation_text)\n",
        "            communication = re.search(r'COMMUNICATION:\\s*(\\d+)', evaluation_text)\n",
        "            depth = re.search(r'DEPTH:\\s*(\\d+)', evaluation_text)\n",
        "            completeness = re.search(r'COMPLETENESS:\\s*(\\d+)', evaluation_text)\n",
        "\n",
        "            scores = {\n",
        "                'relevance': int(relevance.group(1)) if relevance else 5,\n",
        "                'technical_accuracy': int(technical.group(1)) if technical else 5,\n",
        "                'communication': int(communication.group(1)) if communication else 5,\n",
        "                'depth': int(depth.group(1)) if depth else 5,\n",
        "                'completeness': int(completeness.group(1)) if completeness else 5\n",
        "            }\n",
        "\n",
        "            scores['total'] = sum(scores.values())\n",
        "            scores['percentage'] = round((scores['total'] / 50) * 100, 1)\n",
        "\n",
        "        except:\n",
        "            # Fallback scores if parsing fails\n",
        "            scores = {\n",
        "                'relevance': 7,\n",
        "                'technical_accuracy': 7,\n",
        "                'communication': 7,\n",
        "                'depth': 6,\n",
        "                'completeness': 7,\n",
        "                'total': 34,\n",
        "                'percentage': 68.0\n",
        "            }\n",
        "\n",
        "        print(f\"‚úÖ Answer evaluated: {scores['total']}/50 ({scores['percentage']}%)\")\n",
        "\n",
        "        return {\n",
        "            'success': True,\n",
        "            'scores': scores,\n",
        "            'full_evaluation': evaluation_text,\n",
        "            'grade': get_grade(scores['percentage'])\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Evaluation failed: {str(e)}\")\n",
        "        return {\n",
        "            'success': False,\n",
        "            'scores': {'total': 0, 'percentage': 0},\n",
        "            'full_evaluation': \"Evaluation unavailable.\",\n",
        "            'grade': 'N/A'\n",
        "        }\n",
        "\n",
        "\n",
        "def get_grade(percentage: float) -> str:\n",
        "    \"\"\"Convert percentage to letter grade.\"\"\"\n",
        "    if percentage >= 90:\n",
        "        return 'A+ (Excellent)'\n",
        "    elif percentage >= 80:\n",
        "        return 'A (Very Good)'\n",
        "    elif percentage >= 70:\n",
        "        return 'B (Good)'\n",
        "    elif percentage >= 60:\n",
        "        return 'C (Fair)'\n",
        "    elif percentage >= 50:\n",
        "        return 'D (Below Average)'\n",
        "    else:\n",
        "        return 'F (Poor)'\n",
        "\n",
        "\n",
        "def generate_follow_up_question(question: str, answer: str, question_type: str) -> str:\n",
        "    \"\"\"\n",
        "    Generate an intelligent follow-up question based on the answer.\n",
        "    This makes the interview more dynamic!\n",
        "    \"\"\"\n",
        "    print(\"\\nüîÑ Generating follow-up question...\")\n",
        "\n",
        "    prompt = f\"\"\"You are an interviewer. Based on the candidate's answer, generate ONE intelligent follow-up question.\n",
        "\n",
        "ORIGINAL QUESTION ({question_type}):\n",
        "{question}\n",
        "\n",
        "CANDIDATE'S ANSWER:\n",
        "{answer}\n",
        "\n",
        "Generate a follow-up question that:\n",
        "- Probes deeper into their answer\n",
        "- Tests their understanding further\n",
        "- Is relevant to what they just said\n",
        "- Is concise (1-2 sentences)\n",
        "\n",
        "Return ONLY the follow-up question, nothing else.\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = groq_client.chat.completions.create(\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            model=\"llama-3.3-70b-versatile\",\n",
        "            max_tokens=150,\n",
        "            temperature=0.7\n",
        "        )\n",
        "\n",
        "        follow_up = response.choices[0].message.content.strip()\n",
        "        print(f\"‚úÖ Follow-up generated\")\n",
        "        return follow_up\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Follow-up generation failed: {str(e)}\")\n",
        "        return \"Can you elaborate more on that point?\"\n",
        "\n",
        "\n",
        "def analyze_answer_sentiment(answer: str) -> Dict:\n",
        "    \"\"\"\n",
        "    Quick sentiment analysis of the answer (confidence level).\n",
        "    \"\"\"\n",
        "    answer_lower = answer.lower()\n",
        "\n",
        "    # Confidence indicators\n",
        "    confident_words = ['definitely', 'certainly', 'confident', 'sure', 'absolutely',\n",
        "                      'experienced', 'skilled', 'proficient', 'expert']\n",
        "    uncertain_words = ['maybe', 'perhaps', 'not sure', 'think', 'guess',\n",
        "                      'probably', 'might', 'possibly']\n",
        "\n",
        "    confident_count = sum(1 for word in confident_words if word in answer_lower)\n",
        "    uncertain_count = sum(1 for word in uncertain_words if word in answer_lower)\n",
        "\n",
        "    # Calculate confidence score\n",
        "    word_count = len(answer.split())\n",
        "\n",
        "    if confident_count > uncertain_count:\n",
        "        confidence = \"High\"\n",
        "        confidence_score = min(90, 70 + (confident_count * 5))\n",
        "    elif uncertain_count > confident_count:\n",
        "        confidence = \"Low\"\n",
        "        confidence_score = max(40, 60 - (uncertain_count * 5))\n",
        "    else:\n",
        "        confidence = \"Moderate\"\n",
        "        confidence_score = 65\n",
        "\n",
        "    return {\n",
        "        'confidence_level': confidence,\n",
        "        'confidence_score': confidence_score,\n",
        "        'answer_length': word_count,\n",
        "        'is_detailed': word_count >= 50\n",
        "    }\n",
        "\n",
        "\n",
        "def conduct_mock_interview(resume_data: Dict, questions: List[Dict], answers: List[str]) -> Dict:\n",
        "    \"\"\"\n",
        "    Main function to conduct and evaluate a complete mock interview.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"üé§ CONDUCTING MOCK INTERVIEW EVALUATION\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    interview_results = []\n",
        "    total_score = 0\n",
        "    total_possible = 0\n",
        "\n",
        "    for i, (question_obj, answer) in enumerate(zip(questions, answers), 1):\n",
        "        print(f\"\\nüìù Evaluating Question {i}/{len(questions)}...\")\n",
        "\n",
        "        question = question_obj['question']\n",
        "        question_type = question_obj['type']\n",
        "\n",
        "        # Evaluate the answer\n",
        "        evaluation = evaluate_answer_with_groq(question, answer, question_type)\n",
        "\n",
        "        # Analyze sentiment\n",
        "        sentiment = analyze_answer_sentiment(answer)\n",
        "\n",
        "        # Generate follow-up (optional, for interactive mode)\n",
        "        # follow_up = generate_follow_up_question(question, answer, question_type)\n",
        "\n",
        "        result = {\n",
        "            'question_number': i,\n",
        "            'question': question,\n",
        "            'question_type': question_type,\n",
        "            'answer': answer,\n",
        "            'evaluation': evaluation,\n",
        "            'sentiment': sentiment,\n",
        "            'scores': evaluation['scores'],\n",
        "            'grade': evaluation['grade']\n",
        "        }\n",
        "\n",
        "        interview_results.append(result)\n",
        "\n",
        "        if evaluation['success']:\n",
        "            total_score += evaluation['scores']['total']\n",
        "            total_possible += 50\n",
        "\n",
        "    # Calculate overall performance\n",
        "    overall_percentage = round((total_score / total_possible * 100), 1) if total_possible > 0 else 0\n",
        "\n",
        "    # Identify strengths and weaknesses\n",
        "    strengths = []\n",
        "    weaknesses = []\n",
        "\n",
        "    for result in interview_results:\n",
        "        if result['evaluation']['success']:\n",
        "            scores = result['scores']\n",
        "            if scores['total'] >= 40:\n",
        "                strengths.append(result['question_type'])\n",
        "            elif scores['total'] < 30:\n",
        "                weaknesses.append(result['question_type'])\n",
        "\n",
        "    print(f\"\\n‚úÖ Interview evaluation complete!\")\n",
        "    print(f\"   Overall Score: {total_score}/{total_possible} ({overall_percentage}%)\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    return {\n",
        "        'total_questions': len(questions),\n",
        "        'total_answered': len(answers),\n",
        "        'total_score': total_score,\n",
        "        'total_possible': total_possible,\n",
        "        'overall_percentage': overall_percentage,\n",
        "        'overall_grade': get_grade(overall_percentage),\n",
        "        'results': interview_results,\n",
        "        'strengths': list(set(strengths)),\n",
        "        'weaknesses': list(set(weaknesses)),\n",
        "        'average_confidence': sum(r['sentiment']['confidence_score'] for r in interview_results) / len(interview_results) if interview_results else 0\n",
        "    }\n",
        "\n",
        "\n",
        "def generate_improvement_plan(interview_results: Dict) -> str:\n",
        "    \"\"\"\n",
        "    Generate a personalized improvement plan based on interview performance.\n",
        "    \"\"\"\n",
        "    print(\"\\nüìà Generating improvement plan...\")\n",
        "\n",
        "    weaknesses = ', '.join(interview_results['weaknesses']) if interview_results['weaknesses'] else \"No major weaknesses\"\n",
        "    strengths = ', '.join(interview_results['strengths']) if interview_results['strengths'] else \"Various areas\"\n",
        "\n",
        "    prompt = f\"\"\"You are a career coach. Create a personalized improvement plan for this candidate.\n",
        "\n",
        "INTERVIEW PERFORMANCE:\n",
        "- Overall Score: {interview_results['overall_percentage']}%\n",
        "- Total Questions: {interview_results['total_questions']}\n",
        "- Strengths: {strengths}\n",
        "- Weaknesses: {weaknesses}\n",
        "- Average Confidence: {interview_results['average_confidence']:.1f}%\n",
        "\n",
        "Create a focused improvement plan with:\n",
        "1. TOP 3 PRIORITY AREAS (what to focus on first)\n",
        "2. SPECIFIC ACTION ITEMS (5-6 concrete steps)\n",
        "3. PRACTICE RECOMMENDATIONS (what to practice daily)\n",
        "4. TIMELINE (suggested 2-week plan)\n",
        "\n",
        "Be specific, actionable, and encouraging.\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = groq_client.chat.completions.create(\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            model=\"llama-3.3-70b-versatile\",\n",
        "            max_tokens=800,\n",
        "            temperature=0.7\n",
        "        )\n",
        "\n",
        "        improvement_plan = response.choices[0].message.content\n",
        "        print(\"‚úÖ Improvement plan generated!\")\n",
        "        return improvement_plan\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Plan generation failed: {str(e)}\")\n",
        "        return \"Improvement plan unavailable.\"\n",
        "\n",
        "\n",
        "# Test message\n",
        "print(\"=\" * 60)\n",
        "print(\"‚öñÔ∏è Answer Evaluator & Feedback System Ready!\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\n‚ú® Functions created:\")\n",
        "print(\"   ‚Ä¢ evaluate_answer_with_groq() - Scores answers on 5 criteria\")\n",
        "print(\"   ‚Ä¢ generate_follow_up_question() - Dynamic follow-ups\")\n",
        "print(\"   ‚Ä¢ analyze_answer_sentiment() - Confidence level analysis\")\n",
        "print(\"   ‚Ä¢ conduct_mock_interview() - Complete interview evaluation\")\n",
        "print(\"   ‚Ä¢ generate_improvement_plan() - Personalized coaching\")\n",
        "print(\"\\nüìä Scoring Criteria:\")\n",
        "print(\"   1. Relevance (0-10)\")\n",
        "print(\"   2. Technical Accuracy (0-10)\")\n",
        "print(\"   3. Communication (0-10)\")\n",
        "print(\"   4. Depth (0-10)\")\n",
        "print(\"   5. Completeness (0-10)\")\n",
        "print(\"   Total: 0-50 points ‚Üí Converted to percentage & grade\")\n",
        "print(\"\\nüöÄ Ready to evaluate interview answers!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nM7tA5_kelBT",
        "outputId": "21efbe24-dc63-4ad7-e47b-8a9939f47328"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Session initialized\n",
            "============================================================\n",
            "üõ†Ô∏è Helper Functions & Utilities Ready!\n",
            "============================================================\n",
            "\n",
            "‚ú® Functions created:\n",
            "   ‚Ä¢ Session Management:\n",
            "     - initialize_session()\n",
            "     - save_resume_data()\n",
            "     - save_job_match()\n",
            "     - save_interview_results()\n",
            "     - get_session_summary()\n",
            "\n",
            "   ‚Ä¢ Analytics:\n",
            "     - calculate_performance_trends()\n",
            "     - analyze_question_type_performance()\n",
            "     - create_performance_chart_data()\n",
            "\n",
            "   ‚Ä¢ Export:\n",
            "     - export_session_data_to_json()\n",
            "     - generate_text_report()\n",
            "\n",
            "   ‚Ä¢ Formatting:\n",
            "     - format_percentage()\n",
            "     - format_score_badge()\n",
            "     - get_motivational_message()\n",
            "\n",
            "üíæ Session tracking enabled!\n",
            "üìä Analytics ready!\n",
            "üìÑ Report generation ready!\n"
          ]
        }
      ],
      "source": [
        "# Cell 9: Helper Functions & Utilities\n",
        "\n",
        "import json\n",
        "from datetime import datetime\n",
        "from typing import Optional\n",
        "\n",
        "# Global session storage\n",
        "SESSION_DATA = {\n",
        "    'resume_data': None,\n",
        "    'resume_analysis': None,\n",
        "    'job_match_analysis': None,\n",
        "    'interview_history': [],\n",
        "    'current_interview': None,\n",
        "    'user_profile': {\n",
        "        'name': 'Candidate',\n",
        "        'sessions_completed': 0,\n",
        "        'total_questions_answered': 0,\n",
        "        'average_score': 0\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "def initialize_session():\n",
        "    \"\"\"Initialize or reset session data.\"\"\"\n",
        "    global SESSION_DATA\n",
        "    SESSION_DATA = {\n",
        "        'resume_data': None,\n",
        "        'resume_analysis': None,\n",
        "        'job_match_analysis': None,\n",
        "        'interview_history': [],\n",
        "        'current_interview': None,\n",
        "        'user_profile': {\n",
        "            'name': 'Candidate',\n",
        "            'sessions_completed': 0,\n",
        "            'total_questions_answered': 0,\n",
        "            'average_score': 0\n",
        "        }\n",
        "    }\n",
        "    print(\"‚úÖ Session initialized\")\n",
        "\n",
        "\n",
        "def save_resume_data(resume_data: Dict, analysis: Dict):\n",
        "    \"\"\"Save resume data and analysis to session.\"\"\"\n",
        "    SESSION_DATA['resume_data'] = resume_data\n",
        "    SESSION_DATA['resume_analysis'] = analysis\n",
        "    print(\"‚úÖ Resume data saved to session\")\n",
        "\n",
        "\n",
        "def save_job_match(job_match_analysis: Dict):\n",
        "    \"\"\"Save job match analysis to session.\"\"\"\n",
        "    SESSION_DATA['job_match_analysis'] = job_match_analysis\n",
        "    print(\"‚úÖ Job match analysis saved to session\")\n",
        "\n",
        "\n",
        "def save_interview_results(interview_results: Dict):\n",
        "    \"\"\"Save interview results to history.\"\"\"\n",
        "    interview_record = {\n",
        "        'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "        'interview_type': interview_results.get('interview_type', 'Mixed'),\n",
        "        'total_questions': interview_results['total_questions'],\n",
        "        'overall_score': interview_results['overall_percentage'],\n",
        "        'grade': interview_results['overall_grade'],\n",
        "        'results': interview_results['results']\n",
        "    }\n",
        "\n",
        "    SESSION_DATA['interview_history'].append(interview_record)\n",
        "    SESSION_DATA['user_profile']['sessions_completed'] += 1\n",
        "    SESSION_DATA['user_profile']['total_questions_answered'] += interview_results['total_questions']\n",
        "\n",
        "    # Update average score\n",
        "    all_scores = [record['overall_score'] for record in SESSION_DATA['interview_history']]\n",
        "    SESSION_DATA['user_profile']['average_score'] = round(sum(all_scores) / len(all_scores), 1)\n",
        "\n",
        "    print(f\"‚úÖ Interview results saved (Session #{SESSION_DATA['user_profile']['sessions_completed']})\")\n",
        "\n",
        "\n",
        "def get_session_summary() -> Dict:\n",
        "    \"\"\"Get summary of current session.\"\"\"\n",
        "    return {\n",
        "        'has_resume': SESSION_DATA['resume_data'] is not None,\n",
        "        'has_analysis': SESSION_DATA['resume_analysis'] is not None,\n",
        "        'has_job_match': SESSION_DATA['job_match_analysis'] is not None,\n",
        "        'total_interviews': len(SESSION_DATA['interview_history']),\n",
        "        'user_profile': SESSION_DATA['user_profile']\n",
        "    }\n",
        "\n",
        "\n",
        "def calculate_performance_trends() -> Dict:\n",
        "    \"\"\"Calculate performance trends across interview sessions.\"\"\"\n",
        "    if not SESSION_DATA['interview_history']:\n",
        "        return {\n",
        "            'trend': 'No data',\n",
        "            'improvement': 0,\n",
        "            'scores': []\n",
        "        }\n",
        "\n",
        "    scores = [record['overall_score'] for record in SESSION_DATA['interview_history']]\n",
        "\n",
        "    if len(scores) < 2:\n",
        "        return {\n",
        "            'trend': 'Insufficient data',\n",
        "            'improvement': 0,\n",
        "            'scores': scores\n",
        "        }\n",
        "\n",
        "    # Calculate improvement\n",
        "    first_score = scores[0]\n",
        "    last_score = scores[-1]\n",
        "    improvement = last_score - first_score\n",
        "\n",
        "    # Determine trend\n",
        "    if improvement > 10:\n",
        "        trend = \"Strong Improvement üìà\"\n",
        "    elif improvement > 0:\n",
        "        trend = \"Slight Improvement üìä\"\n",
        "    elif improvement == 0:\n",
        "        trend = \"Stable Performance ‚û°Ô∏è\"\n",
        "    elif improvement > -10:\n",
        "        trend = \"Slight Decline üìâ\"\n",
        "    else:\n",
        "        trend = \"Needs Attention ‚ö†Ô∏è\"\n",
        "\n",
        "    return {\n",
        "        'trend': trend,\n",
        "        'improvement': round(improvement, 1),\n",
        "        'scores': scores,\n",
        "        'first_score': first_score,\n",
        "        'last_score': last_score\n",
        "    }\n",
        "\n",
        "\n",
        "def analyze_question_type_performance() -> Dict:\n",
        "    \"\"\"Analyze performance by question type.\"\"\"\n",
        "    if not SESSION_DATA['interview_history']:\n",
        "        return {}\n",
        "\n",
        "    type_scores = {\n",
        "        'Technical': [],\n",
        "        'Behavioral': [],\n",
        "        'Situational': [],\n",
        "        'Resume-Based': []\n",
        "    }\n",
        "\n",
        "    for interview in SESSION_DATA['interview_history']:\n",
        "        for result in interview['results']:\n",
        "            q_type = result['question_type']\n",
        "            if q_type in type_scores and result['evaluation']['success']:\n",
        "                score = result['scores']['percentage']\n",
        "                type_scores[q_type].append(score)\n",
        "\n",
        "    # Calculate averages\n",
        "    avg_scores = {}\n",
        "    for q_type, scores in type_scores.items():\n",
        "        if scores:\n",
        "            avg_scores[q_type] = {\n",
        "                'average': round(sum(scores) / len(scores), 1),\n",
        "                'count': len(scores),\n",
        "                'best': max(scores),\n",
        "                'worst': min(scores)\n",
        "            }\n",
        "\n",
        "    return avg_scores\n",
        "\n",
        "\n",
        "def export_session_data_to_json() -> str:\n",
        "    \"\"\"Export all session data to JSON string.\"\"\"\n",
        "    export_data = {\n",
        "        'export_date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "        'user_profile': SESSION_DATA['user_profile'],\n",
        "        'resume_analysis': {\n",
        "            'ats_score': SESSION_DATA['resume_analysis']['ats_score'] if SESSION_DATA['resume_analysis'] else None,\n",
        "            'skills': SESSION_DATA['resume_data']['skills'] if SESSION_DATA['resume_data'] else []\n",
        "        },\n",
        "        'interview_history': SESSION_DATA['interview_history'],\n",
        "        'performance_trends': calculate_performance_trends(),\n",
        "        'question_type_performance': analyze_question_type_performance()\n",
        "    }\n",
        "\n",
        "    return json.dumps(export_data, indent=2)\n",
        "\n",
        "\n",
        "def generate_text_report(interview_results: Dict) -> str:\n",
        "    \"\"\"Generate a formatted text report of interview results.\"\"\"\n",
        "    report = f\"\"\"\n",
        "{'=' * 70}\n",
        "                    INTERVIEW PERFORMANCE REPORT\n",
        "{'=' * 70}\n",
        "\n",
        "Date: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
        "Interview Type: {interview_results.get('interview_type', 'Mixed')}\n",
        "\n",
        "{'=' * 70}\n",
        "OVERALL PERFORMANCE\n",
        "{'=' * 70}\n",
        "\n",
        "Total Questions: {interview_results['total_questions']}\n",
        "Questions Answered: {interview_results['total_answered']}\n",
        "Overall Score: {interview_results['total_score']}/{interview_results['total_possible']} ({interview_results['overall_percentage']}%)\n",
        "Grade: {interview_results['overall_grade']}\n",
        "Average Confidence: {interview_results['average_confidence']:.1f}%\n",
        "\n",
        "{'=' * 70}\n",
        "STRENGTHS & WEAKNESSES\n",
        "{'=' * 70}\n",
        "\n",
        "Strong Areas:\n",
        "\"\"\"\n",
        "\n",
        "    if interview_results['strengths']:\n",
        "        for strength in interview_results['strengths']:\n",
        "            report += f\"  ‚úÖ {strength}\\n\"\n",
        "    else:\n",
        "        report += \"  ‚Ä¢ Continue practicing all areas\\n\"\n",
        "\n",
        "    report += \"\\nAreas for Improvement:\\n\"\n",
        "    if interview_results['weaknesses']:\n",
        "        for weakness in interview_results['weaknesses']:\n",
        "            report += f\"  ‚ö†Ô∏è {weakness}\\n\"\n",
        "    else:\n",
        "        report += \"  ‚Ä¢ Great job! Keep up the momentum\\n\"\n",
        "\n",
        "    report += f\"\\n{'=' * 70}\\n\"\n",
        "    report += \"DETAILED QUESTION-BY-QUESTION ANALYSIS\\n\"\n",
        "    report += f\"{'=' * 70}\\n\\n\"\n",
        "\n",
        "    for i, result in enumerate(interview_results['results'], 1):\n",
        "        report += f\"Question {i} ({result['question_type']})\\n\"\n",
        "        report += f\"{'-' * 70}\\n\"\n",
        "        report += f\"Q: {result['question'][:100]}...\\n\\n\"\n",
        "\n",
        "        if result['evaluation']['success']:\n",
        "            scores = result['scores']\n",
        "            report += f\"Score: {scores['total']}/50 ({scores['percentage']}%)\\n\"\n",
        "            report += f\"  ‚Ä¢ Relevance: {scores['relevance']}/10\\n\"\n",
        "            report += f\"  ‚Ä¢ Technical Accuracy: {scores['technical_accuracy']}/10\\n\"\n",
        "            report += f\"  ‚Ä¢ Communication: {scores['communication']}/10\\n\"\n",
        "            report += f\"  ‚Ä¢ Depth: {scores['depth']}/10\\n\"\n",
        "            report += f\"  ‚Ä¢ Completeness: {scores['completeness']}/10\\n\"\n",
        "            report += f\"Grade: {result['grade']}\\n\"\n",
        "\n",
        "        report += f\"\\n\"\n",
        "\n",
        "    report += f\"{'=' * 70}\\n\"\n",
        "    report += \"END OF REPORT\\n\"\n",
        "    report += f\"{'=' * 70}\\n\"\n",
        "\n",
        "    return report\n",
        "\n",
        "\n",
        "def create_performance_chart_data() -> Dict:\n",
        "    \"\"\"Prepare data for performance visualization charts.\"\"\"\n",
        "    if not SESSION_DATA['interview_history']:\n",
        "        return {\n",
        "            'has_data': False\n",
        "        }\n",
        "\n",
        "    # Score trend data\n",
        "    sessions = list(range(1, len(SESSION_DATA['interview_history']) + 1))\n",
        "    scores = [record['overall_score'] for record in SESSION_DATA['interview_history']]\n",
        "\n",
        "    # Question type performance data\n",
        "    type_performance = analyze_question_type_performance()\n",
        "\n",
        "    return {\n",
        "        'has_data': True,\n",
        "        'score_trend': {\n",
        "            'sessions': sessions,\n",
        "            'scores': scores\n",
        "        },\n",
        "        'type_performance': type_performance,\n",
        "        'latest_score': scores[-1] if scores else 0,\n",
        "        'average_score': SESSION_DATA['user_profile']['average_score']\n",
        "    }\n",
        "\n",
        "\n",
        "def format_percentage(value: float, total: float = 100) -> str:\n",
        "    \"\"\"Format a value as percentage.\"\"\"\n",
        "    percentage = (value / total) * 100 if total > 0 else 0\n",
        "    return f\"{percentage:.1f}%\"\n",
        "\n",
        "\n",
        "def format_score_badge(score: float) -> str:\n",
        "    \"\"\"Generate an emoji badge based on score.\"\"\"\n",
        "    if score >= 90:\n",
        "        return \"üèÜ Excellent\"\n",
        "    elif score >= 80:\n",
        "        return \"‚≠ê Very Good\"\n",
        "    elif score >= 70:\n",
        "        return \"‚úÖ Good\"\n",
        "    elif score >= 60:\n",
        "        return \"üëç Fair\"\n",
        "    elif score >= 50:\n",
        "        return \"üìà Needs Work\"\n",
        "    else:\n",
        "        return \"‚ö†Ô∏è More Practice Needed\"\n",
        "\n",
        "\n",
        "def get_motivational_message(score: float) -> str:\n",
        "    \"\"\"Get a motivational message based on score.\"\"\"\n",
        "    if score >= 90:\n",
        "        return \"Outstanding performance! You're interview-ready! üéâ\"\n",
        "    elif score >= 80:\n",
        "        return \"Excellent work! A few more practice sessions and you'll be perfect! üí™\"\n",
        "    elif score >= 70:\n",
        "        return \"Good job! Keep practicing to reach excellence! üìö\"\n",
        "    elif score >= 60:\n",
        "        return \"You're making progress! Focus on your weak areas. üéØ\"\n",
        "    elif score >= 50:\n",
        "        return \"Keep going! Every practice session makes you better! üöÄ\"\n",
        "    else:\n",
        "        return \"Don't give up! Practice makes perfect! üí°\"\n",
        "\n",
        "\n",
        "# Initialize session on load\n",
        "initialize_session()\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üõ†Ô∏è Helper Functions & Utilities Ready!\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\n‚ú® Functions created:\")\n",
        "print(\"   ‚Ä¢ Session Management:\")\n",
        "print(\"     - initialize_session()\")\n",
        "print(\"     - save_resume_data()\")\n",
        "print(\"     - save_job_match()\")\n",
        "print(\"     - save_interview_results()\")\n",
        "print(\"     - get_session_summary()\")\n",
        "print(\"\\n   ‚Ä¢ Analytics:\")\n",
        "print(\"     - calculate_performance_trends()\")\n",
        "print(\"     - analyze_question_type_performance()\")\n",
        "print(\"     - create_performance_chart_data()\")\n",
        "print(\"\\n   ‚Ä¢ Export:\")\n",
        "print(\"     - export_session_data_to_json()\")\n",
        "print(\"     - generate_text_report()\")\n",
        "print(\"\\n   ‚Ä¢ Formatting:\")\n",
        "print(\"     - format_percentage()\")\n",
        "print(\"     - format_score_badge()\")\n",
        "print(\"     - get_motivational_message()\")\n",
        "print(\"\\nüíæ Session tracking enabled!\")\n",
        "print(\"üìä Analytics ready!\")\n",
        "print(\"üìÑ Report generation ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "senNaTvYevPW",
        "outputId": "fd8ec596-45d9-40ca-b972-e4af87d0de13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "üé® UI Components & Styling Ready!\n",
            "============================================================\n",
            "\n",
            "‚ú® Components created:\n",
            "   ‚Ä¢ Custom CSS with gradient themes\n",
            "   ‚Ä¢ render_header() - Beautiful page headers\n",
            "   ‚Ä¢ render_score_card() - Color-coded score cards\n",
            "   ‚Ä¢ render_metric_row() - Metric display\n",
            "   ‚Ä¢ render_info_box() - Info/success/warning/error boxes\n",
            "   ‚Ä¢ render_progress_bar() - Animated progress bars\n",
            "   ‚Ä¢ render_badge() - Colorful badges\n",
            "   ‚Ä¢ render_question_card() - Question display cards\n",
            "   ‚Ä¢ render_skills_chips() - Skill tags\n",
            "   ‚Ä¢ render_evaluation_breakdown() - Score breakdown\n",
            "   ‚Ä¢ create_download_button() - Custom download buttons\n",
            "   ‚Ä¢ render_interview_stats() - Statistics dashboard\n",
            "\n",
            "üé® Beautiful UI components ready for Streamlit!\n"
          ]
        }
      ],
      "source": [
        "# Cell 10: UI Components & Styling\n",
        "\n",
        "def get_custom_css() -> str:\n",
        "    \"\"\"\n",
        "    Custom CSS for beautiful Streamlit interface.\n",
        "    \"\"\"\n",
        "    return \"\"\"\n",
        "    <style>\n",
        "    /* Import Google Fonts */\n",
        "    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700&display=swap');\n",
        "\n",
        "    /* Global Styles */\n",
        "    * {\n",
        "        font-family: 'Inter', sans-serif;\n",
        "    }\n",
        "\n",
        "    /* Main container */\n",
        "    .main {\n",
        "        padding: 2rem;\n",
        "    }\n",
        "\n",
        "    /* Custom header styles */\n",
        "    .main-header {\n",
        "        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "        padding: 2rem;\n",
        "        border-radius: 15px;\n",
        "        color: white;\n",
        "        text-align: center;\n",
        "        margin-bottom: 2rem;\n",
        "        box-shadow: 0 10px 30px rgba(0,0,0,0.2);\n",
        "    }\n",
        "\n",
        "    .main-header h1 {\n",
        "        margin: 0;\n",
        "        font-size: 2.5rem;\n",
        "        font-weight: 700;\n",
        "    }\n",
        "\n",
        "    .main-header p {\n",
        "        margin: 0.5rem 0 0 0;\n",
        "        font-size: 1.1rem;\n",
        "        opacity: 0.9;\n",
        "    }\n",
        "\n",
        "    /* Score card styles */\n",
        "    .score-card {\n",
        "        background: white;\n",
        "        padding: 1.5rem;\n",
        "        border-radius: 12px;\n",
        "        box-shadow: 0 4px 15px rgba(0,0,0,0.1);\n",
        "        text-align: center;\n",
        "        margin: 1rem 0;\n",
        "        border-left: 5px solid #667eea;\n",
        "    }\n",
        "\n",
        "    .score-card.excellent {\n",
        "        border-left-color: #10b981;\n",
        "    }\n",
        "\n",
        "    .score-card.good {\n",
        "        border-left-color: #3b82f6;\n",
        "    }\n",
        "\n",
        "    .score-card.fair {\n",
        "        border-left-color: #f59e0b;\n",
        "    }\n",
        "\n",
        "    .score-card.poor {\n",
        "        border-left-color: #ef4444;\n",
        "    }\n",
        "\n",
        "    .score-value {\n",
        "        font-size: 3rem;\n",
        "        font-weight: 700;\n",
        "        color: #1f2937;\n",
        "        margin: 0;\n",
        "    }\n",
        "\n",
        "    .score-label {\n",
        "        font-size: 1rem;\n",
        "        color: #6b7280;\n",
        "        margin: 0.5rem 0 0 0;\n",
        "    }\n",
        "\n",
        "    /* Info box styles */\n",
        "    .info-box {\n",
        "        background: #f3f4f6;\n",
        "        padding: 1.5rem;\n",
        "        border-radius: 10px;\n",
        "        margin: 1rem 0;\n",
        "        border-left: 4px solid #3b82f6;\n",
        "    }\n",
        "\n",
        "    .info-box.success {\n",
        "        background: #ecfdf5;\n",
        "        border-left-color: #10b981;\n",
        "    }\n",
        "\n",
        "    .info-box.warning {\n",
        "        background: #fffbeb;\n",
        "        border-left-color: #f59e0b;\n",
        "    }\n",
        "\n",
        "    .info-box.error {\n",
        "        background: #fef2f2;\n",
        "        border-left-color: #ef4444;\n",
        "    }\n",
        "\n",
        "    /* Metric card */\n",
        "    .metric-card {\n",
        "        background: white;\n",
        "        padding: 1.5rem;\n",
        "        border-radius: 10px;\n",
        "        box-shadow: 0 2px 10px rgba(0,0,0,0.08);\n",
        "        margin: 0.5rem 0;\n",
        "    }\n",
        "\n",
        "    .metric-value {\n",
        "        font-size: 2rem;\n",
        "        font-weight: 700;\n",
        "        color: #667eea;\n",
        "    }\n",
        "\n",
        "    .metric-label {\n",
        "        font-size: 0.9rem;\n",
        "        color: #6b7280;\n",
        "        margin-top: 0.5rem;\n",
        "    }\n",
        "\n",
        "    /* Progress bar custom */\n",
        "    .progress-bar {\n",
        "        background: #e5e7eb;\n",
        "        border-radius: 10px;\n",
        "        height: 12px;\n",
        "        overflow: hidden;\n",
        "        margin: 1rem 0;\n",
        "    }\n",
        "\n",
        "    .progress-fill {\n",
        "        height: 100%;\n",
        "        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);\n",
        "        border-radius: 10px;\n",
        "        transition: width 0.3s ease;\n",
        "    }\n",
        "\n",
        "    /* Button styles */\n",
        "    .stButton>button {\n",
        "        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "        color: white;\n",
        "        border: none;\n",
        "        padding: 0.75rem 2rem;\n",
        "        border-radius: 8px;\n",
        "        font-weight: 600;\n",
        "        transition: all 0.3s ease;\n",
        "    }\n",
        "\n",
        "    .stButton>button:hover {\n",
        "        transform: translateY(-2px);\n",
        "        box-shadow: 0 5px 15px rgba(102, 126, 234, 0.4);\n",
        "    }\n",
        "\n",
        "    /* Tabs styling */\n",
        "    .stTabs [data-baseweb=\"tab-list\"] {\n",
        "        gap: 8px;\n",
        "    }\n",
        "\n",
        "    .stTabs [data-baseweb=\"tab\"] {\n",
        "        border-radius: 8px 8px 0 0;\n",
        "        padding: 10px 20px;\n",
        "        background-color: #f3f4f6;\n",
        "    }\n",
        "\n",
        "    .stTabs [aria-selected=\"true\"] {\n",
        "        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "        color: white;\n",
        "    }\n",
        "\n",
        "    /* Question card */\n",
        "    .question-card {\n",
        "        background: white;\n",
        "        padding: 1.5rem;\n",
        "        border-radius: 10px;\n",
        "        box-shadow: 0 2px 10px rgba(0,0,0,0.08);\n",
        "        margin: 1rem 0;\n",
        "        border-left: 4px solid #667eea;\n",
        "    }\n",
        "\n",
        "    .question-number {\n",
        "        background: #667eea;\n",
        "        color: white;\n",
        "        padding: 0.3rem 0.8rem;\n",
        "        border-radius: 20px;\n",
        "        font-size: 0.9rem;\n",
        "        font-weight: 600;\n",
        "        display: inline-block;\n",
        "        margin-bottom: 0.5rem;\n",
        "    }\n",
        "\n",
        "    /* Badge styles */\n",
        "    .badge {\n",
        "        display: inline-block;\n",
        "        padding: 0.4rem 0.8rem;\n",
        "        border-radius: 20px;\n",
        "        font-size: 0.85rem;\n",
        "        font-weight: 600;\n",
        "        margin: 0.2rem;\n",
        "    }\n",
        "\n",
        "    .badge-success {\n",
        "        background: #d1fae5;\n",
        "        color: #065f46;\n",
        "    }\n",
        "\n",
        "    .badge-warning {\n",
        "        background: #fef3c7;\n",
        "        color: #92400e;\n",
        "    }\n",
        "\n",
        "    .badge-info {\n",
        "        background: #dbeafe;\n",
        "        color: #1e40af;\n",
        "    }\n",
        "\n",
        "    .badge-danger {\n",
        "        background: #fee2e2;\n",
        "        color: #991b1b;\n",
        "    }\n",
        "\n",
        "    /* Divider */\n",
        "    .divider {\n",
        "        height: 2px;\n",
        "        background: linear-gradient(90deg, transparent, #667eea, transparent);\n",
        "        margin: 2rem 0;\n",
        "    }\n",
        "\n",
        "    /* Hide Streamlit branding */\n",
        "    #MainMenu {visibility: hidden;}\n",
        "    footer {visibility: hidden;}\n",
        "\n",
        "    </style>\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "def render_header(title: str, subtitle: str = \"\"):\n",
        "    \"\"\"Render a beautiful header.\"\"\"\n",
        "    import streamlit as st\n",
        "    st.markdown(f\"\"\"\n",
        "        <div class=\"main-header\">\n",
        "            <h1>{title}</h1>\n",
        "            {f'<p>{subtitle}</p>' if subtitle else ''}\n",
        "        </div>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "def render_score_card(score: float, label: str, max_score: float = 100):\n",
        "    \"\"\"Render a score card with color coding.\"\"\"\n",
        "    import streamlit as st\n",
        "\n",
        "    percentage = (score / max_score) * 100\n",
        "\n",
        "    if percentage >= 80:\n",
        "        card_class = \"excellent\"\n",
        "    elif percentage >= 70:\n",
        "        card_class = \"good\"\n",
        "    elif percentage >= 60:\n",
        "        card_class = \"fair\"\n",
        "    else:\n",
        "        card_class = \"poor\"\n",
        "\n",
        "    st.markdown(f\"\"\"\n",
        "        <div class=\"score-card {card_class}\">\n",
        "            <p class=\"score-value\">{score:.1f}</p>\n",
        "            <p class=\"score-label\">{label}</p>\n",
        "        </div>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "def render_metric_row(metrics: list):\n",
        "    \"\"\"Render a row of metrics.\"\"\"\n",
        "    import streamlit as st\n",
        "\n",
        "    cols = st.columns(len(metrics))\n",
        "\n",
        "    for col, metric in zip(cols, metrics):\n",
        "        with col:\n",
        "            st.markdown(f\"\"\"\n",
        "                <div class=\"metric-card\">\n",
        "                    <div class=\"metric-value\">{metric['value']}</div>\n",
        "                    <div class=\"metric-label\">{metric['label']}</div>\n",
        "                </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "def render_info_box(message: str, box_type: str = \"info\"):\n",
        "    \"\"\"Render an info box (info, success, warning, error).\"\"\"\n",
        "    import streamlit as st\n",
        "\n",
        "    icons = {\n",
        "        'info': '‚ÑπÔ∏è',\n",
        "        'success': '‚úÖ',\n",
        "        'warning': '‚ö†Ô∏è',\n",
        "        'error': '‚ùå'\n",
        "    }\n",
        "\n",
        "    icon = icons.get(box_type, '‚ÑπÔ∏è')\n",
        "\n",
        "    st.markdown(f\"\"\"\n",
        "        <div class=\"info-box {box_type}\">\n",
        "            {icon} {message}\n",
        "        </div>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "def render_progress_bar(percentage: float, label: str = \"\"):\n",
        "    \"\"\"Render a custom progress bar.\"\"\"\n",
        "    import streamlit as st\n",
        "\n",
        "    st.markdown(f\"\"\"\n",
        "        <div>\n",
        "            {f'<p style=\"margin-bottom: 0.5rem; font-weight: 600;\">{label}</p>' if label else ''}\n",
        "            <div class=\"progress-bar\">\n",
        "                <div class=\"progress-fill\" style=\"width: {percentage}%;\"></div>\n",
        "            </div>\n",
        "            <p style=\"text-align: right; font-size: 0.9rem; color: #6b7280; margin-top: 0.3rem;\">\n",
        "                {percentage:.1f}%\n",
        "            </p>\n",
        "        </div>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "def render_badge(text: str, badge_type: str = \"info\"):\n",
        "    \"\"\"Render a badge.\"\"\"\n",
        "    import streamlit as st\n",
        "\n",
        "    st.markdown(f\"\"\"\n",
        "        <span class=\"badge badge-{badge_type}\">{text}</span>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "def render_question_card(question_number: int, question: str, question_type: str):\n",
        "    \"\"\"Render a question card.\"\"\"\n",
        "    import streamlit as st\n",
        "\n",
        "    st.markdown(f\"\"\"\n",
        "        <div class=\"question-card\">\n",
        "            <span class=\"question-number\">Question {question_number}</span>\n",
        "            <span class=\"badge badge-info\" style=\"margin-left: 0.5rem;\">{question_type}</span>\n",
        "            <p style=\"margin-top: 1rem; font-size: 1.1rem; color: #1f2937;\">{question}</p>\n",
        "        </div>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "def render_divider():\n",
        "    \"\"\"Render a styled divider.\"\"\"\n",
        "    import streamlit as st\n",
        "    st.markdown('<div class=\"divider\"></div>', unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "def render_skills_chips(skills: list, title: str = \"Skills\"):\n",
        "    \"\"\"Render skills as colorful chips.\"\"\"\n",
        "    import streamlit as st\n",
        "\n",
        "    st.markdown(f\"**{title}:**\")\n",
        "\n",
        "    chips_html = '<div style=\"margin: 0.5rem 0;\">'\n",
        "    for skill in skills:\n",
        "        chips_html += f'<span class=\"badge badge-info\">{skill}</span>'\n",
        "    chips_html += '</div>'\n",
        "\n",
        "    st.markdown(chips_html, unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "def render_evaluation_breakdown(scores: Dict):\n",
        "    \"\"\"Render evaluation score breakdown.\"\"\"\n",
        "    import streamlit as st\n",
        "\n",
        "    st.markdown(\"### üìä Score Breakdown\")\n",
        "\n",
        "    criteria = [\n",
        "        ('Relevance', scores.get('relevance', 0)),\n",
        "        ('Technical Accuracy', scores.get('technical_accuracy', 0)),\n",
        "        ('Communication', scores.get('communication', 0)),\n",
        "        ('Depth', scores.get('depth', 0)),\n",
        "        ('Completeness', scores.get('completeness', 0))\n",
        "    ]\n",
        "\n",
        "    for label, score in criteria:\n",
        "        percentage = (score / 10) * 100\n",
        "        render_progress_bar(percentage, f\"{label}: {score}/10\")\n",
        "\n",
        "\n",
        "def create_download_button(data: str, filename: str, label: str, file_type: str = \"text\"):\n",
        "    \"\"\"Create a custom download button.\"\"\"\n",
        "    import streamlit as st\n",
        "    import base64\n",
        "\n",
        "    if file_type == \"text\":\n",
        "        b64 = base64.b64encode(data.encode()).decode()\n",
        "        href = f'<a href=\"data:text/plain;base64,{b64}\" download=\"{filename}\" style=\"text-decoration: none;\"><button style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; border: none; padding: 0.75rem 2rem; border-radius: 8px; font-weight: 600; cursor: pointer;\">üì• {label}</button></a>'\n",
        "        st.markdown(href, unsafe_allow_html=True)\n",
        "    elif file_type == \"json\":\n",
        "        b64 = base64.b64encode(data.encode()).decode()\n",
        "        href = f'<a href=\"data:application/json;base64,{b64}\" download=\"{filename}\" style=\"text-decoration: none;\"><button style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; border: none; padding: 0.75rem 2rem; border-radius: 8px; font-weight: 600; cursor: pointer;\">üì• {label}</button></a>'\n",
        "        st.markdown(href, unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "def render_comparison_table(data: Dict, title: str = \"Comparison\"):\n",
        "    \"\"\"Render a comparison table.\"\"\"\n",
        "    import streamlit as st\n",
        "    import pandas as pd\n",
        "\n",
        "    st.markdown(f\"### {title}\")\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    st.dataframe(df, use_container_width=True)\n",
        "\n",
        "\n",
        "def show_success_animation(message: str):\n",
        "    \"\"\"Show a success message with animation.\"\"\"\n",
        "    import streamlit as st\n",
        "    import time\n",
        "\n",
        "    success_placeholder = st.empty()\n",
        "    success_placeholder.success(f\"‚ú® {message}\")\n",
        "    time.sleep(2)\n",
        "    success_placeholder.empty()\n",
        "\n",
        "\n",
        "def render_interview_stats(interview_results: Dict):\n",
        "    \"\"\"Render interview statistics in a beautiful layout.\"\"\"\n",
        "    import streamlit as st\n",
        "\n",
        "    col1, col2, col3, col4 = st.columns(4)\n",
        "\n",
        "    with col1:\n",
        "        render_score_card(\n",
        "            interview_results['overall_percentage'],\n",
        "            \"Overall Score\",\n",
        "            100\n",
        "        )\n",
        "\n",
        "    with col2:\n",
        "        st.markdown(f\"\"\"\n",
        "            <div class=\"metric-card\">\n",
        "                <div class=\"metric-value\">{interview_results['total_questions']}</div>\n",
        "                <div class=\"metric-label\">Total Questions</div>\n",
        "            </div>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    with col3:\n",
        "        st.markdown(f\"\"\"\n",
        "            <div class=\"metric-card\">\n",
        "                <div class=\"metric-value\">{len(interview_results.get('strengths', []))}</div>\n",
        "                <div class=\"metric-label\">Strong Areas</div>\n",
        "            </div>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    with col4:\n",
        "        st.markdown(f\"\"\"\n",
        "            <div class=\"metric-card\">\n",
        "                <div class=\"metric-value\">{interview_results.get('average_confidence', 0):.0f}%</div>\n",
        "                <div class=\"metric-label\">Confidence Level</div>\n",
        "            </div>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "# Test message\n",
        "print(\"=\" * 60)\n",
        "print(\"üé® UI Components & Styling Ready!\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\n‚ú® Components created:\")\n",
        "print(\"   ‚Ä¢ Custom CSS with gradient themes\")\n",
        "print(\"   ‚Ä¢ render_header() - Beautiful page headers\")\n",
        "print(\"   ‚Ä¢ render_score_card() - Color-coded score cards\")\n",
        "print(\"   ‚Ä¢ render_metric_row() - Metric display\")\n",
        "print(\"   ‚Ä¢ render_info_box() - Info/success/warning/error boxes\")\n",
        "print(\"   ‚Ä¢ render_progress_bar() - Animated progress bars\")\n",
        "print(\"   ‚Ä¢ render_badge() - Colorful badges\")\n",
        "print(\"   ‚Ä¢ render_question_card() - Question display cards\")\n",
        "print(\"   ‚Ä¢ render_skills_chips() - Skill tags\")\n",
        "print(\"   ‚Ä¢ render_evaluation_breakdown() - Score breakdown\")\n",
        "print(\"   ‚Ä¢ create_download_button() - Custom download buttons\")\n",
        "print(\"   ‚Ä¢ render_interview_stats() - Statistics dashboard\")\n",
        "print(\"\\nüé® Beautiful UI components ready for Streamlit!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbyDKyt0fCO-",
        "outputId": "7e801601-36bd-4687-99a4-80a571f7331a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "üì± Streamlit App - Part 1 Created!\n",
            "============================================================\n",
            "\n",
            "‚ú® Pages included:\n",
            "   ‚Ä¢ Home Page with Quick Actions\n",
            "   ‚Ä¢ API Key Configuration (Sidebar)\n",
            "   ‚Ä¢ Resume Upload & Analysis\n",
            "   ‚Ä¢ ATS Score Display\n",
            "   ‚Ä¢ AI Analysis with Gemini\n",
            "   ‚Ä¢ Improvement Suggestions\n",
            "\n",
            "üíæ Ready to continue with Part 2!\n"
          ]
        }
      ],
      "source": [
        "# Cell 11: Main Streamlit Application - Part 1\n",
        "\n",
        "# This will be saved as app.py for Streamlit Cloud deployment\n",
        "\n",
        "APP_CODE_PART_1 = '''\n",
        "import streamlit as st\n",
        "import PyPDF2\n",
        "import pdfplumber\n",
        "from groq import Groq\n",
        "import google.generativeai as genai\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import json\n",
        "import re\n",
        "from typing import Dict, List\n",
        "\n",
        "# Page configuration\n",
        "st.set_page_config(\n",
        "    page_title=\"AI Interview Prep & Resume Analyzer\",\n",
        "    page_icon=\"üéØ\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\"\n",
        ")\n",
        "\n",
        "# Apply custom CSS\n",
        "st.markdown(\"\"\"''' + get_custom_css() + '''\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# Initialize session state\n",
        "if 'initialized' not in st.session_state:\n",
        "    st.session_state.initialized = True\n",
        "    st.session_state.resume_data = None\n",
        "    st.session_state.resume_analysis = None\n",
        "    st.session_state.job_match_analysis = None\n",
        "    st.session_state.interview_history = []\n",
        "    st.session_state.current_interview = None\n",
        "    st.session_state.api_keys_set = False\n",
        "    st.session_state.groq_client = None\n",
        "    st.session_state.gemini_model = None\n",
        "\n",
        "# Sidebar for API Keys\n",
        "with st.sidebar:\n",
        "    st.markdown(\"### üîë API Configuration\")\n",
        "\n",
        "    if not st.session_state.api_keys_set:\n",
        "        st.info(\"Please enter your API keys to get started\")\n",
        "\n",
        "        groq_key = st.text_input(\"Groq API Key\", type=\"password\", help=\"Get from console.groq.com/keys\")\n",
        "        gemini_key = st.text_input(\"Gemini API Key\", type=\"password\", help=\"Get from aistudio.google.com/app/apikey\")\n",
        "\n",
        "        if st.button(\"‚úÖ Save API Keys\"):\n",
        "            if groq_key and gemini_key:\n",
        "                try:\n",
        "                    # Test Groq\n",
        "                    st.session_state.groq_client = Groq(api_key=groq_key)\n",
        "                    test = st.session_state.groq_client.chat.completions.create(\n",
        "                        messages=[{\"role\": \"user\", \"content\": \"Hi\"}],\n",
        "                        model=\"llama-3.3-70b-versatile\",\n",
        "                        max_tokens=5\n",
        "                    )\n",
        "\n",
        "                    # Test Gemini\n",
        "                    genai.configure(api_key=gemini_key)\n",
        "                    st.session_state.gemini_model = genai.GenerativeModel('gemini-2.5-flash')\n",
        "                    test2 = st.session_state.gemini_model.generate_content(\"Hi\")\n",
        "\n",
        "                    st.session_state.api_keys_set = True\n",
        "                    st.success(\"‚úÖ API keys validated!\")\n",
        "                    st.rerun()\n",
        "                except Exception as e:\n",
        "                    st.error(f\"‚ùå API validation failed: {str(e)}\")\n",
        "            else:\n",
        "                st.error(\"Please enter both API keys\")\n",
        "    else:\n",
        "        st.success(\"‚úÖ API Keys Configured\")\n",
        "        if st.button(\"üîÑ Reset API Keys\"):\n",
        "            st.session_state.api_keys_set = False\n",
        "            st.rerun()\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    # Navigation\n",
        "    st.markdown(\"### üìç Navigation\")\n",
        "    page = st.radio(\n",
        "        \"Go to:\",\n",
        "        [\"üè† Home\", \"üìÑ Resume Analysis\", \"üéØ Job Matcher\", \"üé§ Mock Interview\", \"üìä Dashboard\"],\n",
        "        label_visibility=\"collapsed\"\n",
        "    )\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    st.markdown(\"### üìà Quick Stats\")\n",
        "    if st.session_state.resume_data:\n",
        "        st.metric(\"Skills Found\", len(st.session_state.resume_data.get('skills', [])))\n",
        "    if st.session_state.interview_history:\n",
        "        st.metric(\"Interviews Done\", len(st.session_state.interview_history))\n",
        "        avg_score = sum(i['overall_score'] for i in st.session_state.interview_history) / len(st.session_state.interview_history)\n",
        "        st.metric(\"Average Score\", f\"{avg_score:.1f}%\")\n",
        "\n",
        "# Main content area\n",
        "if not st.session_state.api_keys_set:\n",
        "    # Welcome screen when APIs not configured\n",
        "    st.markdown(\"\"\"\n",
        "        <div class=\"main-header\">\n",
        "            <h1>üéØ AI Interview Prep & Resume Analyzer</h1>\n",
        "            <p>Your AI-powered career preparation assistant</p>\n",
        "        </div>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"## üëà Get Started\")\n",
        "    st.info(\"Enter your API keys in the sidebar to begin!\")\n",
        "\n",
        "    col1, col2 = st.columns(2)\n",
        "\n",
        "    with col1:\n",
        "        st.markdown(\"\"\"\n",
        "            ### üîë Get Groq API Key\n",
        "            1. Visit [console.groq.com/keys](https://console.groq.com/keys)\n",
        "            2. Sign up/Login with Google\n",
        "            3. Click 'Create API Key'\n",
        "            4. Copy and paste in sidebar\n",
        "        \"\"\")\n",
        "\n",
        "    with col2:\n",
        "        st.markdown(\"\"\"\n",
        "            ### üîë Get Gemini API Key\n",
        "            1. Visit [aistudio.google.com/app/apikey](https://aistudio.google.com/app/apikey)\n",
        "            2. Sign in with Google\n",
        "            3. Click 'Create API Key'\n",
        "            4. Copy and paste in sidebar\n",
        "        \"\"\")\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    st.markdown(\"## ‚ú® Features\")\n",
        "\n",
        "    feat1, feat2, feat3 = st.columns(3)\n",
        "\n",
        "    with feat1:\n",
        "        st.markdown(\"\"\"\n",
        "            <div class=\"info-box success\">\n",
        "                <h3>üìÑ Resume Analysis</h3>\n",
        "                <p>Get ATS score, skill analysis, and improvement suggestions</p>\n",
        "            </div>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    with feat2:\n",
        "        st.markdown(\"\"\"\n",
        "            <div class=\"info-box success\">\n",
        "                <h3>üéØ Job Matching</h3>\n",
        "                <p>Compare your resume with job descriptions and get match scores</p>\n",
        "            </div>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    with feat3:\n",
        "        st.markdown(\"\"\"\n",
        "            <div class=\"info-box success\">\n",
        "                <h3>üé§ Mock Interviews</h3>\n",
        "                <p>Practice with AI-generated questions and get real-time feedback</p>\n",
        "            </div>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "else:\n",
        "    # Main application pages\n",
        "\n",
        "    if page == \"üè† Home\":\n",
        "        st.markdown(\"\"\"\n",
        "            <div class=\"main-header\">\n",
        "                <h1>üéØ AI Interview Prep & Resume Analyzer</h1>\n",
        "                <p>Your AI-powered career preparation assistant</p>\n",
        "            </div>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        st.markdown(\"## üöÄ Quick Actions\")\n",
        "\n",
        "        col1, col2, col3 = st.columns(3)\n",
        "\n",
        "        with col1:\n",
        "            if st.button(\"üìÑ Upload Resume\", use_container_width=True):\n",
        "                st.session_state.page = \"üìÑ Resume Analysis\"\n",
        "                st.rerun()\n",
        "\n",
        "        with col2:\n",
        "            if st.button(\"üéØ Match Job\", use_container_width=True):\n",
        "                st.session_state.page = \"üéØ Job Matcher\"\n",
        "                st.rerun()\n",
        "\n",
        "        with col3:\n",
        "            if st.button(\"üé§ Start Interview\", use_container_width=True):\n",
        "                st.session_state.page = \"üé§ Mock Interview\"\n",
        "                st.rerun()\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "\n",
        "        if st.session_state.resume_data:\n",
        "            st.markdown(\"## üìä Your Profile Summary\")\n",
        "\n",
        "            col1, col2, col3 = st.columns(3)\n",
        "\n",
        "            with col1:\n",
        "                st.markdown(f\"\"\"\n",
        "                    <div class=\"metric-card\">\n",
        "                        <div class=\"metric-value\">{len(st.session_state.resume_data.get('skills', []))}</div>\n",
        "                        <div class=\"metric-label\">Skills Identified</div>\n",
        "                    </div>\n",
        "                \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "            with col2:\n",
        "                exp_count = len(st.session_state.resume_data.get('experience', []))\n",
        "                st.markdown(f\"\"\"\n",
        "                    <div class=\"metric-card\">\n",
        "                        <div class=\"metric-value\">{exp_count}</div>\n",
        "                        <div class=\"metric-label\">Experience Entries</div>\n",
        "                    </div>\n",
        "                \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "            with col3:\n",
        "                if st.session_state.resume_analysis:\n",
        "                    ats_score = st.session_state.resume_analysis.get('ats_score', 0)\n",
        "                    st.markdown(f\"\"\"\n",
        "                        <div class=\"metric-card\">\n",
        "                            <div class=\"metric-value\">{ats_score}</div>\n",
        "                            <div class=\"metric-label\">ATS Score</div>\n",
        "                        </div>\n",
        "                    \"\"\", unsafe_allow_html=True)\n",
        "        else:\n",
        "            st.info(\"üëÜ Upload your resume to get started!\")\n",
        "\n",
        "    elif page == \"üìÑ Resume Analysis\":\n",
        "        st.markdown(\"\"\"\n",
        "            <div class=\"main-header\">\n",
        "                <h1>üìÑ Resume Analysis</h1>\n",
        "                <p>Upload your resume for comprehensive AI analysis</p>\n",
        "            </div>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        uploaded_file = st.file_uploader(\"Upload your resume (PDF)\", type=['pdf'])\n",
        "\n",
        "        if uploaded_file:\n",
        "            if st.button(\"üîç Analyze Resume\", type=\"primary\"):\n",
        "                with st.spinner(\"Analyzing your resume...\"):\n",
        "                    # Extract text from PDF\n",
        "                    text = extract_text_from_pdf(uploaded_file)\n",
        "\n",
        "                    if text:\n",
        "                        # Structure resume data\n",
        "                        resume_data = structure_resume_data(text)\n",
        "                        st.session_state.resume_data = resume_data\n",
        "\n",
        "                        # Perform complete analysis\n",
        "                        analysis = complete_resume_analysis(resume_data)\n",
        "                        st.session_state.resume_analysis = analysis\n",
        "\n",
        "                        st.success(\"‚úÖ Resume analysis complete!\")\n",
        "                        st.rerun()\n",
        "\n",
        "        if st.session_state.resume_analysis:\n",
        "            st.markdown(\"---\")\n",
        "\n",
        "            # Display ATS Score\n",
        "            st.markdown(\"## üìä ATS Compatibility Score\")\n",
        "\n",
        "            col1, col2, col3 = st.columns([2, 1, 1])\n",
        "\n",
        "            with col1:\n",
        "                ats_score = st.session_state.resume_analysis['ats_score']\n",
        "                st.markdown(f\"\"\"\n",
        "                    <div class=\"score-card {'excellent' if ats_score >= 80 else 'good' if ats_score >= 70 else 'fair'}\">\n",
        "                        <p class=\"score-value\">{ats_score}</p>\n",
        "                        <p class=\"score-label\">ATS Score / 100</p>\n",
        "                    </div>\n",
        "                \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "            with col2:\n",
        "                grade = st.session_state.resume_analysis['ats_grade']\n",
        "                st.markdown(f\"\"\"\n",
        "                    <div class=\"metric-card\">\n",
        "                        <div class=\"metric-value\">{grade}</div>\n",
        "                        <div class=\"metric-label\">Grade</div>\n",
        "                    </div>\n",
        "                \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "            with col3:\n",
        "                badge = format_score_badge(ats_score)\n",
        "                st.markdown(f\"\"\"\n",
        "                    <div class=\"info-box success\">\n",
        "                        <h3 style=\"margin:0;\">{badge}</h3>\n",
        "                    </div>\n",
        "                \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "            # Score breakdown\n",
        "            st.markdown(\"### üìã Score Breakdown\")\n",
        "            for feedback in st.session_state.resume_analysis['ats_feedback']:\n",
        "                if '‚úÖ' in feedback:\n",
        "                    st.markdown(f'<div class=\"info-box success\">{feedback}</div>', unsafe_allow_html=True)\n",
        "                elif '‚ö†Ô∏è' in feedback:\n",
        "                    st.markdown(f'<div class=\"info-box warning\">{feedback}</div>', unsafe_allow_html=True)\n",
        "                else:\n",
        "                    st.markdown(f'<div class=\"info-box error\">{feedback}</div>', unsafe_allow_html=True)\n",
        "\n",
        "            # Gemini AI Analysis\n",
        "            st.markdown(\"---\")\n",
        "            st.markdown(\"## ü§ñ AI-Powered Analysis\")\n",
        "\n",
        "            with st.expander(\"üìù Detailed Analysis\", expanded=True):\n",
        "                st.markdown(st.session_state.resume_analysis['gemini_analysis'])\n",
        "\n",
        "            # Improvement Suggestions\n",
        "            st.markdown(\"---\")\n",
        "            st.markdown(\"## üí° Improvement Suggestions\")\n",
        "\n",
        "            for i, suggestion in enumerate(st.session_state.resume_analysis['improvement_suggestions'], 1):\n",
        "                st.markdown(f\"{i}. {suggestion}\")\n",
        "\n",
        "            # Skills Display\n",
        "            st.markdown(\"---\")\n",
        "            st.markdown(\"## üéØ Identified Skills\")\n",
        "\n",
        "            skills = st.session_state.resume_data['skills']\n",
        "            skills_html = '<div style=\"margin: 1rem 0;\">'\n",
        "            for skill in skills:\n",
        "                skills_html += f'<span class=\"badge badge-info\">{skill}</span>'\n",
        "            skills_html += '</div>'\n",
        "            st.markdown(skills_html, unsafe_allow_html=True)\n",
        "'''\n",
        "\n",
        "# Save Part 1\n",
        "print(\"=\" * 60)\n",
        "print(\"üì± Streamlit App - Part 1 Created!\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\n‚ú® Pages included:\")\n",
        "print(\"   ‚Ä¢ Home Page with Quick Actions\")\n",
        "print(\"   ‚Ä¢ API Key Configuration (Sidebar)\")\n",
        "print(\"   ‚Ä¢ Resume Upload & Analysis\")\n",
        "print(\"   ‚Ä¢ ATS Score Display\")\n",
        "print(\"   ‚Ä¢ AI Analysis with Gemini\")\n",
        "print(\"   ‚Ä¢ Improvement Suggestions\")\n",
        "print(\"\\nüíæ Ready to continue with Part 2!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2H6UxTgfTH3",
        "outputId": "cef6df2f-3e76-4fb3-93ee-32a3be4edf0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "üì± Streamlit App - Part 2 Created!\n",
            "============================================================\n",
            "\n",
            "‚ú® Pages added:\n",
            "   ‚Ä¢ Job Matcher Page\n",
            "     - Job description input\n",
            "     - Match score calculation\n",
            "     - Skills gap analysis\n",
            "     - AI match report\n",
            "     - Cover letter generation\n",
            "   ‚Ä¢ Mock Interview Page\n",
            "     - Interview configuration\n",
            "     - Question generation\n",
            "     - Answer submission\n",
            "     - Real-time evaluation\n",
            "     - Detailed results\n",
            "     - Improvement plan\n",
            "\n",
            "üíæ Ready to continue with Part 3 (Dashboard)!\n"
          ]
        }
      ],
      "source": [
        "# Cell 12: Main Streamlit Application - Part 2\n",
        "\n",
        "APP_CODE_PART_2 = '''\n",
        "\n",
        "    elif page == \"üéØ Job Matcher\":\n",
        "        st.markdown(\"\"\"\n",
        "            <div class=\"main-header\">\n",
        "                <h1>üéØ Job Description Matcher</h1>\n",
        "                <p>Compare your resume with job descriptions</p>\n",
        "            </div>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        if not st.session_state.resume_data:\n",
        "            st.warning(\"‚ö†Ô∏è Please upload and analyze your resume first!\")\n",
        "            if st.button(\"üìÑ Go to Resume Analysis\"):\n",
        "                st.session_state.page = \"üìÑ Resume Analysis\"\n",
        "                st.rerun()\n",
        "        else:\n",
        "            st.markdown(\"## üìã Paste Job Description\")\n",
        "\n",
        "            job_description = st.text_area(\n",
        "                \"Job Description\",\n",
        "                height=300,\n",
        "                placeholder=\"Paste the complete job description here...\",\n",
        "                help=\"Include requirements, qualifications, and responsibilities\"\n",
        "            )\n",
        "\n",
        "            if st.button(\"üîç Analyze Match\", type=\"primary\", disabled=not job_description):\n",
        "                with st.spinner(\"Analyzing job match...\"):\n",
        "                    try:\n",
        "                        # Perform job match analysis\n",
        "                        match_analysis = complete_job_match_analysis(\n",
        "                            st.session_state.resume_data,\n",
        "                            job_description\n",
        "                        )\n",
        "                        st.session_state.job_match_analysis = match_analysis\n",
        "                        st.success(\"‚úÖ Job match analysis complete!\")\n",
        "                        st.rerun()\n",
        "                    except Exception as e:\n",
        "                        st.error(f\"‚ùå Analysis failed: {str(e)}\")\n",
        "\n",
        "            if st.session_state.job_match_analysis:\n",
        "                st.markdown(\"---\")\n",
        "\n",
        "                # Match Score Display\n",
        "                st.markdown(\"## üìä Match Score\")\n",
        "\n",
        "                match_score = st.session_state.job_match_analysis['match_percentage']\n",
        "\n",
        "                col1, col2 = st.columns([2, 1])\n",
        "\n",
        "                with col1:\n",
        "                    st.markdown(f\"\"\"\n",
        "                        <div class=\"score-card {'excellent' if match_score >= 80 else 'good' if match_score >= 65 else 'fair'}\">\n",
        "                            <p class=\"score-value\">{match_score:.1f}%</p>\n",
        "                            <p class=\"score-label\">Match Score</p>\n",
        "                        </div>\n",
        "                    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "                with col2:\n",
        "                    grade = st.session_state.job_match_analysis['match_grade']\n",
        "                    st.markdown(f\"\"\"\n",
        "                        <div class=\"metric-card\">\n",
        "                            <div class=\"metric-value\" style=\"font-size: 1.5rem;\">{grade}</div>\n",
        "                            <div class=\"metric-label\">Match Grade</div>\n",
        "                        </div>\n",
        "                    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "                # Score Breakdown\n",
        "                st.markdown(\"---\")\n",
        "                st.markdown(\"## üìà Detailed Breakdown\")\n",
        "\n",
        "                breakdown = st.session_state.job_match_analysis['breakdown']\n",
        "\n",
        "                col1, col2, col3, col4 = st.columns(4)\n",
        "\n",
        "                with col1:\n",
        "                    skills_score = breakdown['skills']['score']\n",
        "                    skills_max = breakdown['skills']['max']\n",
        "                    st.markdown(f\"\"\"\n",
        "                        <div class=\"metric-card\">\n",
        "                            <div class=\"metric-value\">{skills_score}/{skills_max}</div>\n",
        "                            <div class=\"metric-label\">Skills Match</div>\n",
        "                        </div>\n",
        "                    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "                with col2:\n",
        "                    exp_score = breakdown['experience']['score']\n",
        "                    exp_max = breakdown['experience']['max']\n",
        "                    st.markdown(f\"\"\"\n",
        "                        <div class=\"metric-card\">\n",
        "                            <div class=\"metric-value\">{exp_score}/{exp_max}</div>\n",
        "                            <div class=\"metric-label\">Experience</div>\n",
        "                        </div>\n",
        "                    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "                with col3:\n",
        "                    edu_score = breakdown['education']['score']\n",
        "                    edu_max = breakdown['education']['max']\n",
        "                    st.markdown(f\"\"\"\n",
        "                        <div class=\"metric-card\">\n",
        "                            <div class=\"metric-value\">{edu_score}/{edu_max}</div>\n",
        "                            <div class=\"metric-label\">Education</div>\n",
        "                        </div>\n",
        "                    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "                with col4:\n",
        "                    quality_score = breakdown['quality']['score']\n",
        "                    quality_max = breakdown['quality']['max']\n",
        "                    st.markdown(f\"\"\"\n",
        "                        <div class=\"metric-card\">\n",
        "                            <div class=\"metric-value\">{quality_score}/{quality_max}</div>\n",
        "                            <div class=\"metric-label\">Profile Quality</div>\n",
        "                        </div>\n",
        "                    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "                # Skills Analysis\n",
        "                st.markdown(\"---\")\n",
        "                st.markdown(\"## üéØ Skills Analysis\")\n",
        "\n",
        "                col1, col2 = st.columns(2)\n",
        "\n",
        "                with col1:\n",
        "                    st.markdown(\"### ‚úÖ Matching Skills\")\n",
        "                    matching_skills = st.session_state.job_match_analysis['matching_skills']\n",
        "                    if matching_skills:\n",
        "                        skills_html = '<div style=\"margin: 1rem 0;\">'\n",
        "                        for skill in matching_skills:\n",
        "                            skills_html += f'<span class=\"badge badge-success\">{skill}</span>'\n",
        "                        skills_html += '</div>'\n",
        "                        st.markdown(skills_html, unsafe_allow_html=True)\n",
        "                    else:\n",
        "                        st.info(\"No matching skills found\")\n",
        "\n",
        "                with col2:\n",
        "                    st.markdown(\"### ‚ùå Missing Skills\")\n",
        "                    missing_skills = st.session_state.job_match_analysis['missing_skills']\n",
        "                    if missing_skills:\n",
        "                        skills_html = '<div style=\"margin: 1rem 0;\">'\n",
        "                        for skill in missing_skills[:10]:  # Limit to 10\n",
        "                            skills_html += f'<span class=\"badge badge-danger\">{skill}</span>'\n",
        "                        skills_html += '</div>'\n",
        "                        st.markdown(skills_html, unsafe_allow_html=True)\n",
        "                    else:\n",
        "                        st.success(\"All required skills present!\")\n",
        "\n",
        "                # AI Match Report\n",
        "                st.markdown(\"---\")\n",
        "                st.markdown(\"## ü§ñ AI Match Analysis\")\n",
        "\n",
        "                with st.expander(\"üìù Detailed Match Report\", expanded=True):\n",
        "                    st.markdown(st.session_state.job_match_analysis['gemini_report'])\n",
        "\n",
        "                # Cover Letter\n",
        "                st.markdown(\"---\")\n",
        "                st.markdown(\"## ‚úçÔ∏è AI-Generated Cover Letter\")\n",
        "\n",
        "                cover_letter = st.session_state.job_match_analysis['cover_letter']\n",
        "                st.text_area(\"Your Cover Letter\", cover_letter, height=400)\n",
        "\n",
        "                # Download button\n",
        "                st.download_button(\n",
        "                    label=\"üì• Download Cover Letter\",\n",
        "                    data=cover_letter,\n",
        "                    file_name=\"cover_letter.txt\",\n",
        "                    mime=\"text/plain\"\n",
        "                )\n",
        "\n",
        "    elif page == \"üé§ Mock Interview\":\n",
        "        st.markdown(\"\"\"\n",
        "            <div class=\"main-header\">\n",
        "                <h1>üé§ Mock Interview Practice</h1>\n",
        "                <p>Practice with AI-generated interview questions</p>\n",
        "            </div>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        if not st.session_state.resume_data:\n",
        "            st.warning(\"‚ö†Ô∏è Please upload and analyze your resume first!\")\n",
        "            if st.button(\"üìÑ Go to Resume Analysis\"):\n",
        "                st.session_state.page = \"üìÑ Resume Analysis\"\n",
        "                st.rerun()\n",
        "        else:\n",
        "            # Interview Configuration\n",
        "            st.markdown(\"## ‚öôÔ∏è Interview Configuration\")\n",
        "\n",
        "            col1, col2 = st.columns(2)\n",
        "\n",
        "            with col1:\n",
        "                interview_type = st.selectbox(\n",
        "                    \"Interview Type\",\n",
        "                    [\"Technical\", \"Behavioral\", \"Mixed\", \"Full\"],\n",
        "                    help=\"Choose the type of interview you want to practice\"\n",
        "                )\n",
        "\n",
        "            with col2:\n",
        "                difficulty = st.selectbox(\n",
        "                    \"Difficulty Level\",\n",
        "                    [\"Easy\", \"Medium\", \"Hard\"],\n",
        "                    index=1\n",
        "                )\n",
        "\n",
        "            if st.button(\"üéØ Generate Interview Questions\", type=\"primary\"):\n",
        "                with st.spinner(\"Generating personalized questions...\"):\n",
        "                    try:\n",
        "                        # Generate questions\n",
        "                        interview_set = generate_complete_interview_set(\n",
        "                            st.session_state.resume_data,\n",
        "                            interview_type,\n",
        "                            difficulty\n",
        "                        )\n",
        "                        st.session_state.current_interview = {\n",
        "                            'questions': interview_set['questions'],\n",
        "                            'answers': [],\n",
        "                            'current_question': 0,\n",
        "                            'interview_type': interview_type,\n",
        "                            'difficulty': difficulty\n",
        "                        }\n",
        "                        st.success(f\"‚úÖ Generated {len(interview_set['questions'])} questions!\")\n",
        "                        st.rerun()\n",
        "                    except Exception as e:\n",
        "                        st.error(f\"‚ùå Question generation failed: {str(e)}\")\n",
        "\n",
        "            # Interview Session\n",
        "            if st.session_state.current_interview:\n",
        "                st.markdown(\"---\")\n",
        "\n",
        "                questions = st.session_state.current_interview['questions']\n",
        "                current_q = st.session_state.current_interview['current_question']\n",
        "\n",
        "                # Progress bar\n",
        "                progress = (current_q / len(questions)) * 100\n",
        "                st.progress(current_q / len(questions))\n",
        "                st.markdown(f\"**Progress:** Question {current_q + 1} of {len(questions)} ({progress:.0f}%)\")\n",
        "\n",
        "                if current_q < len(questions):\n",
        "                    # Display current question\n",
        "                    question_obj = questions[current_q]\n",
        "\n",
        "                    st.markdown(f\"\"\"\n",
        "                        <div class=\"question-card\">\n",
        "                            <span class=\"question-number\">Question {current_q + 1}</span>\n",
        "                            <span class=\"badge badge-info\" style=\"margin-left: 0.5rem;\">{question_obj['type']}</span>\n",
        "                            <span class=\"badge badge-warning\" style=\"margin-left: 0.5rem;\">{question_obj['difficulty']}</span>\n",
        "                            <p style=\"margin-top: 1rem; font-size: 1.1rem; color: #1f2937;\">{question_obj['question']}</p>\n",
        "                        </div>\n",
        "                    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "                    # Answer input\n",
        "                    answer = st.text_area(\n",
        "                        \"Your Answer\",\n",
        "                        height=200,\n",
        "                        placeholder=\"Type your answer here...\",\n",
        "                        key=f\"answer_{current_q}\"\n",
        "                    )\n",
        "\n",
        "                    col1, col2, col3 = st.columns([1, 1, 2])\n",
        "\n",
        "                    with col1:\n",
        "                        if st.button(\"‚è≠Ô∏è Skip Question\"):\n",
        "                            st.session_state.current_interview['answers'].append(\"\")\n",
        "                            st.session_state.current_interview['current_question'] += 1\n",
        "                            st.rerun()\n",
        "\n",
        "                    with col2:\n",
        "                        if st.button(\"‚úÖ Submit Answer\", type=\"primary\", disabled=not answer):\n",
        "                            st.session_state.current_interview['answers'].append(answer)\n",
        "                            st.session_state.current_interview['current_question'] += 1\n",
        "                            st.rerun()\n",
        "\n",
        "                else:\n",
        "                    # Interview completed - show evaluation\n",
        "                    st.markdown(\"---\")\n",
        "                    st.success(\"üéâ Interview Complete! Evaluating your answers...\")\n",
        "\n",
        "                    if st.button(\"üìä View Results\", type=\"primary\"):\n",
        "                        with st.spinner(\"Evaluating your performance...\"):\n",
        "                            try:\n",
        "                                # Evaluate all answers\n",
        "                                results = conduct_mock_interview(\n",
        "                                    st.session_state.resume_data,\n",
        "                                    questions,\n",
        "                                    st.session_state.current_interview['answers']\n",
        "                                )\n",
        "\n",
        "                                # Save to history\n",
        "                                results['interview_type'] = st.session_state.current_interview['interview_type']\n",
        "                                save_interview_results(results)\n",
        "\n",
        "                                # Clear current interview\n",
        "                                st.session_state.current_interview = None\n",
        "                                st.session_state.interview_results = results\n",
        "\n",
        "                                st.rerun()\n",
        "                            except Exception as e:\n",
        "                                st.error(f\"‚ùå Evaluation failed: {str(e)}\")\n",
        "\n",
        "            # Show results if available\n",
        "            if 'interview_results' in st.session_state and st.session_state.interview_results:\n",
        "                st.markdown(\"---\")\n",
        "                st.markdown(\"## üìä Interview Results\")\n",
        "\n",
        "                results = st.session_state.interview_results\n",
        "\n",
        "                # Overall stats\n",
        "                col1, col2, col3, col4 = st.columns(4)\n",
        "\n",
        "                with col1:\n",
        "                    st.markdown(f\"\"\"\n",
        "                        <div class=\"score-card {'excellent' if results['overall_percentage'] >= 80 else 'good' if results['overall_percentage'] >= 70 else 'fair'}\">\n",
        "                            <p class=\"score-value\">{results['overall_percentage']:.1f}%</p>\n",
        "                            <p class=\"score-label\">Overall Score</p>\n",
        "                        </div>\n",
        "                    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "                with col2:\n",
        "                    st.markdown(f\"\"\"\n",
        "                        <div class=\"metric-card\">\n",
        "                            <div class=\"metric-value\">{results['total_questions']}</div>\n",
        "                            <div class=\"metric-label\">Total Questions</div>\n",
        "                        </div>\n",
        "                    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "                with col3:\n",
        "                    st.markdown(f\"\"\"\n",
        "                        <div class=\"metric-card\">\n",
        "                            <div class=\"metric-value\">{len(results['strengths'])}</div>\n",
        "                            <div class=\"metric-label\">Strong Areas</div>\n",
        "                        </div>\n",
        "                    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "                with col4:\n",
        "                    st.markdown(f\"\"\"\n",
        "                        <div class=\"metric-card\">\n",
        "                            <div class=\"metric-value\">{results['average_confidence']:.0f}%</div>\n",
        "                            <div class=\"metric-label\">Confidence</div>\n",
        "                        </div>\n",
        "                    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "                # Motivation message\n",
        "                msg = get_motivational_message(results['overall_percentage'])\n",
        "                st.markdown(f'<div class=\"info-box success\"><h3>{msg}</h3></div>', unsafe_allow_html=True)\n",
        "\n",
        "                # Question-by-question results\n",
        "                st.markdown(\"---\")\n",
        "                st.markdown(\"## üìù Detailed Results\")\n",
        "\n",
        "                for i, result in enumerate(results['results'], 1):\n",
        "                    with st.expander(f\"Question {i} - Score: {result['scores']['percentage']:.1f}% ({result['grade']})\"):\n",
        "                        st.markdown(f\"**Question ({result['question_type']}):**\")\n",
        "                        st.info(result['question'])\n",
        "\n",
        "                        st.markdown(\"**Your Answer:**\")\n",
        "                        st.text_area(\"\", result['answer'], height=100, disabled=True, key=f\"result_answer_{i}\")\n",
        "\n",
        "                        if result['evaluation']['success']:\n",
        "                            st.markdown(\"**Score Breakdown:**\")\n",
        "                            scores = result['scores']\n",
        "\n",
        "                            col1, col2, col3, col4, col5 = st.columns(5)\n",
        "\n",
        "                            with col1:\n",
        "                                st.metric(\"Relevance\", f\"{scores['relevance']}/10\")\n",
        "                            with col2:\n",
        "                                st.metric(\"Accuracy\", f\"{scores['technical_accuracy']}/10\")\n",
        "                            with col3:\n",
        "                                st.metric(\"Communication\", f\"{scores['communication']}/10\")\n",
        "                            with col4:\n",
        "                                st.metric(\"Depth\", f\"{scores['depth']}/10\")\n",
        "                            with col5:\n",
        "                                st.metric(\"Completeness\", f\"{scores['completeness']}/10\")\n",
        "\n",
        "                            st.markdown(\"**AI Feedback:**\")\n",
        "                            st.markdown(result['evaluation']['full_evaluation'])\n",
        "\n",
        "                # Improvement Plan\n",
        "                st.markdown(\"---\")\n",
        "                st.markdown(\"## üìà Personalized Improvement Plan\")\n",
        "\n",
        "                improvement_plan = generate_improvement_plan(results)\n",
        "                st.markdown(improvement_plan)\n",
        "\n",
        "                # Download report\n",
        "                st.markdown(\"---\")\n",
        "                report = generate_text_report(results)\n",
        "                st.download_button(\n",
        "                    label=\"üì• Download Full Report\",\n",
        "                    data=report,\n",
        "                    file_name=f\"interview_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\",\n",
        "                    mime=\"text/plain\"\n",
        "                )\n",
        "\n",
        "                if st.button(\"üîÑ Start New Interview\"):\n",
        "                    st.session_state.interview_results = None\n",
        "                    st.rerun()\n",
        "'''\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üì± Streamlit App - Part 2 Created!\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\n‚ú® Pages added:\")\n",
        "print(\"   ‚Ä¢ Job Matcher Page\")\n",
        "print(\"     - Job description input\")\n",
        "print(\"     - Match score calculation\")\n",
        "print(\"     - Skills gap analysis\")\n",
        "print(\"     - AI match report\")\n",
        "print(\"     - Cover letter generation\")\n",
        "print(\"   ‚Ä¢ Mock Interview Page\")\n",
        "print(\"     - Interview configuration\")\n",
        "print(\"     - Question generation\")\n",
        "print(\"     - Answer submission\")\n",
        "print(\"     - Real-time evaluation\")\n",
        "print(\"     - Detailed results\")\n",
        "print(\"     - Improvement plan\")\n",
        "print(\"\\nüíæ Ready to continue with Part 3 (Dashboard)!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYZ9qbn1gpxQ",
        "outputId": "18bbb05d-c04e-466f-b74d-b0bc0a11aa30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "üì± Complete Streamlit App Created!\n",
            "============================================================\n",
            "\n",
            "‚ú® Final app includes:\n",
            "   ‚Ä¢ All pages (Home, Resume, Job Match, Interview, Dashboard)\n",
            "   ‚Ä¢ All AI functions (Groq + Gemini)\n",
            "   ‚Ä¢ Session management\n",
            "   ‚Ä¢ Beautiful UI components\n",
            "   ‚Ä¢ Performance analytics\n",
            "   ‚Ä¢ Export capabilities\n",
            "\n",
            "üíæ Ready to save as app.py!\n"
          ]
        }
      ],
      "source": [
        "# Cell 13: Main Streamlit Application - Part 3 (Final)\n",
        "\n",
        "APP_CODE_PART_3 = '''\n",
        "\n",
        "    elif page == \"üìä Dashboard\":\n",
        "        st.markdown(\"\"\"\n",
        "            <div class=\"main-header\">\n",
        "                <h1>üìä Performance Dashboard</h1>\n",
        "                <p>Track your interview preparation progress</p>\n",
        "            </div>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        if not SESSION_DATA['interview_history']:\n",
        "            st.info(\"üé§ Complete some mock interviews to see your performance dashboard!\")\n",
        "\n",
        "            if st.button(\"üéØ Start Your First Interview\"):\n",
        "                st.session_state.page = \"üé§ Mock Interview\"\n",
        "                st.rerun()\n",
        "        else:\n",
        "            # Overall Statistics\n",
        "            st.markdown(\"## üìà Overall Statistics\")\n",
        "\n",
        "            total_interviews = len(SESSION_DATA['interview_history'])\n",
        "            total_questions = SESSION_DATA['user_profile']['total_questions_answered']\n",
        "            avg_score = SESSION_DATA['user_profile']['average_score']\n",
        "\n",
        "            col1, col2, col3 = st.columns(3)\n",
        "\n",
        "            with col1:\n",
        "                st.markdown(f\"\"\"\n",
        "                    <div class=\"metric-card\">\n",
        "                        <div class=\"metric-value\">{total_interviews}</div>\n",
        "                        <div class=\"metric-label\">Interviews Completed</div>\n",
        "                    </div>\n",
        "                \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "            with col2:\n",
        "                st.markdown(f\"\"\"\n",
        "                    <div class=\"metric-card\">\n",
        "                        <div class=\"metric-value\">{total_questions}</div>\n",
        "                        <div class=\"metric-label\">Questions Answered</div>\n",
        "                    </div>\n",
        "                \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "            with col3:\n",
        "                st.markdown(f\"\"\"\n",
        "                    <div class=\"score-card {'excellent' if avg_score >= 80 else 'good' if avg_score >= 70 else 'fair'}\">\n",
        "                        <p class=\"score-value\">{avg_score:.1f}%</p>\n",
        "                        <p class=\"score-label\">Average Score</p>\n",
        "                    </div>\n",
        "                \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "            # Performance Trend Chart\n",
        "            st.markdown(\"---\")\n",
        "            st.markdown(\"## üìà Score Trend Over Time\")\n",
        "\n",
        "            chart_data = create_performance_chart_data()\n",
        "\n",
        "            if chart_data['has_data']:\n",
        "                # Line chart for score trend\n",
        "                fig = go.Figure()\n",
        "\n",
        "                fig.add_trace(go.Scatter(\n",
        "                    x=chart_data['score_trend']['sessions'],\n",
        "                    y=chart_data['score_trend']['scores'],\n",
        "                    mode='lines+markers',\n",
        "                    name='Score',\n",
        "                    line=dict(color='#667eea', width=3),\n",
        "                    marker=dict(size=10, color='#764ba2')\n",
        "                ))\n",
        "\n",
        "                fig.update_layout(\n",
        "                    title=\"Interview Score Progression\",\n",
        "                    xaxis_title=\"Interview Session\",\n",
        "                    yaxis_title=\"Score (%)\",\n",
        "                    height=400,\n",
        "                    hovermode='x unified',\n",
        "                    plot_bgcolor='white',\n",
        "                    yaxis=dict(range=[0, 100])\n",
        "                )\n",
        "\n",
        "                st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "                # Performance trend analysis\n",
        "                trends = calculate_performance_trends()\n",
        "\n",
        "                if trends['improvement'] > 0:\n",
        "                    st.success(f\"üìà {trends['trend']} - You've improved by {trends['improvement']:.1f}% since your first interview!\")\n",
        "                elif trends['improvement'] == 0:\n",
        "                    st.info(f\"‚û°Ô∏è {trends['trend']} - Maintain consistency and keep practicing!\")\n",
        "                else:\n",
        "                    st.warning(f\"üìâ {trends['trend']} - Focus on your weak areas to improve!\")\n",
        "\n",
        "            # Question Type Performance\n",
        "            st.markdown(\"---\")\n",
        "            st.markdown(\"## üéØ Performance by Question Type\")\n",
        "\n",
        "            type_performance = analyze_question_type_performance()\n",
        "\n",
        "            if type_performance:\n",
        "                col1, col2 = st.columns(2)\n",
        "\n",
        "                with col1:\n",
        "                    # Bar chart\n",
        "                    types = list(type_performance.keys())\n",
        "                    averages = [type_performance[t]['average'] for t in types]\n",
        "\n",
        "                    fig = go.Figure(data=[\n",
        "                        go.Bar(\n",
        "                            x=types,\n",
        "                            y=averages,\n",
        "                            marker_color=['#667eea', '#764ba2', '#f59e0b', '#10b981']\n",
        "                        )\n",
        "                    ])\n",
        "\n",
        "                    fig.update_layout(\n",
        "                        title=\"Average Score by Question Type\",\n",
        "                        xaxis_title=\"Question Type\",\n",
        "                        yaxis_title=\"Average Score (%)\",\n",
        "                        height=350,\n",
        "                        yaxis=dict(range=[0, 100])\n",
        "                    )\n",
        "\n",
        "                    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "                with col2:\n",
        "                    # Radar chart\n",
        "                    fig = go.Figure()\n",
        "\n",
        "                    fig.add_trace(go.Scatterpolar(\n",
        "                        r=averages,\n",
        "                        theta=types,\n",
        "                        fill='toself',\n",
        "                        fillcolor='rgba(102, 126, 234, 0.3)',\n",
        "                        line=dict(color='#667eea', width=2)\n",
        "                    ))\n",
        "\n",
        "                    fig.update_layout(\n",
        "                        polar=dict(\n",
        "                            radialaxis=dict(\n",
        "                                visible=True,\n",
        "                                range=[0, 100]\n",
        "                            )\n",
        "                        ),\n",
        "                        title=\"Skill Radar Chart\",\n",
        "                        height=350\n",
        "                    )\n",
        "\n",
        "                    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "                # Detailed breakdown\n",
        "                st.markdown(\"### üìä Detailed Breakdown\")\n",
        "\n",
        "                for q_type, stats in type_performance.items():\n",
        "                    with st.expander(f\"{q_type} Questions\"):\n",
        "                        col1, col2, col3, col4 = st.columns(4)\n",
        "\n",
        "                        with col1:\n",
        "                            st.metric(\"Average\", f\"{stats['average']:.1f}%\")\n",
        "                        with col2:\n",
        "                            st.metric(\"Questions\", stats['count'])\n",
        "                        with col3:\n",
        "                            st.metric(\"Best\", f\"{stats['best']:.1f}%\")\n",
        "                        with col4:\n",
        "                            st.metric(\"Worst\", f\"{stats['worst']:.1f}%\")\n",
        "\n",
        "            # Interview History\n",
        "            st.markdown(\"---\")\n",
        "            st.markdown(\"## üìö Interview History\")\n",
        "\n",
        "            history_data = []\n",
        "            for i, interview in enumerate(reversed(SESSION_DATA['interview_history']), 1):\n",
        "                history_data.append({\n",
        "                    'Session': len(SESSION_DATA['interview_history']) - i + 1,\n",
        "                    'Date': interview['timestamp'],\n",
        "                    'Type': interview['interview_type'],\n",
        "                    'Questions': interview['total_questions'],\n",
        "                    'Score': f\"{interview['overall_score']:.1f}%\",\n",
        "                    'Grade': interview['grade']\n",
        "                })\n",
        "\n",
        "            df = pd.DataFrame(history_data)\n",
        "            st.dataframe(df, use_container_width=True, hide_index=True)\n",
        "\n",
        "            # Export Options\n",
        "            st.markdown(\"---\")\n",
        "            st.markdown(\"## üíæ Export Data\")\n",
        "\n",
        "            col1, col2 = st.columns(2)\n",
        "\n",
        "            with col1:\n",
        "                # Export JSON\n",
        "                json_data = export_session_data_to_json()\n",
        "                st.download_button(\n",
        "                    label=\"üì• Download Session Data (JSON)\",\n",
        "                    data=json_data,\n",
        "                    file_name=f\"interview_data_{datetime.now().strftime('%Y%m%d')}.json\",\n",
        "                    mime=\"application/json\"\n",
        "                )\n",
        "\n",
        "            with col2:\n",
        "                # Clear history option\n",
        "                if st.button(\"üóëÔ∏è Clear All History\", type=\"secondary\"):\n",
        "                    if st.checkbox(\"‚ö†Ô∏è Are you sure? This cannot be undone!\"):\n",
        "                        initialize_session()\n",
        "                        st.success(\"‚úÖ History cleared!\")\n",
        "                        st.rerun()\n",
        "\n",
        "# Footer\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"\"\"\n",
        "    <div style=\"text-align: center; color: #6b7280; padding: 2rem;\">\n",
        "        <p>Made with ‚ù§Ô∏è using Streamlit, Groq, and Gemini AI</p>\n",
        "        <p style=\"font-size: 0.9rem;\">üéØ AI Interview Prep & Resume Analyzer v1.0</p>\n",
        "    </div>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "'''\n",
        "\n",
        "# Now combine all parts and add all the helper functions\n",
        "COMPLETE_APP_CODE = f'''\n",
        "{APP_CODE_PART_1}\n",
        "{APP_CODE_PART_2}\n",
        "{APP_CODE_PART_3}\n",
        "'''\n",
        "\n",
        "# Add all the function definitions at the beginning\n",
        "COMPLETE_APP_WITH_FUNCTIONS = f'''\n",
        "import streamlit as st\n",
        "import PyPDF2\n",
        "import pdfplumber\n",
        "from groq import Groq\n",
        "import google.generativeai as genai\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import json\n",
        "import re\n",
        "from typing import Dict, List, Optional\n",
        "\n",
        "# ============================================================================\n",
        "# HELPER FUNCTIONS FROM PREVIOUS CELLS\n",
        "# ============================================================================\n",
        "\n",
        "# PDF Parser Functions (from Cell 4)\n",
        "def extract_text_from_pdf(pdf_file) -> str:\n",
        "    \"\"\"Extract text from uploaded PDF file.\"\"\"\n",
        "    text = \"\"\n",
        "    try:\n",
        "        with pdfplumber.open(pdf_file) as pdf:\n",
        "            for page in pdf.pages:\n",
        "                page_text = page.extract_text()\n",
        "                if page_text:\n",
        "                    text += page_text + \"\\\\n\"\n",
        "        if text.strip():\n",
        "            return text\n",
        "    except Exception as e:\n",
        "        try:\n",
        "            pdf_file.seek(0)\n",
        "            pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "            for page_num in range(len(pdf_reader.pages)):\n",
        "                page = pdf_reader.pages[page_num]\n",
        "                text += page.extract_text() + \"\\\\n\"\n",
        "            return text\n",
        "        except:\n",
        "            return \"\"\n",
        "    return text\n",
        "\n",
        "def extract_email(text: str) -> str:\n",
        "    \"\"\"Extract email address from text.\"\"\"\n",
        "    email_pattern = r'\\\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Z|a-z]{{2,}}\\\\b'\n",
        "    emails = re.findall(email_pattern, text)\n",
        "    return emails[0] if emails else \"Not found\"\n",
        "\n",
        "def extract_phone(text: str) -> str:\n",
        "    \"\"\"Extract phone number from text.\"\"\"\n",
        "    phone_patterns = [\n",
        "        r'\\\\+?\\\\d{{1,3}}[-\\\\.\\\\s]?\\\\(?\\\\d{{3}}\\\\)?[-\\\\.\\\\s]?\\\\d{{3}}[-\\\\.\\\\s]?\\\\d{{4}}',\n",
        "        r'\\\\+?\\\\d{{10,}}',\n",
        "        r'\\\\d{{3}}-\\\\d{{3}}-\\\\d{{4}}',\n",
        "    ]\n",
        "    for pattern in phone_patterns:\n",
        "        phones = re.findall(pattern, text)\n",
        "        if phones:\n",
        "            return phones[0]\n",
        "    return \"Not found\"\n",
        "\n",
        "def extract_skills(text: str) -> List[str]:\n",
        "    \"\"\"Extract technical skills from resume text.\"\"\"\n",
        "    skills_database = [\n",
        "        'python', 'java', 'javascript', 'c++', 'c#', 'ruby', 'php', 'swift',\n",
        "        'kotlin', 'go', 'rust', 'typescript', 'scala', 'r', 'matlab',\n",
        "        'html', 'css', 'react', 'angular', 'vue', 'node.js', 'express',\n",
        "        'django', 'flask', 'spring boot', 'asp.net', 'jquery',\n",
        "        'sql', 'mysql', 'postgresql', 'mongodb', 'redis', 'oracle',\n",
        "        'sqlite', 'cassandra', 'dynamodb', 'firebase',\n",
        "        'aws', 'azure', 'gcp', 'docker', 'kubernetes', 'jenkins', 'git',\n",
        "        'ci/cd', 'terraform', 'ansible', 'linux', 'shell scripting',\n",
        "        'machine learning', 'deep learning', 'tensorflow', 'pytorch',\n",
        "        'scikit-learn', 'pandas', 'numpy', 'data analysis', 'statistics',\n",
        "        'nlp', 'computer vision', 'opencv',\n",
        "        'agile', 'scrum', 'jira', 'rest api', 'graphql', 'microservices',\n",
        "        'testing', 'debugging', 'problem solving', 'communication'\n",
        "    ]\n",
        "    text_lower = text.lower()\n",
        "    found_skills = []\n",
        "    for skill in skills_database:\n",
        "        if skill in text_lower:\n",
        "            found_skills.append(skill.title())\n",
        "    return sorted(list(set(found_skills)))\n",
        "\n",
        "def extract_education(text: str) -> List[str]:\n",
        "    \"\"\"Extract education information.\"\"\"\n",
        "    education_keywords = ['bachelor', 'master', 'phd', 'b.tech', 'm.tech',\n",
        "                         'b.e', 'm.e', 'bca', 'mca', 'degree', 'university',\n",
        "                         'college', 'institute', 'b.sc', 'm.sc']\n",
        "    lines = text.split('\\\\n')\n",
        "    education = []\n",
        "    for i, line in enumerate(lines):\n",
        "        line_lower = line.lower()\n",
        "        if any(keyword in line_lower for keyword in education_keywords):\n",
        "            edu_text = ' '.join(lines[i:i+3]).strip()\n",
        "            if edu_text and len(edu_text) > 10:\n",
        "                education.append(edu_text[:200])\n",
        "    return education[:3]\n",
        "\n",
        "def extract_experience(text: str) -> List[Dict[str, str]]:\n",
        "    \"\"\"Extract work experience details.\"\"\"\n",
        "    experience = []\n",
        "    job_keywords = ['engineer', 'developer', 'analyst', 'manager', 'designer',\n",
        "                   'consultant', 'intern', 'associate', 'specialist', 'lead']\n",
        "    lines = text.split('\\\\n')\n",
        "    for i, line in enumerate(lines):\n",
        "        line_lower = line.lower()\n",
        "        if any(keyword in line_lower for keyword in job_keywords):\n",
        "            exp_entry = {{\n",
        "                'title': line.strip()[:100],\n",
        "                'description': ' '.join(lines[i+1:i+4]).strip()[:300]\n",
        "            }}\n",
        "            experience.append(exp_entry)\n",
        "    return experience[:5]\n",
        "\n",
        "def structure_resume_data(text: str) -> Dict:\n",
        "    \"\"\"Main function to structure all extracted resume data.\"\"\"\n",
        "    structured_data = {{\n",
        "        'raw_text': text,\n",
        "        'email': extract_email(text),\n",
        "        'phone': extract_phone(text),\n",
        "        'skills': extract_skills(text),\n",
        "        'education': extract_education(text),\n",
        "        'experience': extract_experience(text),\n",
        "        'total_words': len(text.split()),\n",
        "        'total_characters': len(text)\n",
        "    }}\n",
        "    return structured_data\n",
        "\n",
        "# Resume Analysis Functions (from Cell 5)\n",
        "def calculate_ats_score(resume_data: Dict) -> Dict:\n",
        "    \"\"\"Calculate ATS compatibility score.\"\"\"\n",
        "    score = 0\n",
        "    max_score = 100\n",
        "    feedback = []\n",
        "\n",
        "    if resume_data['email'] != \"Not found\":\n",
        "        score += 8\n",
        "        feedback.append(\"‚úÖ Email found\")\n",
        "    else:\n",
        "        feedback.append(\"‚ùå Missing email address\")\n",
        "\n",
        "    if resume_data['phone'] != \"Not found\":\n",
        "        score += 7\n",
        "        feedback.append(\"‚úÖ Phone number found\")\n",
        "    else:\n",
        "        feedback.append(\"‚ùå Missing phone number\")\n",
        "\n",
        "    num_skills = len(resume_data['skills'])\n",
        "    if num_skills >= 10:\n",
        "        score += 30\n",
        "        feedback.append(f\"‚úÖ Strong skills section ({{num_skills}} skills)\")\n",
        "    elif num_skills >= 5:\n",
        "        score += 20\n",
        "        feedback.append(f\"‚ö†Ô∏è Moderate skills section ({{num_skills}} skills)\")\n",
        "    else:\n",
        "        score += 10\n",
        "        feedback.append(f\"‚ùå Weak skills section ({{num_skills}} skills)\")\n",
        "\n",
        "    if len(resume_data['education']) >= 1:\n",
        "        score += 15\n",
        "        feedback.append(\"‚úÖ Education section present\")\n",
        "    else:\n",
        "        feedback.append(\"‚ùå Missing education section\")\n",
        "\n",
        "    num_exp = len(resume_data['experience'])\n",
        "    if num_exp >= 3:\n",
        "        score += 25\n",
        "        feedback.append(f\"‚úÖ Strong experience section ({{num_exp}} entries)\")\n",
        "    elif num_exp >= 1:\n",
        "        score += 15\n",
        "        feedback.append(f\"‚ö†Ô∏è Limited experience ({{num_exp}} entries)\")\n",
        "    else:\n",
        "        feedback.append(\"‚ùå No experience section found\")\n",
        "\n",
        "    word_count = resume_data['total_words']\n",
        "    if 300 <= word_count <= 800:\n",
        "        score += 15\n",
        "        feedback.append(f\"‚úÖ Optimal length ({{word_count}} words)\")\n",
        "    elif word_count < 300:\n",
        "        score += 5\n",
        "        feedback.append(f\"‚ö†Ô∏è Too short ({{word_count}} words)\")\n",
        "    else:\n",
        "        score += 10\n",
        "        feedback.append(f\"‚ö†Ô∏è Too long ({{word_count}} words)\")\n",
        "\n",
        "    return {{\n",
        "        'score': score,\n",
        "        'grade': 'A+' if score >= 90 else 'A' if score >= 80 else 'B' if score >= 70 else 'C' if score >= 60 else 'D',\n",
        "        'feedback': feedback\n",
        "    }}\n",
        "\n",
        "def analyze_resume_with_gemini(resume_data: Dict, gemini_model) -> Dict:\n",
        "    \"\"\"Use Gemini AI to provide deep analysis.\"\"\"\n",
        "    prompt = f\"\"\"You are an expert resume reviewer. Analyze this resume and provide detailed feedback.\n",
        "\n",
        "RESUME DATA:\n",
        "- Total Words: {{resume_data['total_words']}}\n",
        "- Skills ({{len(resume_data['skills'])}}): {{', '.join(resume_data['skills'][:15])}}\n",
        "- Education Entries: {{len(resume_data['education'])}}\n",
        "- Experience Entries: {{len(resume_data['experience'])}}\n",
        "\n",
        "RESUME TEXT:\n",
        "{{resume_data['raw_text'][:3000]}}\n",
        "\n",
        "Provide:\n",
        "1. STRENGTHS (3-4 points)\n",
        "2. WEAKNESSES (3-4 points)\n",
        "3. MISSING KEYWORDS\n",
        "4. IMPROVEMENTS (5 suggestions)\n",
        "5. OVERALL IMPRESSION\n",
        "\n",
        "Format clearly with headers.\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = gemini_model.generate_content(prompt)\n",
        "        return {{'success': True, 'analysis': response.text}}\n",
        "    except Exception as e:\n",
        "        return {{'success': False, 'analysis': \"Analysis unavailable.\"}}\n",
        "\n",
        "def generate_improvement_suggestions(resume_data: Dict, ats_score: Dict) -> List[str]:\n",
        "    \"\"\"Generate improvement suggestions.\"\"\"\n",
        "    suggestions = []\n",
        "\n",
        "    if resume_data['email'] == \"Not found\":\n",
        "        suggestions.append(\"üî∏ Add a professional email address\")\n",
        "    if resume_data['phone'] == \"Not found\":\n",
        "        suggestions.append(\"üî∏ Include a contact phone number\")\n",
        "    if len(resume_data['skills']) < 8:\n",
        "        suggestions.append(\"üî∏ Add more technical skills (aim for 10-15)\")\n",
        "    if len(resume_data['education']) == 0:\n",
        "        suggestions.append(\"üî∏ Add Education section\")\n",
        "    if len(resume_data['experience']) < 2:\n",
        "        suggestions.append(\"üî∏ Add more work experience details\")\n",
        "    if resume_data['total_words'] < 300:\n",
        "        suggestions.append(\"üî∏ Expand with more details\")\n",
        "\n",
        "    suggestions.append(\"üî∏ Quantify achievements with numbers\")\n",
        "    suggestions.append(\"üî∏ Tailor resume for each job\")\n",
        "    suggestions.append(\"üî∏ Use industry-specific keywords\")\n",
        "\n",
        "    return suggestions[:8]\n",
        "\n",
        "def complete_resume_analysis(resume_data: Dict) -> Dict:\n",
        "    \"\"\"Complete resume analysis.\"\"\"\n",
        "    ats_result = calculate_ats_score(resume_data)\n",
        "    gemini_analysis = analyze_resume_with_gemini(resume_data, st.session_state.gemini_model)\n",
        "    suggestions = generate_improvement_suggestions(resume_data, ats_result)\n",
        "\n",
        "    return {{\n",
        "        'ats_score': ats_result['score'],\n",
        "        'ats_grade': ats_result['grade'],\n",
        "        'ats_feedback': ats_result['feedback'],\n",
        "        'gemini_analysis': gemini_analysis['analysis'],\n",
        "        'improvement_suggestions': suggestions,\n",
        "        'contact_info': {{\n",
        "            'email': resume_data['email'],\n",
        "            'phone': resume_data['phone']\n",
        "        }},\n",
        "        'stats': {{\n",
        "            'total_skills': len(resume_data['skills']),\n",
        "            'total_experience': len(resume_data['experience']),\n",
        "            'total_education': len(resume_data['education']),\n",
        "            'word_count': resume_data['total_words']\n",
        "        }}\n",
        "    }}\n",
        "\n",
        "# Job Matching Functions (from Cell 6)\n",
        "def extract_job_requirements(job_description: str) -> Dict:\n",
        "    \"\"\"Extract requirements from job description.\"\"\"\n",
        "    jd_lower = job_description.lower()\n",
        "\n",
        "    skills_database = [\n",
        "        'python', 'java', 'javascript', 'c++', 'c#', 'ruby', 'php', 'swift',\n",
        "        'kotlin', 'go', 'rust', 'typescript', 'sql', 'mysql', 'postgresql',\n",
        "        'mongodb', 'aws', 'azure', 'gcp', 'docker', 'kubernetes', 'react',\n",
        "        'angular', 'vue', 'node.js', 'django', 'flask', 'machine learning',\n",
        "        'data analysis', 'agile', 'scrum'\n",
        "    ]\n",
        "\n",
        "    required_skills = []\n",
        "    for skill in skills_database:\n",
        "        if skill in jd_lower:\n",
        "            required_skills.append(skill.title())\n",
        "\n",
        "    exp_pattern = r'(\\\\d+)\\\\+?\\\\s*(?:year|yr)s?\\\\s*(?:of\\\\s*)?(?:experience|exp)'\n",
        "    exp_matches = re.findall(exp_pattern, jd_lower)\n",
        "    required_experience = int(exp_matches[0]) if exp_matches else 0\n",
        "\n",
        "    education_keywords = ['bachelor', 'master', 'phd', 'b.tech', 'm.tech', 'degree']\n",
        "    required_education = any(keyword in jd_lower for keyword in education_keywords)\n",
        "\n",
        "    return {{\n",
        "        'required_skills': required_skills,\n",
        "        'required_experience': required_experience,\n",
        "        'required_education': required_education,\n",
        "        'total_words': len(job_description.split())\n",
        "    }}\n",
        "\n",
        "def calculate_match_score(resume_data: Dict, job_requirements: Dict) -> Dict:\n",
        "    \"\"\"Calculate match score.\"\"\"\n",
        "    score = 0\n",
        "    breakdown = {{}}\n",
        "\n",
        "    # Skills (60 points)\n",
        "    resume_skills = set([s.lower() for s in resume_data['skills']])\n",
        "    required_skills = set([s.lower() for s in job_requirements['required_skills']])\n",
        "\n",
        "    if required_skills:\n",
        "        matching_skills = resume_skills.intersection(required_skills)\n",
        "        missing_skills = required_skills - resume_skills\n",
        "        skill_match_pct = len(matching_skills) / len(required_skills)\n",
        "        skill_points = int(skill_match_pct * 60)\n",
        "        score += skill_points\n",
        "        breakdown['skills'] = {{\n",
        "            'score': skill_points,\n",
        "            'max': 60,\n",
        "            'matching': list(matching_skills),\n",
        "            'missing': list(missing_skills),\n",
        "            'match_percentage': round(skill_match_pct * 100, 1)\n",
        "        }}\n",
        "    else:\n",
        "        score += 30\n",
        "        breakdown['skills'] = {{'score': 30, 'max': 60, 'matching': [], 'missing': [], 'match_percentage': 50.0}}\n",
        "\n",
        "    # Experience (20 points)\n",
        "    num_exp = len(resume_data['experience'])\n",
        "    if num_exp >= job_requirements['required_experience']:\n",
        "        exp_points = 20\n",
        "    elif num_exp >= job_requirements['required_experience'] - 1:\n",
        "        exp_points = 15\n",
        "    else:\n",
        "        exp_points = 10\n",
        "    score += exp_points\n",
        "    breakdown['experience'] = {{'score': exp_points, 'max': 20, 'required': job_requirements['required_experience'], 'found': num_exp}}\n",
        "\n",
        "    # Education (10 points)\n",
        "    has_edu = len(resume_data['education']) > 0\n",
        "    edu_points = 10 if has_edu else 5\n",
        "    score += edu_points\n",
        "    breakdown['education'] = {{'score': edu_points, 'max': 10, 'required': job_requirements['required_education'], 'found': has_edu}}\n",
        "\n",
        "    # Quality (10 points)\n",
        "    quality = 0\n",
        "    if resume_data['email'] != \"Not found\":\n",
        "        quality += 3\n",
        "    if resume_data['phone'] != \"Not found\":\n",
        "        quality += 3\n",
        "    if resume_data['total_words'] >= 300:\n",
        "        quality += 4\n",
        "    score += quality\n",
        "    breakdown['quality'] = {{'score': quality, 'max': 10}}\n",
        "\n",
        "    return {{\n",
        "        'total_score': score,\n",
        "        'percentage': round(score, 1),\n",
        "        'grade': 'Excellent Match' if score >= 80 else 'Good Match' if score >= 65 else 'Fair Match' if score >= 50 else 'Poor Match',\n",
        "        'breakdown': breakdown\n",
        "    }}\n",
        "\n",
        "def generate_job_match_report_with_gemini(resume_data: Dict, job_description: str, match_score: Dict, gemini_model) -> str:\n",
        "    \"\"\"Generate match report with Gemini.\"\"\"\n",
        "    prompt = f\"\"\"Career counselor analysis of job match.\n",
        "\n",
        "JOB DESCRIPTION:\n",
        "{{job_description[:1500]}}\n",
        "\n",
        "CANDIDATE:\n",
        "- Skills: {{', '.join(resume_data['skills'][:20])}}\n",
        "- Experience: {{len(resume_data['experience'])}} roles\n",
        "- Match Score: {{match_score['total_score']}}/100\n",
        "\n",
        "Provide:\n",
        "1. OVERALL FIT\n",
        "2. KEY STRENGTHS (3-4 points)\n",
        "3. GAPS (3-4 points)\n",
        "4. INTERVIEW TIPS (4-5 points)\n",
        "5. PREPARATION STEPS\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = gemini_model.generate_content(prompt)\n",
        "        return response.text\n",
        "    except:\n",
        "        return \"Report unavailable.\"\n",
        "\n",
        "def generate_tailored_cover_letter(resume_data: Dict, job_description: str, groq_client) -> str:\n",
        "    \"\"\"Generate cover letter with Groq.\"\"\"\n",
        "    prompt = f\"\"\"Write a professional cover letter.\n",
        "\n",
        "SKILLS: {{', '.join(resume_data['skills'][:15])}}\n",
        "EXPERIENCE: {{len(resume_data['experience'])}} roles\n",
        "\n",
        "JOB:\n",
        "{{job_description[:1000]}}\n",
        "\n",
        "Write 250-300 words covering:\n",
        "1. Enthusiasm for role\n",
        "2. Relevant skills/experiences\n",
        "3. Understanding of needs\n",
        "4. Call to action\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = groq_client.chat.completions.create(\n",
        "            messages=[{{\"role\": \"user\", \"content\": prompt}}],\n",
        "            model=\"llama-3.3-70b-versatile\",\n",
        "            max_tokens=500,\n",
        "            temperature=0.7\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except:\n",
        "        return \"Cover letter unavailable.\"\n",
        "\n",
        "def complete_job_match_analysis(resume_data: Dict, job_description: str) -> Dict:\n",
        "    \"\"\"Complete job matching.\"\"\"\n",
        "    job_req = extract_job_requirements(job_description)\n",
        "    match_score = calculate_match_score(resume_data, job_req)\n",
        "    gemini_report = generate_job_match_report_with_gemini(resume_data, job_description, match_score, st.session_state.gemini_model)\n",
        "    cover_letter = generate_tailored_cover_letter(resume_data, job_description, st.session_state.groq_client)\n",
        "\n",
        "    return {{\n",
        "        'match_score': match_score['total_score'],\n",
        "        'match_percentage': match_score['percentage'],\n",
        "        'match_grade': match_score['grade'],\n",
        "        'breakdown': match_score['breakdown'],\n",
        "        'gemini_report': gemini_report,\n",
        "        'cover_letter': cover_letter,\n",
        "        'missing_skills': match_score['breakdown']['skills']['missing'],\n",
        "        'matching_skills': match_score['breakdown']['skills']['matching']\n",
        "    }}\n",
        "\n",
        "# Interview Question Generation (from Cell 7)\n",
        "def generate_technical_questions(resume_data: Dict, difficulty: str, num_questions: int, groq_client) -> List[Dict]:\n",
        "    \"\"\"Generate technical questions.\"\"\"\n",
        "    skills_list = ', '.join(resume_data['skills'][:10])\n",
        "\n",
        "    prompt = f\"\"\"Generate {{num_questions}} {{difficulty}} technical interview questions.\n",
        "\n",
        "SKILLS: {{skills_list}}\n",
        "\n",
        "Format:\n",
        "Q1: [Question]\n",
        "Expected Answer: [Answer]\n",
        "Follow-up: [Follow-up]\n",
        "\n",
        "Continue for all questions.\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = groq_client.chat.completions.create(\n",
        "            messages=[{{\"role\": \"user\", \"content\": prompt}}],\n",
        "            model=\"llama-3.3-70b-versatile\",\n",
        "            max_tokens=1500,\n",
        "            temperature=0.8\n",
        "        )\n",
        "\n",
        "        questions_text = response.choices[0].message.content\n",
        "        questions = []\n",
        "        blocks = questions_text.split('\\\\n\\\\n')\n",
        "\n",
        "        for i, block in enumerate(blocks[:num_questions], 1):\n",
        "            if block.strip():\n",
        "                questions.append({{\n",
        "                    'id': i,\n",
        "                    'type': 'Technical',\n",
        "                    'difficulty': difficulty,\n",
        "                    'question': block.strip(),\n",
        "                    'category': 'Programming'\n",
        "                }})\n",
        "\n",
        "        return questions\n",
        "    except:\n",
        "        return []\n",
        "\n",
        "def generate_behavioral_questions(num_questions: int, groq_client) -> List[Dict]:\n",
        "    \"\"\"Generate behavioral questions.\"\"\"\n",
        "    prompt = f\"\"\"Generate {{num_questions}} behavioral interview questions using STAR method.\n",
        "\n",
        "Format:\n",
        "Q1: [Question]\n",
        "What to listen for: [Points]\n",
        "\n",
        "Continue for all questions.\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = groq_client.chat.completions.create(\n",
        "            messages=[{{\"role\": \"user\", \"content\": prompt}}],\n",
        "            model=\"llama-3.3-70b-versatile\",\n",
        "            max_tokens=1000,\n",
        "            temperature=0.7\n",
        "        )\n",
        "\n",
        "        questions_text = response.choices[0].message.content\n",
        "        questions = []\n",
        "        blocks = questions_text.split('\\\\n\\\\n')\n",
        "\n",
        "        for i, block in enumerate(blocks[:num_questions], 1):\n",
        "            if block.strip():\n",
        "                questions.append({{\n",
        "                    'id': i,\n",
        "                    'type': 'Behavioral',\n",
        "                    'difficulty': 'Medium',\n",
        "                    'question': block.strip(),\n",
        "                    'category': 'Soft Skills'\n",
        "                }})\n",
        "\n",
        "        return questions\n",
        "    except:\n",
        "        return []\n",
        "\n",
        "def generate_situational_questions(resume_data: Dict, num_questions: int, groq_client) -> List[Dict]:\n",
        "    \"\"\"Generate situational questions.\"\"\"\n",
        "    prompt = f\"\"\"Generate {{num_questions}} situational questions.\n",
        "\n",
        "BACKGROUND:\n",
        "- Experience: {{len(resume_data['experience'])}} roles\n",
        "- Skills: {{', '.join(resume_data['skills'][:8])}}\n",
        "\n",
        "Format:\n",
        "Q1: [Scenario and question]\n",
        "Evaluation: [Criteria]\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = groq_client.chat.completions.create(\n",
        "            messages=[{{\"role\": \"user\", \"content\": prompt}}],\n",
        "            model=\"llama-3.3-70b-versatile\",\n",
        "            max_tokens=1000,\n",
        "            temperature=0.8\n",
        "        )\n",
        "\n",
        "        questions_text = response.choices[0].message.content\n",
        "        questions = []\n",
        "        blocks = questions_text.split('\\\\n\\\\n')\n",
        "\n",
        "        for i, block in enumerate(blocks[:num_questions], 1):\n",
        "            if block.strip():\n",
        "                questions.append({{\n",
        "                    'id': i,\n",
        "                    'type': 'Situational',\n",
        "                    'difficulty': 'Medium',\n",
        "                    'question': block.strip(),\n",
        "                    'category': 'Problem Solving'\n",
        "                }})\n",
        "\n",
        "        return questions\n",
        "    except:\n",
        "        return []\n",
        "\n",
        "def generate_resume_based_questions(resume_data: Dict, num_questions: int, groq_client) -> List[Dict]:\n",
        "    \"\"\"Generate resume-based questions.\"\"\"\n",
        "    skills = ', '.join(resume_data['skills'][:10])\n",
        "    exp_summary = \"\"\n",
        "    for exp in resume_data['experience'][:3]:\n",
        "        exp_summary += f\"- {{exp['title']}}\\\\n\"\n",
        "\n",
        "    prompt = f\"\"\"Generate {{num_questions}} specific questions based on this resume.\n",
        "\n",
        "SKILLS: {{skills}}\n",
        "EXPERIENCE:\n",
        "{{exp_summary}}\n",
        "\n",
        "Format:\n",
        "Q1: [Question about resume]\n",
        "Why: [Reasoning]\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = groq_client.chat.completions.create(\n",
        "            messages=[{{\"role\": \"user\", \"content\": prompt}}],\n",
        "            model=\"llama-3.3-70b-versatile\",\n",
        "            max_tokens=1000,\n",
        "            temperature=0.7\n",
        "        )\n",
        "\n",
        "        questions_text = response.choices[0].message.content\n",
        "        questions = []\n",
        "        blocks = questions_text.split('\\\\n\\\\n')\n",
        "\n",
        "        for i, block in enumerate(blocks[:num_questions], 1):\n",
        "            if block.strip():\n",
        "                questions.append({{\n",
        "                    'id': i,\n",
        "                    'type': 'Resume-Based',\n",
        "                    'difficulty': 'Medium',\n",
        "                    'question': block.strip(),\n",
        "                    'category': 'Experience'\n",
        "                }})\n",
        "\n",
        "        return questions\n",
        "    except:\n",
        "        return []\n",
        "\n",
        "def generate_complete_interview_set(resume_data: Dict, interview_type: str, difficulty: str) -> Dict:\n",
        "    \"\"\"Generate complete interview set.\"\"\"\n",
        "    all_questions = []\n",
        "\n",
        "    if interview_type == \"Technical\":\n",
        "        all_questions.extend(generate_technical_questions(resume_data, difficulty, 8, st.session_state.groq_client))\n",
        "        all_questions.extend(generate_resume_based_questions(resume_data, 3, st.session_state.groq_client))\n",
        "    elif interview_type == \"Behavioral\":\n",
        "        all_questions.extend(generate_behavioral_questions(7, st.session_state.groq_client))\n",
        "        all_questions.extend(generate_situational_questions(resume_data, 4, st.session_state.groq_client))\n",
        "    elif interview_type == \"Mixed\":\n",
        "        all_questions.extend(generate_technical_questions(resume_data, difficulty, 4, st.session_state.groq_client))\n",
        "        all_questions.extend(generate_behavioral_questions(3, st.session_state.groq_client))\n",
        "        all_questions.extend(generate_resume_based_questions(resume_data, 2, st.session_state.groq_client))\n",
        "    else:  # Full\n",
        "        all_questions.extend(generate_technical_questions(resume_data, difficulty, 5, st.session_state.groq_client))\n",
        "        all_questions.extend(generate_behavioral_questions(4, st.session_state.groq_client))\n",
        "        all_questions.extend(generate_situational_questions(resume_data, 3, st.session_state.groq_client))\n",
        "        all_questions.extend(generate_resume_based_questions(resume_data, 3, st.session_state.groq_client))\n",
        "\n",
        "    return {{\n",
        "        'interview_type': interview_type,\n",
        "        'difficulty': difficulty,\n",
        "        'total_questions': len(all_questions),\n",
        "        'questions': all_questions\n",
        "    }}\n",
        "\n",
        "# Answer Evaluation (from Cell 8)\n",
        "def evaluate_answer_with_groq(question: str, answer: str, question_type: str, groq_client) -> Dict:\n",
        "    \"\"\"Evaluate interview answer.\"\"\"\n",
        "    prompt = f\"\"\"Evaluate this answer.\n",
        "\n",
        "TYPE: {{question_type}}\n",
        "QUESTION: {{question}}\n",
        "ANSWER: {{answer}}\n",
        "\n",
        "Score (0-10 each):\n",
        "RELEVANCE: [score]/10\n",
        "TECHNICAL_ACCURACY: [score]/10\n",
        "COMMUNICATION: [score]/10\n",
        "DEPTH: [score]/10\n",
        "COMPLETENESS: [score]/10\n",
        "\n",
        "TOTAL_SCORE: [sum]/50\n",
        "\n",
        "STRENGTHS:\n",
        "- [point]\n",
        "\n",
        "WEAKNESSES:\n",
        "- [point]\n",
        "\n",
        "IMPROVED_ANSWER:\n",
        "[better version]\n",
        "\n",
        "FEEDBACK:\n",
        "[2-3 sentences]\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = groq_client.chat.completions.create(\n",
        "            messages=[{{\"role\": \"user\", \"content\": prompt}}],\n",
        "            model=\"llama-3.3-70b-versatile\",\n",
        "            max_tokens=800,\n",
        "            temperature=0.3\n",
        "        )\n",
        "\n",
        "        eval_text = response.choices[0].message.content\n",
        "\n",
        "        scores = {{}}\n",
        "        try:\n",
        "            relevance = re.search(r'RELEVANCE:\\\\s*(\\\\d+)', eval_text)\n",
        "            technical = re.search(r'TECHNICAL_ACCURACY:\\\\s*(\\\\d+)', eval_text)\n",
        "            communication = re.search(r'COMMUNICATION:\\\\s*(\\\\d+)', eval_text)\n",
        "            depth = re.search(r'DEPTH:\\\\s*(\\\\d+)', eval_text)\n",
        "            completeness = re.search(r'COMPLETENESS:\\\\s*(\\\\d+)', eval_text)\n",
        "\n",
        "            scores = {{\n",
        "                'relevance': int(relevance.group(1)) if relevance else 7,\n",
        "                'technical_accuracy': int(technical.group(1)) if technical else 7,\n",
        "                'communication': int(communication.group(1)) if communication else 7,\n",
        "                'depth': int(depth.group(1)) if depth else 6,\n",
        "                'completeness': int(completeness.group(1)) if completeness else 7\n",
        "            }}\n",
        "\n",
        "            scores['total'] = sum(scores.values())\n",
        "            scores['percentage'] = round((scores['total'] / 50) * 100, 1)\n",
        "        except:\n",
        "            scores = {{'relevance': 7, 'technical_accuracy': 7, 'communication': 7, 'depth': 6, 'completeness': 7, 'total': 34, 'percentage': 68.0}}\n",
        "\n",
        "        return {{\n",
        "            'success': True,\n",
        "            'scores': scores,\n",
        "            'full_evaluation': eval_text,\n",
        "            'grade': get_grade(scores['percentage'])\n",
        "        }}\n",
        "    except:\n",
        "        return {{'success': False, 'scores': {{'total': 0, 'percentage': 0}}, 'full_evaluation': \"Unavailable\", 'grade': 'N/A'}}\n",
        "\n",
        "def get_grade(percentage: float) -> str:\n",
        "    \"\"\"Convert percentage to grade.\"\"\"\n",
        "    if percentage >= 90:\n",
        "        return 'A+ (Excellent)'\n",
        "    elif percentage >= 80:\n",
        "        return 'A (Very Good)'\n",
        "    elif percentage >= 70:\n",
        "        return 'B (Good)'\n",
        "    elif percentage >= 60:\n",
        "        return 'C (Fair)'\n",
        "    elif percentage >= 50:\n",
        "        return 'D (Below Average)'\n",
        "    else:\n",
        "        return 'F (Poor)'\n",
        "\n",
        "def analyze_answer_sentiment(answer: str) -> Dict:\n",
        "    \"\"\"Analyze answer confidence.\"\"\"\n",
        "    answer_lower = answer.lower()\n",
        "    confident_words = ['definitely', 'certainly', 'confident', 'sure', 'absolutely', 'experienced', 'skilled', 'proficient', 'expert']\n",
        "    uncertain_words = ['maybe', 'perhaps', 'not sure', 'think', 'guess', 'probably', 'might', 'possibly']\n",
        "\n",
        "    confident_count = sum(1 for word in confident_words if word in answer_lower)\n",
        "    uncertain_count = sum(1 for word in uncertain_words if word in answer_lower)\n",
        "    word_count = len(answer.split())\n",
        "\n",
        "    if confident_count > uncertain_count:\n",
        "        confidence = \"High\"\n",
        "        confidence_score = min(90, 70 + (confident_count * 5))\n",
        "    elif uncertain_count > confident_count:\n",
        "        confidence = \"Low\"\n",
        "        confidence_score = max(40, 60 - (uncertain_count * 5))\n",
        "    else:\n",
        "        confidence = \"Moderate\"\n",
        "        confidence_score = 65\n",
        "\n",
        "    return {{\n",
        "        'confidence_level': confidence,\n",
        "        'confidence_score': confidence_score,\n",
        "        'answer_length': word_count,\n",
        "        'is_detailed': word_count >= 50\n",
        "    }}\n",
        "\n",
        "def conduct_mock_interview(resume_data: Dict, questions: List[Dict], answers: List[str]) -> Dict:\n",
        "    \"\"\"Conduct complete interview evaluation.\"\"\"\n",
        "    interview_results = []\n",
        "    total_score = 0\n",
        "    total_possible = 0\n",
        "\n",
        "    for i, (question_obj, answer) in enumerate(zip(questions, answers), 1):\n",
        "        question = question_obj['question']\n",
        "        question_type = question_obj['type']\n",
        "\n",
        "        evaluation = evaluate_answer_with_groq(question, answer, question_type, st.session_state.groq_client)\n",
        "        sentiment = analyze_answer_sentiment(answer)\n",
        "\n",
        "        result = {{\n",
        "            'question_number': i,\n",
        "            'question': question,\n",
        "            'question_type': question_type,\n",
        "            'answer': answer,\n",
        "            'evaluation': evaluation,\n",
        "            'sentiment': sentiment,\n",
        "            'scores': evaluation['scores'],\n",
        "            'grade': evaluation['grade']\n",
        "        }}\n",
        "\n",
        "        interview_results.append(result)\n",
        "\n",
        "        if evaluation['success']:\n",
        "            total_score += evaluation['scores']['total']\n",
        "            total_possible += 50\n",
        "\n",
        "    overall_pct = round((total_score / total_possible * 100), 1) if total_possible > 0 else 0\n",
        "\n",
        "    strengths = []\n",
        "    weaknesses = []\n",
        "\n",
        "    for result in interview_results:\n",
        "        if result['evaluation']['success']:\n",
        "            if result['scores']['total'] >= 40:\n",
        "                strengths.append(result['question_type'])\n",
        "            elif result['scores']['total'] < 30:\n",
        "                weaknesses.append(result['question_type'])\n",
        "\n",
        "    return {{\n",
        "        'total_questions': len(questions),\n",
        "        'total_answered': len(answers),\n",
        "        'total_score': total_score,\n",
        "        'total_possible': total_possible,\n",
        "        'overall_percentage': overall_pct,\n",
        "        'overall_grade': get_grade(overall_pct),\n",
        "        'results': interview_results,\n",
        "        'strengths': list(set(strengths)),\n",
        "        'weaknesses': list(set(weaknesses)),\n",
        "        'average_confidence': sum(r['sentiment']['confidence_score'] for r in interview_results) / len(interview_results) if interview_results else 0\n",
        "    }}\n",
        "\n",
        "def generate_improvement_plan(interview_results: Dict, groq_client) -> str:\n",
        "    \"\"\"Generate improvement plan.\"\"\"\n",
        "    weaknesses = ', '.join(interview_results['weaknesses']) if interview_results['weaknesses'] else \"None\"\n",
        "    strengths = ', '.join(interview_results['strengths']) if interview_results['strengths'] else \"Various\"\n",
        "\n",
        "    prompt = f\"\"\"Create improvement plan for candidate.\n",
        "\n",
        "PERFORMANCE:\n",
        "- Score: {{interview_results['overall_percentage']}}%\n",
        "- Questions: {{interview_results['total_questions']}}\n",
        "- Strengths: {{strengths}}\n",
        "- Weaknesses: {{weaknesses}}\n",
        "- Confidence: {{interview_results['average_confidence']:.1f}}%\n",
        "\n",
        "Provide:\n",
        "1. TOP 3 PRIORITIES\n",
        "2. ACTION ITEMS (5-6 steps)\n",
        "3. PRACTICE TIPS\n",
        "4. 2-WEEK TIMELINE\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = groq_client.chat.completions.create(\n",
        "            messages=[{{\"role\": \"user\", \"content\": prompt}}],\n",
        "            model=\"llama-3.3-70b-versatile\",\n",
        "            max_tokens=800,\n",
        "            temperature=0.7\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except:\n",
        "        return \"Plan unavailable.\"\n",
        "\n",
        "# Session Management (from Cell 9)\n",
        "SESSION_DATA = {{\n",
        "    'resume_data': None,\n",
        "    'resume_analysis': None,\n",
        "    'job_match_analysis': None,\n",
        "    'interview_history': [],\n",
        "    'current_interview': None,\n",
        "    'user_profile': {{\n",
        "        'name': 'Candidate',\n",
        "        'sessions_completed': 0,\n",
        "        'total_questions_answered': 0,\n",
        "        'average_score': 0\n",
        "    }}\n",
        "}}\n",
        "\n",
        "def initialize_session():\n",
        "    \"\"\"Initialize session.\"\"\"\n",
        "    global SESSION_DATA\n",
        "    SESSION_DATA = {{\n",
        "        'resume_data': None,\n",
        "        'resume_analysis': None,\n",
        "        'job_match_analysis': None,\n",
        "        'interview_history': [],\n",
        "        'current_interview': None,\n",
        "        'user_profile': {{\n",
        "            'name': 'Candidate',\n",
        "            'sessions_completed': 0,\n",
        "            'total_questions_answered': 0,\n",
        "            'average_score': 0\n",
        "        }}\n",
        "    }}\n",
        "\n",
        "def save_interview_results(interview_results: Dict):\n",
        "    \"\"\"Save interview to history.\"\"\"\n",
        "    interview_record = {{\n",
        "        'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "        'interview_type': interview_results.get('interview_type', 'Mixed'),\n",
        "        'total_questions': interview_results['total_questions'],\n",
        "        'overall_score': interview_results['overall_percentage'],\n",
        "        'grade': interview_results['overall_grade'],\n",
        "        'results': interview_results['results']\n",
        "    }}\n",
        "\n",
        "    SESSION_DATA['interview_history'].append(interview_record)\n",
        "    SESSION_DATA['user_profile']['sessions_completed'] += 1\n",
        "    SESSION_DATA['user_profile']['total_questions_answered'] += interview_results['total_questions']\n",
        "\n",
        "    all_scores = [r['overall_score'] for r in SESSION_DATA['interview_history']]\n",
        "    SESSION_DATA['user_profile']['average_score'] = round(sum(all_scores) / len(all_scores), 1)\n",
        "\n",
        "def calculate_performance_trends() -> Dict:\n",
        "    \"\"\"Calculate performance trends.\"\"\"\n",
        "    if not SESSION_DATA['interview_history']:\n",
        "        return {{'trend': 'No data', 'improvement': 0, 'scores': []}}\n",
        "\n",
        "    scores = [r['overall_score'] for r in SESSION_DATA['interview_history']]\n",
        "\n",
        "    if len(scores) < 2:\n",
        "        return {{'trend': 'Insufficient data', 'improvement': 0, 'scores': scores}}\n",
        "\n",
        "    first_score = scores[0]\n",
        "    last_score = scores[-1]\n",
        "    improvement = last_score - first_score\n",
        "\n",
        "    if improvement > 10:\n",
        "        trend = \"Strong Improvement üìà\"\n",
        "    elif improvement > 0:\n",
        "        trend = \"Slight Improvement üìä\"\n",
        "    elif improvement == 0:\n",
        "        trend = \"Stable Performance ‚û°Ô∏è\"\n",
        "    elif improvement > -10:\n",
        "        trend = \"Slight Decline üìâ\"\n",
        "    else:\n",
        "        trend = \"Needs Attention ‚ö†Ô∏è\"\n",
        "\n",
        "    return {{\n",
        "        'trend': trend,\n",
        "        'improvement': round(improvement, 1),\n",
        "        'scores': scores,\n",
        "        'first_score': first_score,\n",
        "        'last_score': last_score\n",
        "    }}\n",
        "\n",
        "def analyze_question_type_performance() -> Dict:\n",
        "    \"\"\"Analyze by question type.\"\"\"\n",
        "    if not SESSION_DATA['interview_history']:\n",
        "        return {{}}\n",
        "\n",
        "    type_scores = {{\n",
        "        'Technical': [],\n",
        "        'Behavioral': [],\n",
        "        'Situational': [],\n",
        "        'Resume-Based': []\n",
        "    }}\n",
        "\n",
        "    for interview in SESSION_DATA['interview_history']:\n",
        "        for result in interview['results']:\n",
        "            q_type = result['question_type']\n",
        "            if q_type in type_scores and result['evaluation']['success']:\n",
        "                type_scores[q_type].append(result['scores']['percentage'])\n",
        "\n",
        "    avg_scores = {{}}\n",
        "    for q_type, scores in type_scores.items():\n",
        "        if scores:\n",
        "            avg_scores[q_type] = {{\n",
        "                'average': round(sum(scores) / len(scores), 1),\n",
        "                'count': len(scores),\n",
        "                'best': max(scores),\n",
        "                'worst': min(scores)\n",
        "            }}\n",
        "\n",
        "    return avg_scores\n",
        "\n",
        "def create_performance_chart_data() -> Dict:\n",
        "    \"\"\"Prepare chart data.\"\"\"\n",
        "    if not SESSION_DATA['interview_history']:\n",
        "        return {{'has_data': False}}\n",
        "\n",
        "    sessions = list(range(1, len(SESSION_DATA['interview_history']) + 1))\n",
        "    scores = [r['overall_score'] for r in SESSION_DATA['interview_history']]\n",
        "    type_perf = analyze_question_type_performance()\n",
        "\n",
        "    return {{\n",
        "        'has_data': True,\n",
        "        'score_trend': {{\n",
        "            'sessions': sessions,\n",
        "            'scores': scores\n",
        "        }},\n",
        "        'type_performance': type_perf,\n",
        "        'latest_score': scores[-1] if scores else 0,\n",
        "        'average_score': SESSION_DATA['user_profile']['average_score']\n",
        "    }}\n",
        "\n",
        "def export_session_data_to_json() -> str:\n",
        "    \"\"\"Export to JSON.\"\"\"\n",
        "    export_data = {{\n",
        "        'export_date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "        'user_profile': SESSION_DATA['user_profile'],\n",
        "        'interview_history': SESSION_DATA['interview_history'],\n",
        "        'performance_trends': calculate_performance_trends(),\n",
        "        'question_type_performance': analyze_question_type_performance()\n",
        "    }}\n",
        "    return json.dumps(export_data, indent=2)\n",
        "\n",
        "def generate_text_report(interview_results: Dict) -> str:\n",
        "    \"\"\"Generate text report.\"\"\"\n",
        "    report = f\"\"\"\n",
        "{{'=' * 70}}\n",
        "                    INTERVIEW PERFORMANCE REPORT\n",
        "{{'=' * 70}}\n",
        "\n",
        "Date: {{datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}}\n",
        "Interview Type: {{interview_results.get('interview_type', 'Mixed')}}\n",
        "\n",
        "{{'=' * 70}}\n",
        "OVERALL PERFORMANCE\n",
        "{{'=' * 70}}\n",
        "\n",
        "Total Questions: {{interview_results['total_questions']}}\n",
        "Overall Score: {{interview_results['total_score']}}/{{interview_results['total_possible']}} ({{interview_results['overall_percentage']}}%)\n",
        "Grade: {{interview_results['overall_grade']}}\n",
        "Average Confidence: {{interview_results['average_confidence']:.1f}}%\n",
        "\n",
        "{{'=' * 70}}\n",
        "END OF REPORT\n",
        "{{'=' * 70}}\n",
        "\"\"\"\n",
        "    return report\n",
        "\n",
        "def format_score_badge(score: float) -> str:\n",
        "    \"\"\"Generate score badge.\"\"\"\n",
        "    if score >= 90:\n",
        "        return \"üèÜ Excellent\"\n",
        "    elif score >= 80:\n",
        "        return \"‚≠ê Very Good\"\n",
        "    elif score >= 70:\n",
        "        return \"‚úÖ Good\"\n",
        "    elif score >= 60:\n",
        "        return \"üëç Fair\"\n",
        "    elif score >= 50:\n",
        "        return \"üìà Needs Work\"\n",
        "    else:\n",
        "        return \"‚ö†Ô∏è More Practice Needed\"\n",
        "\n",
        "def get_motivational_message(score: float) -> str:\n",
        "    \"\"\"Get motivational message.\"\"\"\n",
        "    if score >= 90:\n",
        "        return \"Outstanding! You're interview-ready! üéâ\"\n",
        "    elif score >= 80:\n",
        "        return \"Excellent work! Keep it up! üí™\"\n",
        "    elif score >= 70:\n",
        "        return \"Good job! Keep practicing! üìö\"\n",
        "    elif score >= 60:\n",
        "        return \"You're making progress! üéØ\"\n",
        "    elif score >= 50:\n",
        "        return \"Keep going! üöÄ\"\n",
        "    else:\n",
        "        return \"Don't give up! Practice makes perfect! üí°\"\n",
        "\n",
        "# UI Components (from Cell 10)\n",
        "{get_custom_css()}\n",
        "\n",
        "{COMPLETE_APP_CODE}\n",
        "'''\n",
        "\n",
        "# Save the complete app\n",
        "print(\"=\" * 60)\n",
        "print(\"üì± Complete Streamlit App Created!\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\n‚ú® Final app includes:\")\n",
        "print(\"   ‚Ä¢ All pages (Home, Resume, Job Match, Interview, Dashboard)\")\n",
        "print(\"   ‚Ä¢ All AI functions (Groq + Gemini)\")\n",
        "print(\"   ‚Ä¢ Session management\")\n",
        "print(\"   ‚Ä¢ Beautiful UI components\")\n",
        "print(\"   ‚Ä¢ Performance analytics\")\n",
        "print(\"   ‚Ä¢ Export capabilities\")\n",
        "print(\"\\nüíæ Ready to save as app.py!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgcABdN-h0qM",
        "outputId": "7d961ea2-0e5c-48b7-b72a-2d30a68ee909"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "üíæ Saving Project Files to Colab Runtime\n",
            "============================================================\n",
            "‚úÖ Saved: app.py (85806 characters)\n",
            "‚úÖ Saved: requirements.txt\n",
            "‚úÖ Saved: .streamlit/config.toml\n",
            "‚úÖ Saved: README.md\n",
            "‚úÖ Saved: .gitignore\n",
            "‚úÖ Saved: sample_data/sample_resume.txt\n",
            "‚úÖ Saved: DEPLOYMENT.md\n",
            "\n",
            "============================================================\n",
            "üì¶ Creating ZIP file for download...\n",
            "============================================================\n",
            "‚úÖ Created: interview_prep_app.zip\n",
            "\n",
            "============================================================\n",
            "‚úÖ PROJECT FILES READY!\n",
            "============================================================\n",
            "\n",
            "üìÅ Files created in /content/interview_prep_app/:\n",
            "   1. app.py - Main application (complete Streamlit app)\n",
            "   2. requirements.txt - Python dependencies\n",
            "   3. .streamlit/config.toml - Streamlit theme configuration\n",
            "   4. README.md - Project documentation\n",
            "   5. .gitignore - Git ignore rules\n",
            "   6. DEPLOYMENT.md - Detailed deployment guide\n",
            "   7. sample_data/sample_resume.txt - Test data\n",
            "\n",
            "üì¶ Download Options:\n",
            "   ‚Ä¢ Download entire folder: /content/interview_prep_app/\n",
            "   ‚Ä¢ Download ZIP: /content/interview_prep_app.zip\n",
            "\n",
            "üöÄ Next Steps:\n",
            "   1. Download the files from Colab\n",
            "   2. Create GitHub repository\n",
            "   3. Upload all files to GitHub\n",
            "   4. Deploy on Streamlit Cloud (share.streamlit.io)\n",
            "   5. Add your API keys when using the app\n",
            "\n",
            "============================================================\n",
            "üéâ PROJECT COMPLETE!\n",
            "============================================================\n",
            "\n",
            "üìÑ Complete file structure:\n",
            "interview_prep_app/\n",
            "  requirements.txt\n",
            "  README.md\n",
            "  DEPLOYMENT.md\n",
            "  app.py\n",
            "  .gitignore\n",
            "  .streamlit/\n",
            "    config.toml\n",
            "  sample_data/\n",
            "    sample_resume.txt\n"
          ]
        }
      ],
      "source": [
        "# Cell 14: Save Complete App to Files\n",
        "\n",
        "import os\n",
        "\n",
        "# Create project directory\n",
        "project_dir = \"/content/interview_prep_app\"\n",
        "os.makedirs(project_dir, exist_ok=True)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üíæ Saving Project Files to Colab Runtime\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 1. Save main app.py\n",
        "app_file_path = os.path.join(project_dir, \"app.py\")\n",
        "\n",
        "with open(app_file_path, 'w', encoding='utf-8') as f:\n",
        "    f.write(COMPLETE_APP_WITH_FUNCTIONS)\n",
        "\n",
        "print(f\"‚úÖ Saved: app.py ({len(COMPLETE_APP_WITH_FUNCTIONS)} characters)\")\n",
        "\n",
        "# 2. Create requirements.txt\n",
        "requirements = \"\"\"streamlit==1.31.0\n",
        "groq==0.4.1\n",
        "google-generativeai==0.3.2\n",
        "PyPDF2==3.0.1\n",
        "pdfplumber==0.10.3\n",
        "python-docx==1.1.0\n",
        "plotly==5.18.0\n",
        "pandas==2.1.4\n",
        "pillow==10.2.0\n",
        "\"\"\"\n",
        "\n",
        "requirements_path = os.path.join(project_dir, \"requirements.txt\")\n",
        "with open(requirements_path, 'w') as f:\n",
        "    f.write(requirements)\n",
        "\n",
        "print(f\"‚úÖ Saved: requirements.txt\")\n",
        "\n",
        "# 3. Create .streamlit/config.toml for better UI\n",
        "streamlit_dir = os.path.join(project_dir, \".streamlit\")\n",
        "os.makedirs(streamlit_dir, exist_ok=True)\n",
        "\n",
        "config_toml = \"\"\"[theme]\n",
        "primaryColor=\"#667eea\"\n",
        "backgroundColor=\"#ffffff\"\n",
        "secondaryBackgroundColor=\"#f3f4f6\"\n",
        "textColor=\"#1f2937\"\n",
        "font=\"sans serif\"\n",
        "\n",
        "[server]\n",
        "headless = true\n",
        "port = 8501\n",
        "enableCORS = false\n",
        "enableXsrfProtection = false\n",
        "\"\"\"\n",
        "\n",
        "config_path = os.path.join(streamlit_dir, \"config.toml\")\n",
        "with open(config_path, 'w') as f:\n",
        "    f.write(config_toml)\n",
        "\n",
        "print(f\"‚úÖ Saved: .streamlit/config.toml\")\n",
        "\n",
        "# 4. Create README.md\n",
        "readme = \"\"\"# üéØ AI Interview Prep & Resume Analyzer\n",
        "\n",
        "An AI-powered interview preparation and resume analysis tool built with Streamlit, Groq, and Gemini AI.\n",
        "\n",
        "## ‚ú® Features\n",
        "\n",
        "- **üìÑ Resume Analysis**: Upload PDF resumes and get comprehensive ATS compatibility scores\n",
        "- **üéØ Job Matching**: Compare your resume with job descriptions and get match scores\n",
        "- **üé§ Mock Interviews**: Practice with AI-generated interview questions\n",
        "- **üìä Performance Dashboard**: Track your progress with detailed analytics\n",
        "- **ü§ñ AI-Powered**: Uses Groq (fast inference) and Gemini (multimodal analysis)\n",
        "\n",
        "## üöÄ Quick Start\n",
        "\n",
        "### Prerequisites\n",
        "\n",
        "- Python 3.8+\n",
        "- Groq API Key ([Get it here](https://console.groq.com/keys))\n",
        "- Gemini API Key ([Get it here](https://aistudio.google.com/app/apikey))\n",
        "\n",
        "### Installation\n",
        "\n",
        "1. Clone the repository:\n",
        "```bash\n",
        "git clone <your-repo-url>\n",
        "cd interview_prep_app\n",
        "```\n",
        "\n",
        "2. Install dependencies:\n",
        "```bash\n",
        "pip install -r requirements.txt\n",
        "```\n",
        "\n",
        "3. Run the app:\n",
        "```bash\n",
        "streamlit run app.py\n",
        "```\n",
        "\n",
        "4. Open your browser to `http://localhost:8501`\n",
        "\n",
        "## üåê Deploy to Streamlit Cloud\n",
        "\n",
        "1. Push this code to GitHub\n",
        "2. Go to [share.streamlit.io](https://share.streamlit.io)\n",
        "3. Connect your GitHub repository\n",
        "4. Deploy!\n",
        "5. Add your API keys in Streamlit Cloud secrets:\n",
        "   - Go to App Settings ‚Üí Secrets\n",
        "   - Add your Groq and Gemini API keys\n",
        "\n",
        "## üìñ How to Use\n",
        "\n",
        "### 1. Resume Analysis\n",
        "- Upload your PDF resume\n",
        "- Get instant ATS compatibility score\n",
        "- View AI-powered suggestions for improvement\n",
        "- See identified skills and experience\n",
        "\n",
        "### 2. Job Matching\n",
        "- Paste any job description\n",
        "- Get match score (0-100%)\n",
        "- See which skills match and which are missing\n",
        "- Generate tailored cover letter automatically\n",
        "\n",
        "### 3. Mock Interview\n",
        "- Choose interview type (Technical/Behavioral/Mixed/Full)\n",
        "- Select difficulty (Easy/Medium/Hard)\n",
        "- Answer AI-generated questions\n",
        "- Get detailed feedback on each answer\n",
        "- Receive personalized improvement plan\n",
        "\n",
        "### 4. Performance Dashboard\n",
        "- Track your interview scores over time\n",
        "- Analyze performance by question type\n",
        "- View strengths and weaknesses\n",
        "- Export your data\n",
        "\n",
        "## üõ†Ô∏è Technology Stack\n",
        "\n",
        "- **Frontend**: Streamlit\n",
        "- **AI Models**:\n",
        "  - Groq (Llama 3.3 70B) - Fast inference for real-time responses\n",
        "  - Gemini 2.5 Flash - Multimodal analysis and vision capabilities\n",
        "- **PDF Processing**: PyPDF2, pdfplumber\n",
        "- **Visualization**: Plotly\n",
        "- **Data**: Pandas\n",
        "\n",
        "## üìä Project Structure\n",
        "```\n",
        "interview_prep_app/\n",
        "‚îú‚îÄ‚îÄ app.py                 # Main application\n",
        "‚îú‚îÄ‚îÄ requirements.txt       # Python dependencies\n",
        "‚îú‚îÄ‚îÄ .streamlit/\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ config.toml       # Streamlit configuration\n",
        "‚îî‚îÄ‚îÄ README.md             # This file\n",
        "```\n",
        "\n",
        "## üéì Use Cases\n",
        "\n",
        "- **Students**: Prepare for campus placements\n",
        "- **Job Seekers**: Practice interviews and optimize resumes\n",
        "- **Career Switchers**: Get feedback on new domain preparation\n",
        "- **Professionals**: Keep interview skills sharp\n",
        "\n",
        "## üîí Privacy & Security\n",
        "\n",
        "- All processing happens in real-time\n",
        "- No data is stored permanently on servers\n",
        "- API keys are securely managed\n",
        "- Session data is temporary\n",
        "\n",
        "## ü§ù Contributing\n",
        "\n",
        "Contributions are welcome! Feel free to:\n",
        "- Report bugs\n",
        "- Suggest features\n",
        "- Submit pull requests\n",
        "\n",
        "## üìù License\n",
        "\n",
        "MIT License - feel free to use this project for your own purposes!\n",
        "\n",
        "## üë®‚Äçüíª Author\n",
        "\n",
        "Built as a Generative AI course project\n",
        "\n",
        "## üôè Acknowledgments\n",
        "\n",
        "- Anthropic for Groq API\n",
        "- Google for Gemini AI\n",
        "- Streamlit for the amazing framework\n",
        "\n",
        "---\n",
        "\n",
        "**‚≠ê If you find this helpful, please star the repository!**\n",
        "\"\"\"\n",
        "\n",
        "readme_path = os.path.join(project_dir, \"README.md\")\n",
        "with open(readme_path, 'w') as f:\n",
        "    f.write(readme)\n",
        "\n",
        "print(f\"‚úÖ Saved: README.md\")\n",
        "\n",
        "# 5. Create .gitignore\n",
        "gitignore = \"\"\"# Python\n",
        "__pycache__/\n",
        "*.py[cod]\n",
        "*$py.class\n",
        "*.so\n",
        ".Python\n",
        "env/\n",
        "venv/\n",
        "ENV/\n",
        "build/\n",
        "develop-eggs/\n",
        "dist/\n",
        "downloads/\n",
        "eggs/\n",
        ".eggs/\n",
        "lib/\n",
        "lib64/\n",
        "parts/\n",
        "sdist/\n",
        "var/\n",
        "wheels/\n",
        "*.egg-info/\n",
        ".installed.cfg\n",
        "*.egg\n",
        "\n",
        "# Streamlit\n",
        ".streamlit/secrets.toml\n",
        "\n",
        "# API Keys\n",
        ".env\n",
        "*.env\n",
        "\n",
        "# IDE\n",
        ".vscode/\n",
        ".idea/\n",
        "*.swp\n",
        "*.swo\n",
        "*~\n",
        "\n",
        "# OS\n",
        ".DS_Store\n",
        "Thumbs.db\n",
        "\n",
        "# Logs\n",
        "*.log\n",
        "\"\"\"\n",
        "\n",
        "gitignore_path = os.path.join(project_dir, \".gitignore\")\n",
        "with open(gitignore_path, 'w') as f:\n",
        "    f.write(gitignore)\n",
        "\n",
        "print(f\"‚úÖ Saved: .gitignore\")\n",
        "\n",
        "# 6. Create sample resume for testing\n",
        "sample_resume_text = \"\"\"\n",
        "JOHN DOE\n",
        "Email: john.doe@email.com | Phone: +1-234-567-8900\n",
        "LinkedIn: linkedin.com/in/johndoe | GitHub: github.com/johndoe\n",
        "\n",
        "PROFESSIONAL SUMMARY\n",
        "Results-driven Software Engineer with 3+ years of experience in full-stack development.\n",
        "Proficient in Python, JavaScript, and cloud technologies.\n",
        "\n",
        "TECHNICAL SKILLS\n",
        "Languages: Python, JavaScript, Java, C++, SQL\n",
        "Frameworks: React, Node.js, Django, Flask, Spring Boot\n",
        "Databases: MySQL, PostgreSQL, MongoDB, Redis\n",
        "Cloud & DevOps: AWS, Docker, Kubernetes, Jenkins, Git\n",
        "Other: Machine Learning, Data Analysis, REST API, Agile, Scrum\n",
        "\n",
        "WORK EXPERIENCE\n",
        "\n",
        "Senior Software Engineer | Tech Corp Inc.\n",
        "June 2022 - Present\n",
        "- Developed and maintained microservices architecture serving 1M+ users\n",
        "- Implemented CI/CD pipeline reducing deployment time by 60%\n",
        "- Led team of 3 junior developers on e-commerce platform redesign\n",
        "- Technologies: Python, Django, AWS, Docker, PostgreSQL\n",
        "\n",
        "Software Developer | StartUp Solutions\n",
        "Jan 2021 - May 2022\n",
        "- Built responsive web applications using React and Node.js\n",
        "- Optimized database queries improving application performance by 40%\n",
        "- Collaborated with cross-functional teams in Agile environment\n",
        "- Technologies: JavaScript, React, Node.js, MongoDB\n",
        "\n",
        "Junior Developer | Digital Agency\n",
        "June 2020 - Dec 2020\n",
        "- Developed client websites and web applications\n",
        "- Fixed bugs and implemented new features based on client feedback\n",
        "- Technologies: HTML, CSS, JavaScript, PHP\n",
        "\n",
        "EDUCATION\n",
        "\n",
        "Bachelor of Technology in Computer Science\n",
        "State University | 2016 - 2020\n",
        "CGPA: 8.5/10\n",
        "\n",
        "PROJECTS\n",
        "\n",
        "E-Commerce Platform | Python, Django, React, AWS\n",
        "- Built full-stack e-commerce application with payment integration\n",
        "- Implemented user authentication and authorization\n",
        "- Deployed on AWS with auto-scaling capabilities\n",
        "\n",
        "Machine Learning Model | Python, TensorFlow, Scikit-learn\n",
        "- Developed predictive model for customer churn with 85% accuracy\n",
        "- Performed data preprocessing and feature engineering\n",
        "- Created visualization dashboard using Plotly\n",
        "\n",
        "CERTIFICATIONS\n",
        "- AWS Certified Developer Associate\n",
        "- Google Cloud Professional\n",
        "- Certified Scrum Master (CSM)\n",
        "\n",
        "ACHIEVEMENTS\n",
        "- Won Best Innovation Award at company hackathon 2023\n",
        "- Published technical article with 10K+ views\n",
        "- Mentor for Google Summer of Code 2023\n",
        "\"\"\"\n",
        "\n",
        "sample_resume_dir = os.path.join(project_dir, \"sample_data\")\n",
        "os.makedirs(sample_resume_dir, exist_ok=True)\n",
        "\n",
        "sample_resume_path = os.path.join(sample_resume_dir, \"sample_resume.txt\")\n",
        "with open(sample_resume_path, 'w') as f:\n",
        "    f.write(sample_resume_text)\n",
        "\n",
        "print(f\"‚úÖ Saved: sample_data/sample_resume.txt\")\n",
        "\n",
        "# 7. Create deployment guide\n",
        "deploy_guide = \"\"\"# üöÄ Deployment Guide\n",
        "\n",
        "## Option 1: Deploy to Streamlit Cloud (Recommended)\n",
        "\n",
        "### Step 1: Prepare GitHub Repository\n",
        "\n",
        "1. Create a new repository on GitHub\n",
        "2. Upload all files from this project:\n",
        "   - app.py\n",
        "   - requirements.txt\n",
        "   - .streamlit/config.toml\n",
        "   - README.md\n",
        "   - .gitignore\n",
        "\n",
        "### Step 2: Deploy on Streamlit Cloud\n",
        "\n",
        "1. Go to [share.streamlit.io](https://share.streamlit.io)\n",
        "2. Click \"New app\"\n",
        "3. Connect your GitHub account\n",
        "4. Select your repository\n",
        "5. Set main file path: `app.py`\n",
        "6. Click \"Deploy\"\n",
        "\n",
        "### Step 3: Add API Keys\n",
        "\n",
        "1. Go to App Settings (‚öôÔ∏è icon)\n",
        "2. Click \"Secrets\"\n",
        "3. Add your secrets in TOML format:\n",
        "```toml\n",
        "# No secrets needed - users enter API keys in the app!\n",
        "```\n",
        "\n",
        "**Note**: This app uses a user-input approach for API keys, so no secrets configuration needed!\n",
        "\n",
        "### Step 4: Share Your App\n",
        "\n",
        "Your app will be available at: `https://<your-app-name>.streamlit.app`\n",
        "\n",
        "---\n",
        "\n",
        "## Option 2: Run Locally\n",
        "\n",
        "### Prerequisites\n",
        "- Python 3.8 or higher\n",
        "- pip package manager\n",
        "\n",
        "### Installation Steps\n",
        "\n",
        "1. Clone/Download the repository\n",
        "```bash\n",
        "cd interview_prep_app\n",
        "```\n",
        "\n",
        "2. Create virtual environment (optional but recommended)\n",
        "```bash\n",
        "python -m venv venv\n",
        "source venv/bin/activate  # On Windows: venv\\\\Scripts\\\\activate\n",
        "```\n",
        "\n",
        "3. Install dependencies\n",
        "```bash\n",
        "pip install -r requirements.txt\n",
        "```\n",
        "\n",
        "4. Run the app\n",
        "```bash\n",
        "streamlit run app.py\n",
        "```\n",
        "\n",
        "5. Open browser to `http://localhost:8501`\n",
        "\n",
        "---\n",
        "\n",
        "## Option 3: Deploy to Other Platforms\n",
        "\n",
        "### Heroku\n",
        "\n",
        "1. Create `Procfile`:\n",
        "```\n",
        "web: streamlit run app.py --server.port=$PORT\n",
        "```\n",
        "\n",
        "2. Create `setup.sh`:\n",
        "```bash\n",
        "mkdir -p ~/.streamlit/\n",
        "echo \"[server]\n",
        "headless = true\n",
        "port = $PORT\n",
        "enableCORS = false\n",
        "\" > ~/.streamlit/config.toml\n",
        "```\n",
        "\n",
        "3. Deploy:\n",
        "```bash\n",
        "heroku create your-app-name\n",
        "git push heroku main\n",
        "```\n",
        "\n",
        "### Google Cloud Run\n",
        "\n",
        "1. Create `Dockerfile`:\n",
        "```dockerfile\n",
        "FROM python:3.9-slim\n",
        "WORKDIR /app\n",
        "COPY requirements.txt .\n",
        "RUN pip install -r requirements.txt\n",
        "COPY . .\n",
        "EXPOSE 8501\n",
        "CMD [\"streamlit\", \"run\", \"app.py\", \"--server.port=8501\"]\n",
        "```\n",
        "\n",
        "2. Deploy:\n",
        "```bash\n",
        "gcloud run deploy --source .\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üîë Getting API Keys\n",
        "\n",
        "### Groq API Key\n",
        "1. Visit [console.groq.com](https://console.groq.com/keys)\n",
        "2. Sign up with Google account\n",
        "3. Click \"Create API Key\"\n",
        "4. Copy the key (starts with `gsk_...`)\n",
        "5. **Free tier**: 14,400 requests/day\n",
        "\n",
        "### Gemini API Key\n",
        "1. Visit [aistudio.google.com/app/apikey](https://aistudio.google.com/app/apikey)\n",
        "2. Sign in with Google account\n",
        "3. Click \"Create API Key\"\n",
        "4. Copy the key\n",
        "5. **Free tier**: Very generous limits\n",
        "\n",
        "---\n",
        "\n",
        "## üêõ Troubleshooting\n",
        "\n",
        "### Issue: App won't start\n",
        "- Check Python version: `python --version` (need 3.8+)\n",
        "- Reinstall dependencies: `pip install -r requirements.txt --force-reinstall`\n",
        "\n",
        "### Issue: API errors\n",
        "- Verify API keys are correct\n",
        "- Check API rate limits\n",
        "- Ensure internet connection\n",
        "\n",
        "### Issue: PDF parsing fails\n",
        "- Ensure PDF is not password protected\n",
        "- Try re-saving PDF from Word/Google Docs\n",
        "- Check file size (< 10MB recommended)\n",
        "\n",
        "### Issue: Slow response\n",
        "- This is normal for first request (model loading)\n",
        "- Groq is very fast for subsequent requests\n",
        "- Check your internet speed\n",
        "\n",
        "---\n",
        "\n",
        "## üìä Performance Tips\n",
        "\n",
        "1. **Optimize PDF Size**: Keep resumes under 5MB\n",
        "2. **Use Groq for Speed**: Technical questions use Groq for fast responses\n",
        "3. **Cache Results**: Session state keeps data during navigation\n",
        "4. **Batch Processing**: Generate all interview questions at once\n",
        "\n",
        "---\n",
        "\n",
        "## üîí Security Best Practices\n",
        "\n",
        "1. **Never commit API keys** to Git\n",
        "2. **Use environment variables** in production\n",
        "3. **Enable rate limiting** if deploying publicly\n",
        "4. **Validate user inputs** before processing\n",
        "5. **Use HTTPS** in production\n",
        "\n",
        "---\n",
        "\n",
        "## üìà Monitoring\n",
        "\n",
        "### Streamlit Cloud\n",
        "- Built-in analytics in dashboard\n",
        "- View logs in real-time\n",
        "- Monitor resource usage\n",
        "\n",
        "### Local Development\n",
        "- Check terminal for logs\n",
        "- Use `st.write()` for debugging\n",
        "- Enable Streamlit debug mode: `streamlit run app.py --server.runOnSave true`\n",
        "\n",
        "---\n",
        "\n",
        "## üéì For Your Project Report\n",
        "\n",
        "### Deployment Section\n",
        "\n",
        "Include these points in your report:\n",
        "\n",
        "1. **Platform Used**: Streamlit Cloud / Local\n",
        "2. **Hosting**: Free tier on Streamlit Cloud\n",
        "3. **Technologies**: Python, Streamlit, Groq AI, Gemini AI\n",
        "4. **Architecture**: Client-server model with API integration\n",
        "5. **Scalability**: Handles multiple concurrent users\n",
        "6. **Cost**: Free (using free API tiers)\n",
        "\n",
        "### Screenshots to Include\n",
        "\n",
        "1. Landing page with API configuration\n",
        "2. Resume analysis results\n",
        "3. Job matching scores\n",
        "4. Mock interview interface\n",
        "5. Performance dashboard\n",
        "6. Deployment on Streamlit Cloud\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Pre-Deployment Checklist\n",
        "\n",
        "- [ ] All files present (app.py, requirements.txt, etc.)\n",
        "- [ ] Tested locally with `streamlit run app.py`\n",
        "- [ ] API keys work correctly\n",
        "- [ ] README.md updated with your info\n",
        "- [ ] .gitignore includes sensitive files\n",
        "- [ ] Sample data for testing\n",
        "- [ ] Screenshots for documentation\n",
        "\n",
        "---\n",
        "\n",
        "**Need help?** Check Streamlit docs at [docs.streamlit.io](https://docs.streamlit.io)\n",
        "\"\"\"\n",
        "\n",
        "deploy_guide_path = os.path.join(project_dir, \"DEPLOYMENT.md\")\n",
        "with open(deploy_guide_path, 'w') as f:\n",
        "    f.write(deploy_guide)\n",
        "\n",
        "print(f\"‚úÖ Saved: DEPLOYMENT.md\")\n",
        "\n",
        "# Create a zip file for easy download\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üì¶ Creating ZIP file for download...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "import shutil\n",
        "\n",
        "zip_path = \"/content/interview_prep_app\"\n",
        "shutil.make_archive(zip_path, 'zip', project_dir)\n",
        "\n",
        "print(f\"‚úÖ Created: interview_prep_app.zip\")\n",
        "\n",
        "# Summary\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"‚úÖ PROJECT FILES READY!\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\nüìÅ Files created in /content/interview_prep_app/:\")\n",
        "print(\"   1. app.py - Main application (complete Streamlit app)\")\n",
        "print(\"   2. requirements.txt - Python dependencies\")\n",
        "print(\"   3. .streamlit/config.toml - Streamlit theme configuration\")\n",
        "print(\"   4. README.md - Project documentation\")\n",
        "print(\"   5. .gitignore - Git ignore rules\")\n",
        "print(\"   6. DEPLOYMENT.md - Detailed deployment guide\")\n",
        "print(\"   7. sample_data/sample_resume.txt - Test data\")\n",
        "\n",
        "print(\"\\nüì¶ Download Options:\")\n",
        "print(\"   ‚Ä¢ Download entire folder: /content/interview_prep_app/\")\n",
        "print(\"   ‚Ä¢ Download ZIP: /content/interview_prep_app.zip\")\n",
        "\n",
        "print(\"\\nüöÄ Next Steps:\")\n",
        "print(\"   1. Download the files from Colab\")\n",
        "print(\"   2. Create GitHub repository\")\n",
        "print(\"   3. Upload all files to GitHub\")\n",
        "print(\"   4. Deploy on Streamlit Cloud (share.streamlit.io)\")\n",
        "print(\"   5. Add your API keys when using the app\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üéâ PROJECT COMPLETE!\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# List all files\n",
        "print(\"\\nüìÑ Complete file structure:\")\n",
        "for root, dirs, files in os.walk(project_dir):\n",
        "    level = root.replace(project_dir, '').count(os.sep)\n",
        "    indent = ' ' * 2 * level\n",
        "    print(f'{indent}{os.path.basename(root)}/')\n",
        "    subindent = ' ' * 2 * (level + 1)\n",
        "    for file in files:\n",
        "        print(f'{subindent}{file}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgJDZ344icE-",
        "outputId": "ca28faef-fc30-4e43-ca65-82651904ef1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "üéâ PROJECT COMPLETE - AI INTERVIEW PREP & RESUME ANALYZER\n",
            "======================================================================\n",
            "\n",
            "‚úÖ ALL COMPONENTS BUILT SUCCESSFULLY!\n",
            "\n",
            "üì¶ Your project is ready at: /content/interview_prep_app/\n",
            "\n",
            "üìÅ Files included:\n",
            "   ‚úì app.py                    - Complete Streamlit application (2000+ lines)\n",
            "   ‚úì requirements.txt          - All dependencies listed\n",
            "   ‚úì .streamlit/config.toml   - UI theme configuration\n",
            "   ‚úì README.md                 - Full documentation\n",
            "   ‚úì DEPLOYMENT.md             - Deployment guide\n",
            "   ‚úì .gitignore                - Git ignore rules\n",
            "   ‚úì sample_data/              - Test data\n",
            "\n",
            "üéØ FEATURES IMPLEMENTED:\n",
            "\n",
            "1. Resume Analysis Module:\n",
            "   ‚úì PDF parsing (PyPDF2 + pdfplumber)\n",
            "   ‚úì ATS score calculation (0-100)\n",
            "   ‚úì Skills extraction (40+ skills database)\n",
            "   ‚úì Gemini AI analysis\n",
            "   ‚úì Improvement suggestions\n",
            "\n",
            "2. Job Matching Module:\n",
            "   ‚úì Job description parsing\n",
            "   ‚úì Match score calculation (skills, experience, education)\n",
            "   ‚úì Skills gap analysis\n",
            "   ‚úì Gemini match report\n",
            "   ‚úì Groq cover letter generation\n",
            "\n",
            "3. Mock Interview Module:\n",
            "   ‚úì 4 interview types (Technical, Behavioral, Mixed, Full)\n",
            "   ‚úì 3 difficulty levels\n",
            "   ‚úì Dynamic question generation (Groq)\n",
            "   ‚úì Real-time answer evaluation\n",
            "   ‚úì 5-criteria scoring system\n",
            "   ‚úì Detailed feedback\n",
            "   ‚úì Improvement plans\n",
            "\n",
            "4. Performance Dashboard:\n",
            "   ‚úì Interview history tracking\n",
            "   ‚úì Score trend charts (Plotly)\n",
            "   ‚úì Question type analysis\n",
            "   ‚úì Radar charts\n",
            "   ‚úì Data export (JSON)\n",
            "\n",
            "ü§ñ AI MODELS USED:\n",
            "\n",
            "   ‚Ä¢ Groq (Llama 3.3 70B Versatile)\n",
            "     - Fast inference for real-time responses\n",
            "     - Question generation\n",
            "     - Answer evaluation\n",
            "     - Cover letter generation\n",
            "   \n",
            "   ‚Ä¢ Gemini 2.5 Flash\n",
            "     - Resume analysis\n",
            "     - Job matching reports\n",
            "     - Multimodal capabilities\n",
            "     - 1M token context window\n",
            "     \n"
          ]
        }
      ],
      "source": [
        "# Cell 15: Final Summary & Project Report Template\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"üéâ PROJECT COMPLETE - AI INTERVIEW PREP & RESUME ANALYZER\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(\"\"\"\n",
        "‚úÖ ALL COMPONENTS BUILT SUCCESSFULLY!\n",
        "\n",
        "üì¶ Your project is ready at: /content/interview_prep_app/\n",
        "\n",
        "üìÅ Files included:\n",
        "   ‚úì app.py                    - Complete Streamlit application (2000+ lines)\n",
        "   ‚úì requirements.txt          - All dependencies listed\n",
        "   ‚úì .streamlit/config.toml   - UI theme configuration\n",
        "   ‚úì README.md                 - Full documentation\n",
        "   ‚úì DEPLOYMENT.md             - Deployment guide\n",
        "   ‚úì .gitignore                - Git ignore rules\n",
        "   ‚úì sample_data/              - Test data\n",
        "\n",
        "üéØ FEATURES IMPLEMENTED:\n",
        "\n",
        "1. Resume Analysis Module:\n",
        "   ‚úì PDF parsing (PyPDF2 + pdfplumber)\n",
        "   ‚úì ATS score calculation (0-100)\n",
        "   ‚úì Skills extraction (40+ skills database)\n",
        "   ‚úì Gemini AI analysis\n",
        "   ‚úì Improvement suggestions\n",
        "\n",
        "2. Job Matching Module:\n",
        "   ‚úì Job description parsing\n",
        "   ‚úì Match score calculation (skills, experience, education)\n",
        "   ‚úì Skills gap analysis\n",
        "   ‚úì Gemini match report\n",
        "   ‚úì Groq cover letter generation\n",
        "\n",
        "3. Mock Interview Module:\n",
        "   ‚úì 4 interview types (Technical, Behavioral, Mixed, Full)\n",
        "   ‚úì 3 difficulty levels\n",
        "   ‚úì Dynamic question generation (Groq)\n",
        "   ‚úì Real-time answer evaluation\n",
        "   ‚úì 5-criteria scoring system\n",
        "   ‚úì Detailed feedback\n",
        "   ‚úì Improvement plans\n",
        "\n",
        "4. Performance Dashboard:\n",
        "   ‚úì Interview history tracking\n",
        "   ‚úì Score trend charts (Plotly)\n",
        "   ‚úì Question type analysis\n",
        "   ‚úì Radar charts\n",
        "   ‚úì Data export (JSON)\n",
        "\n",
        "ü§ñ AI MODELS USED:\n",
        "\n",
        "   ‚Ä¢ Groq (Llama 3.3 70B Versatile)\n",
        "     - Fast inference for real-time responses\n",
        "     - Question generation\n",
        "     - Answer evaluation\n",
        "     - Cover letter generation\n",
        "\n",
        "   ‚Ä¢ Gemini 2.5 Flash\n",
        "     - Resume analysis\n",
        "     - Job matching reports\n",
        "     - Multimodal capabilities\n",
        "     - 1M token context window\n",
        "     \"\"\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
